<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Readings, lectures, and videos | Data Analytics</title>
    <link>https://ssc442.netlify.app/content/</link>
      <atom:link href="https://ssc442.netlify.app/content/index.xml" rel="self" type="application/rss+xml" />
    <description>Readings, lectures, and videos</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><lastBuildDate>Wed, 01 Sep 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://ssc442.netlify.app/img/social-image.png</url>
      <title>Readings, lectures, and videos</title>
      <link>https://ssc442.netlify.app/content/</link>
    </image>
    
    <item>
      <title>Introduction to Regression</title>
      <link>https://ssc442.netlify.app/content/06-content/</link>
      <pubDate>Tue, 05 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://ssc442.netlify.app/content/06-content/</guid>
      <description>
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#required-reading&#34;&gt;Required Reading&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#guiding-questions&#34;&gt;Guiding Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#regression&#34;&gt;Introduction to Linear Regression&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#case-study-is-height-hereditary&#34;&gt;Case study: is height hereditary?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#corr-coef&#34;&gt;The correlation coefficient&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#sample-correlation-is-a-random-variable&#34;&gt;Sample correlation is a random variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#correlation-is-not-always-a-useful-summary&#34;&gt;Correlation is not always a useful summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conditional-expectation&#34;&gt;Conditional expectations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-regression-line&#34;&gt;The regression line&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#regression-improves-precision&#34;&gt;Regression improves precision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bivariate-normal-distribution-advanced&#34;&gt;Bivariate normal distribution (advanced)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variance-explained&#34;&gt;Variance explained&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#warning-there-are-two-regression-lines&#34;&gt;Warning: there are two regression lines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;required-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Required Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This page.&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- ### Supplemental Readings --&gt;
&lt;!-- - Coming soon. --&gt;
&lt;div id=&#34;guiding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Guiding Questions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;How can we express a simple relationship between variables?&lt;/li&gt;
&lt;li&gt;What is a geometric intuition behind “linear regression”?&lt;/li&gt;
&lt;li&gt;How might we visualize a linear regression?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;Today’s lecture will ask you to touch real data during the lecture. Please download the following dataset and load it into &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ssc442.netlify.app/projects/data/ames.csv&#34;&gt;&lt;i class=&#34;fas fa-file-csv&#34;&gt;&lt;/i&gt; &lt;code&gt;Ames.csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This dataset is from houses in Ames, Iowa. (Thrilling!) We will use this dataset during the lecture to illustrate some of the points discussed below.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;regression&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction to Linear Regression&lt;/h1&gt;
&lt;p&gt;Up to this point, this class has focused mainly on single variables. However, in data analytics applications, it is very common to be interested in the &lt;strong&gt;relationship&lt;/strong&gt; between two or more variables. For instance, in the coming days we will use a data-driven approach that examines the relationship between player statistics and success to guide the building of a baseball team with a limited budget. Before delving into this more complex example, we introduce necessary concepts needed to understand regression using a simpler illustration. We actually use the dataset from which regression was born.&lt;/p&gt;
&lt;p&gt;The example is from genetics. Francis Galton&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; studied the variation and heredity of human traits. Among many other traits, Galton collected and studied height data from families to try to understand heredity. While doing this, he developed the concepts of correlation and regression, as well as a connection to pairs of data that follow a normal distribution. Of course, at the time this data was collected our knowledge of genetics was quite limited compared to what we know today. A very specific question Galton tried to answer was: how well can we predict a child’s height based on the parents’ height? The technique he developed to answer this question, regression, can also be applied to our baseball question. Regression can be applied in many other circumstances as well.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Historical note&lt;/strong&gt;: Galton made important contributions to statistics and genetics, but he was also one of the first proponents of eugenics, a scientifically flawed philosophical movement favored by many biologists of Galton’s time but with horrific historical consequences. These consequences still reverberate to this day, and form the basis for much of the Western world’s racist policies. You can read more about it here: &lt;a href=&#34;https://pged.org/history-eugenics-and-genetics/&#34;&gt;https://pged.org/history-eugenics-and-genetics/&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;case-study-is-height-hereditary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Case study: is height hereditary?&lt;/h2&gt;
&lt;p&gt;We have access to Galton’s family height data through the &lt;strong&gt;HistData&lt;/strong&gt; package. This data contains heights on several dozen families: mothers, fathers, daughters, and sons. To imitate Galton’s analysis, we will create a dataset with the heights of fathers and a randomly selected son of each family:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(HistData)
data(&amp;quot;GaltonFamilies&amp;quot;)

set.seed(1983)
galton_heights &amp;lt;- GaltonFamilies %&amp;gt;%
  filter(gender == &amp;quot;male&amp;quot;) %&amp;gt;%
  group_by(family) %&amp;gt;%
  sample_n(1) %&amp;gt;%
  ungroup() %&amp;gt;%
  select(father, childHeight) %&amp;gt;%
  rename(son = childHeight)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the exercises, we will look at other relationships including mothers and daughters.&lt;/p&gt;
&lt;p&gt;Suppose we were asked to summarize the father and son data. Since both distributions are well approximated by the normal distribution, we could use the two averages and two standard deviations as summaries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;%
  summarize(mean(father), sd(father), mean(son), sd(son))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 4
##   `mean(father)` `sd(father)` `mean(son)` `sd(son)`
##            &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
## 1           69.1         2.55        69.2      2.71&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this summary fails to describe an important characteristic of the data: the trend that the taller the father, the taller the son.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;% ggplot(aes(father, son)) +
  geom_point(alpha = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/scatterplot-1.png&#34; width=&#34;40%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We will learn that the correlation coefficient is an informative summary of how two variables move together and then see how this can be used to predict one variable using the other.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;corr-coef&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The correlation coefficient&lt;/h2&gt;
&lt;p&gt;The correlation coefficient is defined for a list of pairs &lt;span class=&#34;math inline&#34;&gt;\((x_1, y_1), \dots, (x_n,y_n)\)&lt;/span&gt; as the average of the product of the standardized values:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\rho = \frac{1}{n} \sum_{i=1}^n \left( \frac{x_i-\mu_x}{\sigma_x} \right)\left( \frac{y_i-\mu_y}{\sigma_y} \right)
\]&lt;/span&gt;
with &lt;span class=&#34;math inline&#34;&gt;\(\mu_x, \mu_y\)&lt;/span&gt; the averages of &lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots, x_n\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_1, \dots, y_n\)&lt;/span&gt;, respectively, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_x, \sigma_y\)&lt;/span&gt; the standard deviations. The Greek letter &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; is commonly used in statistics books to denote the correlation. The Greek letter for &lt;span class=&#34;math inline&#34;&gt;\(r\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, because it is the first letter of regression. Soon we learn about the connection between correlation and regression. We can represent the formula above with R code using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rho &amp;lt;- mean(scale(x) * scale(y))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To understand why this equation does in fact summarize how two variables move together, consider the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;-th entry of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\left( \frac{x_i-\mu_x}{\sigma_x} \right)\)&lt;/span&gt; SDs away from the average. Similarly, the &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; that is paired with &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt;, is &lt;span class=&#34;math inline&#34;&gt;\(\left( \frac{y_1-\mu_y}{\sigma_y} \right)\)&lt;/span&gt; SDs away from the average &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. If &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are unrelated, the product &lt;span class=&#34;math inline&#34;&gt;\(\left( \frac{x_i-\mu_x}{\sigma_x} \right)\left( \frac{y_i-\mu_y}{\sigma_y} \right)\)&lt;/span&gt; will be positive ( &lt;span class=&#34;math inline&#34;&gt;\(+ \times +\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(- \times -\)&lt;/span&gt; ) as often as negative (&lt;span class=&#34;math inline&#34;&gt;\(+ \times -\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(- \times +\)&lt;/span&gt;) and will average out to about 0. This correlation is the average and therefore unrelated variables will have 0 correlation. If instead the quantities vary together, then we are averaging mostly positive products ( &lt;span class=&#34;math inline&#34;&gt;\(+ \times +\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(- \times -\)&lt;/span&gt;) and we get a positive correlation. If they vary in opposite directions, we get a negative correlation.&lt;/p&gt;
&lt;p&gt;The correlation coefficient is always between -1 and 1. We can show this mathematically: consider that we can’t have higher correlation than when we compare a list to itself (perfect correlation) and in this case the correlation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\rho = \frac{1}{n} \sum_{i=1}^n \left( \frac{x_i-\mu_x}{\sigma_x} \right)^2 =
\frac{1}{\sigma_x^2} \frac{1}{n} \sum_{i=1}^n \left( x_i-\mu_x \right)^2 =
\frac{1}{\sigma_x^2} \sigma^2_x =
1
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;A similar derivation, but with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; and its exact opposite, proves the correlation has to be bigger or equal to -1.&lt;/p&gt;
&lt;p&gt;For other pairs, the correlation is in between -1 and 1. The correlation between father and son’s heights is about 0.5:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;% summarize(r = cor(father, son)) %&amp;gt;% pull(r)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4334102&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see what data looks like for different values of &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;, here are six examples of pairs with correlations ranging from -0.9 to 0.99:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/what-correlation-looks-like-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;sample-correlation-is-a-random-variable&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sample correlation is a random variable&lt;/h3&gt;
&lt;p&gt;Before we continue connecting correlation to regression, let’s remind ourselves about random variability.&lt;/p&gt;
&lt;p&gt;In most data science applications, we observe data that includes random variation. For example, in many cases, we do not observe data for the entire population of interest but rather for a random sample. As with the average and standard deviation, the &lt;em&gt;sample correlation&lt;/em&gt; is the most commonly used estimate of the population correlation. This implies that the correlation we compute and use as a summary is a random variable.&lt;/p&gt;
&lt;p&gt;By way of illustration, let’s assume that the 179 pairs of fathers and sons is our entire population. A less fortunate geneticist can only afford measurements from a random sample of 25 pairs. The sample correlation can be computed with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;R &amp;lt;- sample_n(galton_heights, 25, replace = TRUE) %&amp;gt;%
  summarize(r = cor(father, son)) %&amp;gt;% pull(r)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; is a random variable. We can run a Monte Carlo simulation to see its distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 1000
N &amp;lt;- 25
R &amp;lt;- replicate(B, {
  sample_n(galton_heights, N, replace = TRUE) %&amp;gt;%
    summarize(r=cor(father, son)) %&amp;gt;%
    pull(r)
})
qplot(R, geom = &amp;quot;histogram&amp;quot;, binwidth = 0.05, color = I(&amp;quot;black&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/sample-correlation-distribution-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the expected value of &lt;code&gt;R&lt;/code&gt; is the population correlation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(R)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4307393&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and that it has a relatively high standard error relative to the range of values &lt;code&gt;R&lt;/code&gt; can take:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(R)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1609393&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, when interpreting correlations, remember that correlations derived from samples are estimates containing uncertainty.&lt;/p&gt;
&lt;p&gt;Also, note that because the sample correlation is an average of independent draws, the central limit actually applies. Therefore, for large enough &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, the distribution of &lt;code&gt;R&lt;/code&gt; is approximately normal with expected value &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. The standard deviation, which is somewhat complex to derive, is &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{\frac{1-r^2}{N-2}}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;In our example, &lt;span class=&#34;math inline&#34;&gt;\(N=25\)&lt;/span&gt; does not seem to be large enough to make the approximation a good one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(aes(sample=R), data = data.frame(R)) +
  stat_qq() +
  geom_abline(intercept = mean(R), slope = sqrt((1-mean(R)^2)/(N-2)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/small-sample-correlation-not-normal-1.png&#34; width=&#34;40%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you increase &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, you will see the distribution converging to normal.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;correlation-is-not-always-a-useful-summary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Correlation is not always a useful summary&lt;/h3&gt;
&lt;p&gt;Correlation is not always a good summary of the relationship between two variables. The following four artificial datasets, referred to as Anscombe’s quartet, famously illustrate this point. All these pairs have a correlation of 0.82:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## `geom_smooth()` using formula &amp;#39;y ~ x&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/ascombe-quartet-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Correlation is only meaningful in a particular context. To help us understand when it is that correlation is meaningful as a summary statistic, we will return to the example of predicting a son’s height using his father’s height. This will help motivate and define linear regression. We start by demonstrating how correlation can be useful for prediction.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conditional-expectation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conditional expectations&lt;/h2&gt;
&lt;p&gt;Suppose we are asked to guess the height of a randomly selected son and we don’t know his father’s height. Because the distribution of sons’ heights is approximately normal, we know the average height, 69.2, is the value with the highest proportion and would be the prediction with the highest chance of minimizing the error. But what if we are told that the father is taller than average, say 72 inches tall, do we still guess 69.2 for the son?&lt;/p&gt;
&lt;p&gt;It turns out that if we were able to collect data from a very large number of fathers that are 72 inches, the distribution of their sons’ heights would be normally distributed. This implies that the average of the distribution computed on this subset would be our best prediction.&lt;/p&gt;
&lt;p&gt;In general, we call this approach &lt;em&gt;conditioning&lt;/em&gt;. The general idea is that we stratify a population into groups and compute summaries in each group. To provide a mathematical description of conditioning, consider we have a population of pairs of values &lt;span class=&#34;math inline&#34;&gt;\((x_1,y_1),\dots,(x_n,y_n)\)&lt;/span&gt;, for example all father and son heights in England. In the previous week’s content, we learned that if you take a random pair &lt;span class=&#34;math inline&#34;&gt;\((X,Y)\)&lt;/span&gt;, the expected value and best predictor of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(\mbox{E}(Y) = \mu_y\)&lt;/span&gt;, the population average &lt;span class=&#34;math inline&#34;&gt;\(1/n\sum_{i=1}^n y_i\)&lt;/span&gt;. However, we are no longer interested in the general population, instead we are interested in only the subset of a population with a specific &lt;span class=&#34;math inline&#34;&gt;\(x_i\)&lt;/span&gt; value, 72 inches in our example. This subset of the population, is also a population and thus the same principles and properties we have learned apply. The &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; in the subpopulation have a distribution, referred to as the &lt;em&gt;conditional distribution&lt;/em&gt;, and this distribution has an expected value referred to as the &lt;em&gt;conditional expectation&lt;/em&gt;. In our example, the conditional expectation is the average height of all sons in England with fathers that are 72 inches. The statistical notation for the conditional expectation is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}(Y \mid X = x)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; representing the fixed value that defines that subset, for example 72 inches. Similarly, we denote the standard deviation of the strata with&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{SD}(Y \mid X = x) = \sqrt{\mbox{Var}(Y \mid X = x)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Because the conditional expectation &lt;span class=&#34;math inline&#34;&gt;\(E(Y\mid X=x)\)&lt;/span&gt; is the best predictor for the random variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for an individual in the strata defined by &lt;span class=&#34;math inline&#34;&gt;\(X=x\)&lt;/span&gt;, many data science challenges reduce to estimating this quantity. The conditional standard deviation quantifies the precision of the prediction.&lt;/p&gt;
&lt;p&gt;In the example we have been considering, we are interested in computing the average son height &lt;em&gt;conditioned&lt;/em&gt; on the father being 72 inches tall. We want to estimate &lt;span class=&#34;math inline&#34;&gt;\(E(Y|X=72)\)&lt;/span&gt; using the sample collected by Galton. We previously learned that the sample average is the preferred approach to estimating the population average. However, a challenge when using this approach to estimating conditional expectations is that for continuous data we don’t have many data points matching exactly one value in our sample. For example, we have only:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(galton_heights$father == 72)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;fathers that are exactly 72-inches. If we change the number to 72.5, we get even fewer data points:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(galton_heights$father == 72.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A practical way to improve these estimates of the conditional expectations, is to define strata of with similar values of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. In our example, we can round father heights to the nearest inch and assume that they are all 72 inches. If we do this, we end up with the following prediction for the son of a father that is 72 inches tall:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conditional_avg &amp;lt;- galton_heights %&amp;gt;%
  filter(round(father) == 72) %&amp;gt;%
  summarize(avg = mean(son)) %&amp;gt;%
  pull(avg)
conditional_avg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 70.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that a 72-inch father is taller than average – specifically, 72 - 69.1/2.5 =
1.1 standard deviations taller than the average father. Our prediction 70.5 is also taller than average, but only 0.49 standard deviations larger than the average son. The sons of 72-inch fathers have &lt;em&gt;regressed&lt;/em&gt; some to the average height. We notice that the reduction in how many SDs taller is about 0.5, which happens to be the correlation. As we will see in a later lecture, this is not a coincidence.&lt;/p&gt;
&lt;p&gt;If we want to make a prediction of any height, not just 72, we could apply the same approach to each strata. Stratification followed by boxplots lets us see the distribution of each group:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;% mutate(father_strata = factor(round(father))) %&amp;gt;%
  ggplot(aes(father_strata, son)) +
  geom_boxplot() +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/boxplot-1-1.png&#34; width=&#34;40%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not surprisingly, the centers of the groups are increasing with height.
Furthermore, these centers appear to follow a linear relationship. Below we plot the averages of each group. If we take into account that these averages are random variables with standard errors, the data is consistent with these points following a straight line:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/conditional-averages-follow-line-1.png&#34; width=&#34;40%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The fact that these conditional averages follow a line is not a coincidence. In the next section, we explain that the line these averages follow is what we call the &lt;em&gt;regression line&lt;/em&gt;, which improves the precision of our estimates. However, it is not always appropriate to estimate conditional expectations with the regression line so we also describe Galton’s theoretical justification for using the regression line.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-regression-line&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The regression line&lt;/h2&gt;
&lt;p&gt;If we are predicting a random variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; knowing the value of another &lt;span class=&#34;math inline&#34;&gt;\(X=x\)&lt;/span&gt; using a regression line, then we predict that for every standard deviation, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_X\)&lt;/span&gt;, that &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; increases above the average &lt;span class=&#34;math inline&#34;&gt;\(\mu_X\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; increase &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; standard deviations &lt;span class=&#34;math inline&#34;&gt;\(\sigma_Y\)&lt;/span&gt; above the average &lt;span class=&#34;math inline&#34;&gt;\(\mu_Y\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; the correlation between &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;. The formula for the regression is therefore:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\left( \frac{Y-\mu_Y}{\sigma_Y} \right) = \rho \left( \frac{x-\mu_X}{\sigma_X} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can rewrite it like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y = \mu_Y + \rho \left( \frac{x-\mu_X}{\sigma_X} \right) \sigma_Y
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If there is perfect correlation, the regression line predicts an increase that is the same number of SDs. If there is 0 correlation, then we don’t use &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; at all for the prediction and simply predict the average &lt;span class=&#34;math inline&#34;&gt;\(\mu_Y\)&lt;/span&gt;. For values between 0 and 1, the prediction is somewhere in between. If the correlation is negative, we predict a reduction instead of an increase.&lt;/p&gt;
&lt;p&gt;Note that if the correlation is positive and lower than 1, our prediction is closer, in standard units, to the average height than the value used to predict, &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, is to the average of the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;s. This is why we call it &lt;em&gt;regression&lt;/em&gt;: the son regresses to the average height. In fact, the title of Galton’s paper was: &lt;em&gt;Regression toward mediocrity in hereditary stature&lt;/em&gt;. To add regression lines to plots, we will need the above formula in the form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
y= b + mx \mbox{ with slope } m = \rho \frac{\sigma_y}{\sigma_x} \mbox{ and intercept } b=\mu_y - m \mu_x
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here we add the regression line to the original data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_x &amp;lt;- mean(galton_heights$father)
mu_y &amp;lt;- mean(galton_heights$son)
s_x &amp;lt;- sd(galton_heights$father)
s_y &amp;lt;- sd(galton_heights$son)
r &amp;lt;- cor(galton_heights$father, galton_heights$son)

galton_heights %&amp;gt;%
  ggplot(aes(father, son)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = r * s_y/s_x, intercept = mu_y - r * s_y/s_x * mu_x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/regression-line-1.png&#34; width=&#34;40%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The regression formula implies that if we first standardize the variables, that is subtract the average and divide by the standard deviation, then the regression line has intercept 0 and slope equal to the correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. You can make same plot, but using standard units like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;%
  ggplot(aes(scale(father), scale(son))) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = 0, slope = r)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;regression-improves-precision&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Regression improves precision&lt;/h3&gt;
&lt;p&gt;Let’s compare the two approaches to prediction that we have presented:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Round fathers’ heights to closest inch, stratify, and then take the average.&lt;/li&gt;
&lt;li&gt;Compute the regression line and use it to predict.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We use a Monte Carlo simulation sampling &lt;span class=&#34;math inline&#34;&gt;\(N=50\)&lt;/span&gt; families:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 1000
N &amp;lt;- 50

set.seed(1983)
conditional_avg &amp;lt;- replicate(B, {
  dat &amp;lt;- sample_n(galton_heights, N)
  dat %&amp;gt;% filter(round(father) == 72) %&amp;gt;%
    summarize(avg = mean(son)) %&amp;gt;%
    pull(avg)
  })

regression_prediction &amp;lt;- replicate(B, {
  dat &amp;lt;- sample_n(galton_heights, N)
  mu_x &amp;lt;- mean(dat$father)
  mu_y &amp;lt;- mean(dat$son)
  s_x &amp;lt;- sd(dat$father)
  s_y &amp;lt;- sd(dat$son)
  r &amp;lt;- cor(dat$father, dat$son)
  mu_y + r*(72 - mu_x)/s_x*s_y
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although the expected value of these two random variables is about the same:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(conditional_avg, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 70.49368&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(regression_prediction)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 70.50941&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The standard error for the regression prediction is substantially smaller:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(conditional_avg, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9635814&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(regression_prediction)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.4520833&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The regression line is therefore much more stable than the conditional mean. There is an intuitive reason for this. The conditional average is computed on a relatively small subset: the fathers that are about 72 inches tall. In fact, in some of the permutations we have no data, which is why we use &lt;code&gt;na.rm=TRUE&lt;/code&gt;. The regression always uses all the data.&lt;/p&gt;
&lt;p&gt;So why not always use the regression for prediction? Because it is not always appropriate. For example, Anscombe provided cases for which the data does not have a linear relationship. So are we justified in using the regression line to predict? Galton answered this in the positive for height data. The justification, which we include in the next section, is somewhat more advanced than the rest of this reading.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bivariate-normal-distribution-advanced&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Bivariate normal distribution (advanced)&lt;/h3&gt;
&lt;p&gt;Correlation and the regression slope are a widely used summary statistic, but they are often misused or misinterpreted. Anscombe’s examples provide over-simplified cases of dataset in which summarizing with correlation would be a mistake. But there are many more real-life examples.&lt;/p&gt;
&lt;p&gt;The main way we motivate the use of correlation involves what is called the &lt;em&gt;bivariate normal distribution&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;When a pair of random variables is approximated by the bivariate normal distribution, scatterplots look like ovals. These ovals can be thin (high correlation) or circle-shaped (no correlation).&lt;/p&gt;
&lt;!--
&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/bivariate-ovals-1.png&#34; width=&#34;672&#34; /&gt;
--&gt;
&lt;p&gt;A more technical way to define the bivariate normal distribution is the following: if &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is a normally distributed random variable, &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is also a normally distributed random variable, and the conditional distribution of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; for any &lt;span class=&#34;math inline&#34;&gt;\(X=x\)&lt;/span&gt; is approximately normal, then the pair is approximately bivariate normal.&lt;/p&gt;
&lt;p&gt;If we think the height data is well approximated by the bivariate normal distribution, then we should see the normal approximation hold for each strata. Here we stratify the son heights by the standardized father heights and see that the assumption appears to hold:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;%
  mutate(z_father = round((father - mean(father)) / sd(father))) %&amp;gt;%
  filter(z_father %in% -2:2) %&amp;gt;%
  ggplot() +
  stat_qq(aes(sample = son)) +
  facet_wrap( ~ z_father)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/qqnorm-of-strata-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we come back to defining correlation. Galton used mathematical statistics to demonstrate that, when two variables follow a bivariate normal distribution, computing the regression line is equivalent to computing conditional expectations. We don’t show the derivation here, but we can show that under this assumption, for any given value of &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, the expected value of the &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; in pairs for which &lt;span class=&#34;math inline&#34;&gt;\(X=x\)&lt;/span&gt; is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}(Y | X=x) = \mu_Y +  \rho \frac{X-\mu_X}{\sigma_X}\sigma_Y
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the regression line, with slope &lt;span class=&#34;math display&#34;&gt;\[\rho \frac{\sigma_Y}{\sigma_X}\]&lt;/span&gt; and intercept &lt;span class=&#34;math inline&#34;&gt;\(\mu_y - m\mu_X\)&lt;/span&gt;. It is equivalent to the regression equation we showed earlier which can be written like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\mbox{E}(Y \mid X=x)  - \mu_Y}{\sigma_Y} = \rho \frac{x-\mu_X}{\sigma_X}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This implies that, if our data is approximately bivariate, the regression line gives the conditional probability. Therefore, we can obtain a much more stable estimate of the conditional expectation by finding the regression line and using it to predict.&lt;/p&gt;
&lt;p&gt;In summary, if our data is approximately bivariate, then the conditional expectation, the best prediction of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; given we know the value of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, is given by the regression line.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;variance-explained&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variance explained&lt;/h3&gt;
&lt;p&gt;The bivariate normal theory also tells us that the standard deviation of the &lt;em&gt;conditional&lt;/em&gt; distribution described above is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{SD}(Y \mid X=x ) = \sigma_Y \sqrt{1-\rho^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To see why this is intuitive, notice that without conditioning, &lt;span class=&#34;math inline&#34;&gt;\(\mbox{SD}(Y) = \sigma_Y\)&lt;/span&gt;, we are looking at the variability of all the sons. But once we condition, we are only looking at the variability of the sons with a tall, 72-inch, father. This group will all tend to be somewhat tall so the standard deviation is reduced.&lt;/p&gt;
&lt;p&gt;Specifically, it is reduced to &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{1-\rho^2} = \sqrt{1 - 0.25}\)&lt;/span&gt; = 0.87 of what it was originally. We could say that father heights “explain” 13% of the variability observed in son heights.&lt;/p&gt;
&lt;p&gt;The statement “&lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; explains such and such percent of the variability” is commonly used in academic papers. In this case, this percent actually refers to the variance (the SD squared). So if the data is bivariate normal, the variance is reduced by &lt;span class=&#34;math inline&#34;&gt;\(1-\rho^2\)&lt;/span&gt;, so we say that &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; explains &lt;span class=&#34;math inline&#34;&gt;\(1- (1-\rho^2)=\rho^2\)&lt;/span&gt; (the correlation squared) of the variance.&lt;/p&gt;
&lt;p&gt;But it is important to remember that the “variance explained” statement only makes sense when the data is approximated by a bivariate normal distribution.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;warning-there-are-two-regression-lines&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Warning: there are two regression lines&lt;/h3&gt;
&lt;p&gt;We computed a regression line to predict the son’s height from father’s height. We used these calculations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_x &amp;lt;- mean(galton_heights$father)
mu_y &amp;lt;- mean(galton_heights$son)
s_x &amp;lt;- sd(galton_heights$father)
s_y &amp;lt;- sd(galton_heights$son)
r &amp;lt;- cor(galton_heights$father, galton_heights$son)
m_1 &amp;lt;-  r * s_y / s_x
b_1 &amp;lt;- mu_y - m_1*mu_x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which gives us the function &lt;span class=&#34;math inline&#34;&gt;\(\mbox{E}(Y\mid X=x) =\)&lt;/span&gt; 37.3 + 0.46 &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;What if we want to predict the father’s height based on the son’s? It is important to know that this is not determined by computing the inverse function:
&lt;span class=&#34;math inline&#34;&gt;\(x = \{ \mbox{E}(Y\mid X=x) -\)&lt;/span&gt; 37.3 &lt;span class=&#34;math inline&#34;&gt;\(\} /\)&lt;/span&gt; 0.5.&lt;/p&gt;
&lt;p&gt;We need to compute &lt;span class=&#34;math inline&#34;&gt;\(\mbox{E}(X \mid Y=y)\)&lt;/span&gt;. Since the data is approximately bivariate normal, the theory described above tells us that this conditional expectation will follow a line with slope and intercept:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m_2 &amp;lt;-  r * s_x / s_y
b_2 &amp;lt;- mu_x - m_2 * mu_y&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we get &lt;span class=&#34;math inline&#34;&gt;\(\mbox{E}(X \mid Y=y) =\)&lt;/span&gt; 40.9 + 0.41y. Again we see regression to the average: the prediction for the father is closer to the father average than the son heights &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is to the son average.&lt;/p&gt;
&lt;p&gt;Here is a plot showing the two regression lines, with blue for the predicting son heights with father heights and red for predicting father heights with son heights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;galton_heights %&amp;gt;%
  ggplot(aes(father, son)) +
  geom_point(alpha = 0.5) +
  geom_abline(intercept = b_1, slope = m_1, col = &amp;quot;blue&amp;quot;) +
  geom_abline(intercept = -b_2/m_2, slope = 1/m_2, col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/06-content_files/figure-html/two-regression-lines-1.png&#34; width=&#34;40%&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Load the &lt;code&gt;GaltonFamilies&lt;/code&gt; data from the &lt;strong&gt;HistData&lt;/strong&gt;. The children in each family are listed by gender and then by height. Create a dataset called &lt;code&gt;galton_heights&lt;/code&gt; by picking a male and female at random.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Make a scatterplot for heights between mothers and daughters, mothers and sons, fathers and daughters, and fathers and sons.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compute the correlation in heights between mothers and daughters, mothers and sons, fathers and daughters, and fathers and sons.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Francis_Galton&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Francis_Galton&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Effective Visualizations</title>
      <link>https://ssc442.netlify.app/content/03-content/</link>
      <pubDate>Tue, 14 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://ssc442.netlify.app/content/03-content/</guid>
      <description>
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#readings&#34;&gt;Readings&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#guiding-questions&#34;&gt;Guiding Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ggplot2&#34;&gt;ggplot2&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#the-components-of-a-graph&#34;&gt;The components of a graph&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ggplot-objects&#34;&gt;&lt;code&gt;ggplot&lt;/code&gt; objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#geometries-briefly&#34;&gt;Geometries (briefly)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#aesthetic-mappings&#34;&gt;Aesthetic mappings&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#aesthetics-in-general&#34;&gt;Aesthetics in general&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#now-back-to-aesthetic-mappings&#34;&gt;Now, back to aesthetic mappings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#legends-for-aesthetics&#34;&gt;Legends for aesthetics&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#annotation-layers&#34;&gt;Annotation Layers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#global-versus-local-aesthetic-mappings&#34;&gt;Global versus local aesthetic mappings&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#try-it&#34;&gt;Try it!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#some-quirky-stuff&#34;&gt;Some Quirky Stuff&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scales-and-transformations&#34;&gt;Scales and transformations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#log-transformations&#34;&gt;Log transformations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#transforming-data-vs.-transforming-using-scale_...&#34;&gt;Transforming data vs. transforming using &lt;code&gt;scale_...&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#axis-labels-legends-and-titles&#34;&gt;Axis labels, legends, and titles&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#changing-axis-titles&#34;&gt;Changing axis titles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#titles&#34;&gt;Titles&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#axis-ticks&#34;&gt;Axis ticks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#additional-geometries&#34;&gt;Additional geometries&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#geom_line&#34;&gt;&lt;code&gt;geom_line&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-different-data-with-different-geometries&#34;&gt;Using different data with different geometries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#multiple-geometries&#34;&gt;Multiple geometries&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#try-it-1&#34;&gt;Try it!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;readings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Readings&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This page.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;guiding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Guiding Questions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;No guiding questions today; we’re mostly learning some technical aspects of &lt;code&gt;ggplot&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;ggplot2&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;ggplot2&lt;/h1&gt;
&lt;p&gt;Exploratory data visualization is perhaps the greatest strength of &lt;code&gt;R&lt;/code&gt;. One can quickly go from idea to data to plot with a unique balance of flexibility and ease. For example, Excel may be easier than &lt;code&gt;R&lt;/code&gt; for some plots, but it is nowhere near as flexible. &lt;code&gt;D3.js&lt;/code&gt; may be more flexible and powerful than &lt;code&gt;R&lt;/code&gt;, but it takes much longer to generate a plot. One of the reasons we use &lt;code&gt;R&lt;/code&gt; is its incredible flexibility &lt;strong&gt;and&lt;/strong&gt; ease.&lt;/p&gt;
&lt;p&gt;Throughout this course, we will be creating plots using the &lt;strong&gt;ggplot2&lt;/strong&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Many other approaches are available for creating plots in &lt;code&gt;R&lt;/code&gt;. In fact, the plotting capabilities that come with a basic installation of &lt;code&gt;R&lt;/code&gt; are already quite powerful. There are also other packages for creating graphics such as &lt;strong&gt;grid&lt;/strong&gt; and &lt;strong&gt;lattice&lt;/strong&gt;. We chose to use &lt;strong&gt;ggplot2&lt;/strong&gt; in this course because it breaks plots into components in a way that permits beginners to create relatively complex and aesthetically pleasing plots using syntax that is intuitive and comparatively easy to remember.&lt;/p&gt;
&lt;p&gt;One reason &lt;strong&gt;ggplot2&lt;/strong&gt; is generally more intuitive for beginners is that it uses a so-called “grammar of graphics”&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, the letters &lt;em&gt;gg&lt;/em&gt; in &lt;strong&gt;ggplot2&lt;/strong&gt;. This is analogous to the way learning grammar can help a beginner construct hundreds of different sentences by learning just a handful of verbs, nouns and adjectives without having to memorize each specific sentence. Similarly, by learning a handful of &lt;strong&gt;ggplot2&lt;/strong&gt; building blocks and its grammar, you will be able to create hundreds of different plots.&lt;/p&gt;
&lt;p&gt;Another reason &lt;strong&gt;ggplot2&lt;/strong&gt; is easy for beginners is that its default behavior is carefully chosen to satisfy the great majority of cases and is visually pleasing. As a result, it is possible to create informative and elegant graphs with relatively simple and readable code.&lt;/p&gt;
&lt;p&gt;One limitation is that &lt;strong&gt;ggplot2&lt;/strong&gt; is designed to work exclusively with data tables in tidy format (where rows are observations and columns are variables). However, a substantial percentage of datasets that beginners work with are in, or can be converted into, this format. An advantage of this approach is that, assuming that our data is tidy, &lt;strong&gt;ggplot2&lt;/strong&gt; simplifies plotting code and the learning of grammar for a variety of plots. You should review the previous content about tidy data if you are feeling lost.&lt;/p&gt;
&lt;p&gt;To use &lt;strong&gt;ggplot2&lt;/strong&gt; you will have to learn several functions and arguments. These are hard to memorize, so we highly recommend you have the ggplot2 cheat sheet handy. You can get a copy here: &lt;a href=&#34;https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf&#34;&gt;https://www.rstudio.com/wp-content/uploads/2015/03/ggplot2-cheatsheet.pdf&lt;/a&gt; or simply perform an internet search for “ggplot2 cheat sheet”.&lt;/p&gt;
&lt;div id=&#34;the-components-of-a-graph&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The components of a graph&lt;/h2&gt;
&lt;p&gt;We will eventually construct a graph that summarizes the US murders dataset that looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-plot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can clearly see how much states vary across population size and the total number of murders. Not surprisingly, we also see a clear relationship between murder totals and population size. A state falling on the dashed grey line has the same murder rate as the US average. The four geographic regions are denoted with color, which depicts how most southern states have murder rates above the average.&lt;/p&gt;
&lt;p&gt;This data visualization shows us pretty much all the information in the data table. The code needed to make this plot is relatively simple. We will learn to create the plot part by part.&lt;/p&gt;
&lt;p&gt;The first step in learning &lt;strong&gt;ggplot2&lt;/strong&gt; is to be able to break a graph apart into components. Let’s break down the plot above and introduce some of the &lt;strong&gt;ggplot2&lt;/strong&gt; terminology. The main five components to note are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Data&lt;/strong&gt;: The US murders data table is being summarized. We refer to this as the &lt;strong&gt;data&lt;/strong&gt; component.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Geometry&lt;/strong&gt;: The plot above is a scatterplot. This is referred to as the
&lt;strong&gt;geometry&lt;/strong&gt; component. Other possible geometries are barplot, histogram, smooth densities, qqplot, boxplot, pie (ew!), and many, many more. We will learn about these later.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Aesthetic mapping&lt;/strong&gt;: The plot uses several visual cues to represent the information provided by the dataset. The two most important cues in this plot are the point positions on the x-axis and y-axis, which represent population size and the total number of murders, respectively. Each point represents a different observation, and we &lt;em&gt;map&lt;/em&gt; data about these observations to visual cues like x- and y-scale. Color is another visual cue that we map to region. We refer to this as the &lt;strong&gt;aesthetic mapping&lt;/strong&gt; component. How we define the mapping depends on what &lt;strong&gt;geometry&lt;/strong&gt; we are using.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Annotations&lt;/strong&gt;: These are things like axis labels, axis ticks (the lines along the axis at regular intervals or specific points of interest), axis scales (e.g. log-scale), titles, legends, etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Style&lt;/strong&gt;: An overall appearance of the graph determined by fonts, color palattes, layout, blank spaces, and more.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We also note that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The points are labeled with the state abbreviations.&lt;/li&gt;
&lt;li&gt;The range of the x-axis and y-axis appears to be defined by the range of the data. They are both on log-scales.&lt;/li&gt;
&lt;li&gt;There are labels, a title, a legend, and we use the style of The Economist magazine.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of the flexibility and visualization power of &lt;code&gt;ggplot&lt;/code&gt; is contained in these four elements (plus your data)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ggplot-objects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;ggplot&lt;/code&gt; objects&lt;/h2&gt;
&lt;p&gt;We will now construct the plot piece by piece.&lt;/p&gt;
&lt;p&gt;We start by loading the dataset:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first step in creating a &lt;strong&gt;ggplot2&lt;/strong&gt; graph is to define a &lt;code&gt;ggplot&lt;/code&gt; object. We do this with the function &lt;code&gt;ggplot&lt;/code&gt;, which initializes the graph. If we read the help file for this function, we see that the first argument is used to specify what data is associated with this object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(data = murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also pipe the data in as the first argument. So this line of code is equivalent to the one above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% ggplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It renders a plot. But in this case, it renders a blank slate. The object was created and, because it was not assigned to an object, it was automatically evaluated. Of course, we can assign our plot to an object, for example like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(data = murders)
class(p)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;gg&amp;quot;     &amp;quot;ggplot&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To render the plot associated with this object, we simply print the object &lt;code&gt;p&lt;/code&gt;. The following two lines of code each produce the same plot we see above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(p)
p&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;geometries-briefly&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Geometries (briefly)&lt;/h2&gt;
&lt;p&gt;The plot above is incredibly boring (it’s only a blank slate). It’s boring because we didn’t tell &lt;code&gt;ggplot2&lt;/code&gt; what to do. In general, if &lt;code&gt;R&lt;/code&gt; is doing something unexpected, it’s because you (the user) failed to tell it what you had in &lt;em&gt;mind&lt;/em&gt;. Here, we want to make an actual plot, but we didn’t tell &lt;code&gt;R&lt;/code&gt; what sort of plot to make. In order to tell it what sort of plot we want, we use “geometries”.&lt;/p&gt;
&lt;p&gt;Specifically, in &lt;code&gt;ggplot2&lt;/code&gt; we create graphs by adding geometry &lt;em&gt;layers&lt;/em&gt;. Layers can define geometries, compute summary statistics, define what scales to use, create annotations, or even change styles. To add layers, we use the symbol &lt;code&gt;+&lt;/code&gt;. In general, a line of code will look like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;DATA %&amp;gt;% ggplot() + LAYER 1 + LAYER 2 + ... + LAYER N&lt;/code&gt;
Usually, the first &lt;strong&gt;added&lt;/strong&gt; layer after &lt;code&gt;ggplot() +&lt;/code&gt; defines the geometry. After that, we may add additional geometries, we may rescale an axis, we may add annotations and labels, or we may change the style. For now, we want to make a scatterplot. What geometry do we use?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Taking a quick look at the cheat sheet, we see that the function used to create plots with this geometry is &lt;code&gt;geom_point&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/example/02-example_files/ggplot2-cheatsheeta.png&#34; /&gt;
&lt;img src=&#34;https://ssc442.netlify.app/example/02-example_files/ggplot2-cheatsheetb.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Image courtesy of RStudio&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. CC-BY-4.0 license&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.)&lt;/p&gt;
&lt;!--(Source: [RStudio](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf))--&gt;
&lt;p&gt;Geometry function names follow the pattern: &lt;code&gt;geom_X&lt;/code&gt; where X is the name of some specific geometry. Some examples include &lt;code&gt;geom_point&lt;/code&gt;, &lt;code&gt;geom_bar&lt;/code&gt;, and &lt;code&gt;geom_histogram&lt;/code&gt;. You’ve already seen a few of these. We will start with a scatterplot created using &lt;code&gt;geom_point()&lt;/code&gt; for now, then circle back to more geometries after we cover aesthetic mappings, layers, and annotations.&lt;/p&gt;
&lt;p&gt;For &lt;code&gt;geom_point&lt;/code&gt; to run properly we need to provide data and an &lt;strong&gt;aesthetic mapping&lt;/strong&gt;. The simplest mapping for a scatter plot is to say we want one variable on the X-axis, and a different one on the Y-axis, so each point is an {X,Y} pair. That is an &lt;strong&gt;aesthetic mapping&lt;/strong&gt; because X and Y are &lt;strong&gt;aesthetics&lt;/strong&gt; in a &lt;code&gt;geom_point&lt;/code&gt; scatterplot.&lt;/p&gt;
&lt;p&gt;We have already connected the object &lt;code&gt;p&lt;/code&gt; with the &lt;code&gt;murders&lt;/code&gt; data table, and if we add the layer &lt;code&gt;geom_point&lt;/code&gt; it defaults to using this data. To find out what mappings are expected, we read the &lt;strong&gt;Aesthetics&lt;/strong&gt; section of the help file &lt;code&gt;?geom_point&lt;/code&gt; help file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; Aesthetics
&amp;gt;
&amp;gt; geom_point understands the following aesthetics (required aesthetics are in bold):
&amp;gt;
&amp;gt; **x**
&amp;gt;
&amp;gt; **y**
&amp;gt;
&amp;gt; alpha
&amp;gt;
&amp;gt; colour
&amp;gt;
&amp;gt; fill
&amp;gt;
&amp;gt; group
&amp;gt;
&amp;gt; shape
&amp;gt;
&amp;gt; size
&amp;gt;
&amp;gt; stroke&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and—although it does not show in bold above—we see that at least two arguments are required: &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. You can’t have a &lt;code&gt;geom_point&lt;/code&gt; scatterplot unless you state what you want on the X and Y axes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;aesthetic-mappings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aesthetic mappings&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Aesthetic mappings&lt;/strong&gt; describe how properties of the data connect with features of the graph, such as distance along an axis, size, or color. The &lt;code&gt;aes&lt;/code&gt; function connects data with what we see on the graph by defining aesthetic mappings and will be one of the functions you use most often when plotting. The outcome of the &lt;code&gt;aes&lt;/code&gt; function is often used as the argument of a geometry function. This example produces a scatterplot of population in millions (x-axis) versus total murders (y-axis):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% ggplot() +
  geom_point(aes(x = population/10^6, y = total))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of defining our plot from scratch, we can also add a layer to the &lt;code&gt;p&lt;/code&gt; object that was defined above as &lt;code&gt;p &amp;lt;- ggplot(data = murders)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The scales and annotations like axis labels are defined by default when adding this layer (note the x-axis label is exactly what we wrote in the function call). Like &lt;strong&gt;dplyr&lt;/strong&gt; functions, &lt;code&gt;aes&lt;/code&gt; also uses the variable names from the object component: we can use &lt;code&gt;population&lt;/code&gt; and &lt;code&gt;total&lt;/code&gt; without having to call them as &lt;code&gt;murders$population&lt;/code&gt; and &lt;code&gt;murders$total&lt;/code&gt;. The behavior of recognizing the variables from the data component is quite specific to &lt;code&gt;aes&lt;/code&gt;. With most functions, if you try to access the values of &lt;code&gt;population&lt;/code&gt; or &lt;code&gt;total&lt;/code&gt; outside of &lt;code&gt;aes&lt;/code&gt; you receive an error.&lt;/p&gt;
&lt;p&gt;Note that we did some rescaling within the &lt;code&gt;aes()&lt;/code&gt; call - we can do simple things like multiplication or division on the variable names in the &lt;code&gt;ggplot&lt;/code&gt; call. The axis labels reflect this. We will change the axis labels later.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;aesthetic mappings&lt;/strong&gt; are very powerful - changing the variable in &lt;code&gt;x=&lt;/code&gt; or &lt;code&gt;y=&lt;/code&gt; changes the meaning of the plot entirely. We’ll come back to additional &lt;strong&gt;aesthetic mappings&lt;/strong&gt; once we talk about aesthetics in general.&lt;/p&gt;
&lt;div id=&#34;aesthetics-in-general&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Aesthetics in general&lt;/h3&gt;
&lt;p&gt;Even without mappings, a plots aesthetics can be useful. Things like color, fill, alpha, and size are aesthetics that can be changed.&lt;/p&gt;
&lt;p&gt;Let’s say we want larger points in our scatterplot. The &lt;code&gt;size&lt;/code&gt; aesthetic can be used to set the size. The scale of &lt;code&gt;size&lt;/code&gt; is “multiples of the defaults” (so &lt;code&gt;size = 1&lt;/code&gt; is the default)&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total), size = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;size&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a mapping so it is &lt;strong&gt;not&lt;/strong&gt; in the &lt;code&gt;aes()&lt;/code&gt; part: whereas mappings use data from specific observations and need to be inside &lt;code&gt;aes()&lt;/code&gt;, operations we want to affect all the points the same way do not need to be included inside &lt;code&gt;aes&lt;/code&gt;. We’ll see what happens if &lt;code&gt;size&lt;/code&gt; is inside &lt;code&gt;aes(size = xxx)&lt;/code&gt; in a second.&lt;/p&gt;
&lt;p&gt;We can change the &lt;code&gt;shape&lt;/code&gt; to one of the many different base-R options found &lt;a href=&#34;http://www.sthda.com/english/wiki/r-plot-pch-symbols-the-different-point-shapes-available-in-r&#34;&gt;here&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total), size = 3, shape = 17)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-5shape-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can also change the &lt;code&gt;fill&lt;/code&gt; and the &lt;code&gt;color&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total), size = 4, shape = 23, fill = &amp;#39;#18453B&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-5b-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;fill&lt;/code&gt; can take a common name like &lt;code&gt;&#39;green&#39;&lt;/code&gt;, or can take a hex color like &lt;code&gt;&#39;#18453B&#39;&lt;/code&gt;, which is &lt;a href=&#34;https://brand.msu.edu/design-visual/index.html#color&#34;&gt;MSU Green according to MSU’s branding site&lt;/a&gt;. You can also find &lt;a href=&#34;https://youtu.be/0BxNHwJi1y4&#34;&gt;UM Maize&lt;/a&gt; and &lt;a href=&#34;https://youtu.be/dQw4w9WgXcQ&#34;&gt;OSU Scarlet&lt;/a&gt; on respective branding pages, or google “XXX color hex.” We’ll learn how to build a color palatte later on.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;color&lt;/code&gt; (or &lt;code&gt;colour&lt;/code&gt;, same thing because &lt;code&gt;ggplot&lt;/code&gt; creators allow both spellings) is a little tricky with points - it changes the outline of the geometry rather than the fill color, but in &lt;code&gt;geom_point()&lt;/code&gt; most shapes are only the outline, including the default. This is more useful with, say, a barplot where the outline and the fill might be different colors. Still, shapes 21-25 have both &lt;code&gt;fill&lt;/code&gt; and &lt;code&gt;color&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total), size = 5, shape = 23, fill = &amp;#39;#18453B&amp;#39;, color = &amp;#39;white&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-5c-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;color = &#39;white&#39;&lt;/code&gt; makes the outline of the shape white, which you can see if you look closely in the areas where the shapes overlap. This only works with shapes 21-25, or any other geometry that has both an outline and a fill.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-back-to-aesthetic-mappings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Now, back to aesthetic mappings&lt;/h3&gt;
&lt;p&gt;Now that we’ve seen a few aesthetics (and know we can find more by looking at which aesthetics work with our geometry in the help file), let’s return to the power of aesthetic mappings.&lt;/p&gt;
&lt;p&gt;An &lt;strong&gt;aesthetic mapping&lt;/strong&gt; means we can vary an aesthetic (like fill or shape or size) according to some &lt;strong&gt;variable in our data&lt;/strong&gt;. This opens up a world of possibilities! Let’s try adding to our &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; aesthetics with a &lt;code&gt;color&lt;/code&gt; aesthetic (since points respond to &lt;code&gt;color&lt;/code&gt; better than &lt;code&gt;fill&lt;/code&gt;) that varies by &lt;code&gt;region&lt;/code&gt;, which is a column in our data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total, color = region), size = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-color-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We include &lt;code&gt;color=region&lt;/code&gt; &lt;strong&gt;inside&lt;/strong&gt; the &lt;code&gt;aes&lt;/code&gt; call, which tells R to find a variable called &lt;code&gt;region&lt;/code&gt; and change color based on that. R will choose a somewhat ghastly color palatte, and &lt;strong&gt;every&lt;/strong&gt; unique value in the data for &lt;code&gt;region&lt;/code&gt; will get a different color if the variable is discrete. If the variable is a continuous value, then &lt;code&gt;ggplot&lt;/code&gt; will automatically make a color ramp. Thus, &lt;strong&gt;discrete&lt;/strong&gt; and &lt;strong&gt;continuous&lt;/strong&gt; values for aesthetic mappings work differently.&lt;/p&gt;
&lt;p&gt;Let’s see a useful example of a continuous aesthetic mapping to &lt;code&gt;color&lt;/code&gt;. In our data, we are making a scatterplot of population and total murders, which really just shows that states with higher populations have higher murders. What we really want is murders per capita (I think COVID taught us a lot about rates vs. levels like “cases” and “cases per 100,000 people”). We can create a variable of “murders per capita” on the fly. Since “murders per capita” is a very small number and hard to read, we’ll multiply by 100 so that we get “percent of population murdered per year”:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^5, y = total, color = 100*total/population), size = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-colfill-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While the clear pattern of “more population means more murders” is still there, look at the outlier in light blue in the bottom left. With the color ramp, see how easy it is to see here that there is one location where murders per capita is quite high?&lt;/p&gt;
&lt;p&gt;Note that &lt;code&gt;size&lt;/code&gt; is outside of &lt;code&gt;aes&lt;/code&gt; and is set to an explicit value, not to a variable. What if we set size to a variable in the data?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total, color = region, size = population/10^6))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-color2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;legends-for-aesthetics&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Legends for aesthetics&lt;/h3&gt;
&lt;p&gt;Here we see yet another useful default behavior: &lt;strong&gt;ggplot2&lt;/strong&gt; automatically adds a legend that maps color to region, and size to population (which we scaled by 1,000,000). To avoid adding this legend we set the &lt;code&gt;geom_point&lt;/code&gt; argument &lt;code&gt;show.legend = FALSE&lt;/code&gt;. This removes both the &lt;code&gt;size&lt;/code&gt; and the &lt;code&gt;color&lt;/code&gt; legend.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total, color = region, size = population/10^6), show.legend = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-color3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Later on, when we get to &lt;strong&gt;annotation layers&lt;/strong&gt;, we’ll talk about controlling the legend text and layout. For now, we just need to know how to turn them off.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;annotation-layers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Annotation Layers&lt;/h2&gt;
&lt;p&gt;A second layer in the plot we wish to make involves adding a label to each point to identify the state. The &lt;code&gt;geom_label&lt;/code&gt; and &lt;code&gt;geom_text&lt;/code&gt; functions permit us to add text to the plot with and without a rectangle behind the text, respectively.&lt;/p&gt;
&lt;p&gt;Because each point (each state in this case) has a label, we need an &lt;strong&gt;aesthetic mapping&lt;/strong&gt; to make the connection between points and labels. By reading the help file &lt;code&gt;?geom_text&lt;/code&gt;, we learn that we supply the mapping between point and label through the &lt;code&gt;label&lt;/code&gt; argument of &lt;code&gt;aes&lt;/code&gt;. That is, &lt;code&gt;label&lt;/code&gt; is an &lt;strong&gt;aesthetic&lt;/strong&gt; that we can map. So the code looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total)) +
  geom_text(aes(x = population/10^6, y = total, label = abb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We have successfully added a second layer to the plot.&lt;/p&gt;
&lt;p&gt;As an example of the unique behavior of &lt;code&gt;aes&lt;/code&gt; mentioned above, note that this call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total)) +
  geom_text(aes(population/10^6, total, label = abb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is fine, whereas this call:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total)) +
  geom_text(aes(population/10^6, total), label = abb)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will give you an error since &lt;code&gt;abb&lt;/code&gt; is not found because it is outside of the &lt;code&gt;aes&lt;/code&gt; function. The layer &lt;code&gt;geom_text&lt;/code&gt; does not know where to find &lt;code&gt;abb&lt;/code&gt; since it is a column name and not a global variable, and &lt;code&gt;ggplot&lt;/code&gt; does not look for column names for non-mapped aesthetics. For a trivial example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total)) +
  geom_text(aes(population/10^6, total), label = &amp;#39;abb&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;global-versus-local-aesthetic-mappings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Global versus local aesthetic mappings&lt;/h3&gt;
&lt;p&gt;In the previous line of code, we define the mapping &lt;code&gt;aes(population/10^6, total)&lt;/code&gt; twice, once in each geometry. We can avoid this by using a &lt;em&gt;global&lt;/em&gt; aesthetic mapping. We can do this when we define the blank slate &lt;code&gt;ggplot&lt;/code&gt; object. Remember that the function &lt;code&gt;ggplot&lt;/code&gt; contains an argument that permits us to define aesthetic mappings:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;args(ggplot)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (data = NULL, mapping = aes(), ..., environment = parent.frame()) 
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we define a mapping in &lt;code&gt;ggplot&lt;/code&gt;, all the geometries that are added as layers will default to this mapping. We redefine &lt;code&gt;p&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- murders %&amp;gt;% ggplot(aes(x = population/10^6, y = total, label = abb))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then we can simply write the following code to produce the previous plot:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(size = 3) +
  geom_text(nudge_x = 1.5) # offsets the label&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We keep the &lt;code&gt;size&lt;/code&gt; and &lt;code&gt;nudge_x&lt;/code&gt; arguments in &lt;code&gt;geom_point&lt;/code&gt; and &lt;code&gt;geom_text&lt;/code&gt;, respectively, because we want to only increase the size of points and only nudge the labels. If we put those arguments in &lt;code&gt;aes&lt;/code&gt; then they would apply to both plots. Also note that the &lt;code&gt;geom_point&lt;/code&gt; function does not need a &lt;code&gt;label&lt;/code&gt; argument and therefore ignores that aesthetic.&lt;/p&gt;
&lt;p&gt;If necessary, we can override the global mapping by defining a new mapping within each layer. These &lt;em&gt;local&lt;/em&gt; definitions override the &lt;em&gt;global&lt;/em&gt;. Here is an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(size = 3) +
  geom_text(aes(x = 10, y = 800, label = &amp;quot;Hello there!&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Clearly, the second call to &lt;code&gt;geom_text&lt;/code&gt; does not use &lt;code&gt;x = population&lt;/code&gt; and &lt;code&gt;y = total&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;try-it&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Try it!&lt;/h2&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;Let’s break in to smaller groups and try playing with some of the aesthetics and aesthetic mappings. If we’re online, we’ll use Zoom Breakout Rooms. Each of the rooms have a room number which will correspond with one of the tasks below. If we’re in person (woohoo!), we’ll form the same number of groups in class.&lt;/p&gt;
&lt;p&gt;In each group, one person should be the main coder - someone who has the packages like &lt;code&gt;dslabs&lt;/code&gt; installed and has successfully run the plots above. Each set of tasks ask you to learn about an aesthetic and put it into action with the &lt;code&gt;murder&lt;/code&gt; data. We’ll leave about 5 minutes to do the task, then have you come back and share your results with the class.&lt;/p&gt;
&lt;p&gt;For each group, we’ll start with the following code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p + geom_point(aes(x = population/10^6, y = total)) +
  geom_text(aes(x = population/10^6, y = total, label = abb))&lt;/code&gt;&lt;/pre&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The &lt;code&gt;alpha&lt;/code&gt; aesthetic mapping.
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;The &lt;code&gt;alpha&lt;/code&gt; aesthetic can only take a number between 0 and 1. So first, in &lt;code&gt;murders&lt;/code&gt;, create a &lt;code&gt;murders_per_capita&lt;/code&gt; column by dividing &lt;code&gt;total&lt;/code&gt; by &lt;code&gt;population&lt;/code&gt;. Second, find the &lt;code&gt;max(murders$murders_per_capita)&lt;/code&gt; and then create another new column called &lt;code&gt;murders_per_capita_rescaled&lt;/code&gt; which divides &lt;code&gt;murders_per_capita&lt;/code&gt; by the max value. &lt;code&gt;murders_per_capita_rescaled&lt;/code&gt; will be between 0 and 1, with the value of 1 for the state with the max murder rate. This is a little hard to do on the fly in &lt;code&gt;ggplot&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;alpha&lt;/code&gt; aesthetic mapping to &lt;code&gt;murders_per_capita_rescaled&lt;/code&gt; for &lt;code&gt;geom_point&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Turn off the legend using &lt;code&gt;show.legend=FALSE&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Include the &lt;code&gt;geom_text&lt;/code&gt; labels, but make sure the aesthetic mapping does &lt;strong&gt;not&lt;/strong&gt; apply to the labels.&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;nudge_x = 1.5&lt;/code&gt; as before to offset the labels.&lt;/li&gt;
&lt;li&gt;Be able to explain the plot.
&lt;ul&gt;
&lt;li&gt;Does the &lt;code&gt;alpha&lt;/code&gt; aesthetic help present the data here? It’s OK if it doesn’t!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;stroke&lt;/code&gt; aesthetic mapping.
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;The &lt;code&gt;stroke&lt;/code&gt; aesthetic works a bit like the &lt;code&gt;size&lt;/code&gt; aesthetic. It must be used with a plot that has both a border and a fill, like shapes 21-25, so use one of those.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;stroke&lt;/code&gt; aesthetic mapping (meaning the stroke will change according to a value in the data) to set a different stroke size based on murders &lt;em&gt;per capita&lt;/em&gt;. You can create a murders per capita variable on the fly, or add it to your &lt;code&gt;murders&lt;/code&gt; data.
&lt;ul&gt;
&lt;li&gt;Include the text labels as before and use &lt;code&gt;nudge_x = 1.5&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Make sure you’re only setting the aesthetic for the points on the scatterplot!&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;angle&lt;/code&gt; aesthetic
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Using the &lt;code&gt;?geom_text&lt;/code&gt; help, note that &lt;code&gt;geom_text&lt;/code&gt; takes an aesthetic of &lt;code&gt;angle&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;angle&lt;/code&gt; aesthetic (not aesthetic mapping) in the appropriate place (e.g. on &lt;code&gt;geom_text&lt;/code&gt; and not on other geometries) to adjust the labels on our plot.&lt;/li&gt;
&lt;li&gt;Now, try using the &lt;code&gt;angle&lt;/code&gt; aesthetic mapping by using the &lt;code&gt;total&lt;/code&gt; field as both the &lt;code&gt;y&lt;/code&gt; value &lt;strong&gt;and&lt;/strong&gt; the &lt;code&gt;angle&lt;/code&gt; value in the &lt;code&gt;geom_text&lt;/code&gt; layer.&lt;/li&gt;
&lt;li&gt;Does using &lt;code&gt;angle&lt;/code&gt; as an aesthetic help? What about as an aesthetic mapping?&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;color&lt;/code&gt; aesthetic mapping
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Set the &lt;code&gt;color&lt;/code&gt; aesthetic mapping in &lt;code&gt;geom_text&lt;/code&gt; to &lt;code&gt;total/population&lt;/code&gt;.
&lt;ul&gt;
&lt;li&gt;Use the &lt;code&gt;nudge_x = 1.5&lt;/code&gt; aesthetic in &lt;code&gt;geom_text&lt;/code&gt; still&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Try it with and without the legend using &lt;code&gt;show.legend&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Be able to explain the plot.
&lt;ul&gt;
&lt;li&gt;Does the &lt;code&gt;color&lt;/code&gt; aesthetic mapping help present the data here?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geom_label&lt;/code&gt; and the &lt;code&gt;fill&lt;/code&gt; aesthetic
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Looking at &lt;code&gt;?geom_label&lt;/code&gt; (which is the same help as &lt;code&gt;geom_text&lt;/code&gt;), we note that “The &lt;code&gt;fill&lt;/code&gt; aesthetic controls the backgreound colour of the label”.&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;fill&lt;/code&gt; aesthetic mapping to &lt;code&gt;total/population&lt;/code&gt; in &lt;code&gt;geom_label&lt;/code&gt; (replacing &lt;code&gt;geom_text&lt;/code&gt; but still using &lt;code&gt;nudge_x=1.5&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Set the &lt;code&gt;fill&lt;/code&gt; aesthetic (not mapping) to the color of your choice.&lt;/li&gt;
&lt;li&gt;Be able to explain the plots.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Does the &lt;code&gt;fill&lt;/code&gt; aesthetic mapping help present the data here?&lt;/li&gt;
&lt;li&gt;What color did you choose for the non-mapped fill aesthetic?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;some-quirky-stuff&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Some Quirky Stuff&lt;/h2&gt;
&lt;p&gt;Load up our &lt;code&gt;murders&lt;/code&gt; data&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
library(ggplot2)
library(dplyr)
data(murders)
p &amp;lt;- ggplot(data = murders, aes(x = population, y = total, label = abb))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;scales-and-transformations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scales and transformations&lt;/h2&gt;
&lt;div id=&#34;log-transformations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Log transformations&lt;/h3&gt;
&lt;p&gt;Last lecture, we re-scaled our population by 10^6 (millions), but still had a lot of variation because some states are tiny and some are huge. Sometimes, we want to have one (or both) of our axes scaled non-linearly. For instance, if we wanted to have our x-axis be in log base 10, then each major tick would represent a factor of 10 over the last. This is not the default, so this change needs to be added through a &lt;em&gt;scales&lt;/em&gt; layer. A quick look at the cheat sheet reveals the &lt;code&gt;scale_x_continuous&lt;/code&gt; function lets us control the behavior of scales. We use them like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(size = 3) +
  geom_text(nudge_x = 0.05) +
  scale_x_continuous(trans = &amp;quot;log10&amp;quot;) +
  scale_y_continuous(trans = &amp;quot;log10&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/ggplot-example-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A couple of things here: adding things like &lt;code&gt;scale_x_continuous(...)&lt;/code&gt; operates on the whole plot. In some cases, order matters, but it doesn’t here, so we can throw &lt;code&gt;scale_x_continuous&lt;/code&gt; anywhere. Because we have altered the whole plot’s scale to be in the log-scale now, the &lt;em&gt;nudge&lt;/em&gt; must be made smaller. It is in log-base-10 units. Using &lt;code&gt;?scale_x_continuous&lt;/code&gt; brings us to the help for both &lt;code&gt;scale_x_continuous&lt;/code&gt; and &lt;code&gt;scale_y_continuous&lt;/code&gt;, which shows us the options for transformations &lt;code&gt;trans = ...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This particular transformation is so common that &lt;strong&gt;ggplot2&lt;/strong&gt; provides the specialized functions &lt;code&gt;scale_x_log10&lt;/code&gt; and &lt;code&gt;scale_y_log10&lt;/code&gt; which “inherit” (take the place of) the &lt;code&gt;scale_x_continuous&lt;/code&gt; functions but have log base 10 as default. We can use these to rewrite the code like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(size = 3) +
  geom_text(nudge_x = 0.05) +
  scale_x_log10() +
  scale_y_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This can make a plot much easier to read, though one has to be sure to pay attention to the values on the axes. Plotting anything with very large outliers will almost always be better if done in log-scale. Adding the scale layer is an easy way to fix this.&lt;/p&gt;
&lt;p&gt;We can also use one of many built-in transformations. Of note: &lt;strong&gt;reverse&lt;/strong&gt; just inverts the scale, which can be helpful, &lt;strong&gt;log&lt;/strong&gt; uses the natural log, &lt;strong&gt;sqrt&lt;/strong&gt; takes the square root (dropping anything with a negative value), &lt;strong&gt;reciprocal&lt;/strong&gt; takes 1/x. If your x-axis is in a date format, you can also scale to &lt;strong&gt;hms&lt;/strong&gt; (hour-minute-second) or &lt;strong&gt;date&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;transforming-data-vs.-transforming-using-scale_...&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Transforming data vs. transforming using &lt;code&gt;scale_...&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;We could simply take the log of population and log of total in the call and we’d get something very similar. Note that we had to override the aesthetic mapping set in &lt;code&gt;p&lt;/code&gt; in each of the geometries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(x = log(population, base=10), y = log(total, base=10)), size = 3) +
  geom_text(aes(x = log(population, base=10), y = log(total, base=10)), nudge_x = 0.05)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This avoids using &lt;code&gt;scale_x_continuous&lt;/code&gt; or it’s child function &lt;code&gt;scale_x_log10&lt;/code&gt;. One advantage to using &lt;code&gt;scale_x...&lt;/code&gt; is that the axes are correctly labeled. When we transform the data directly, the axis labels only show the transformed values, so 7,000,000 becomes 7.0. This could be confusing! We could update the axis labels to say “total murders (log base 10)” and “total population (log base 10)”, but that’s cumbersome. Using &lt;code&gt;scale_x...&lt;/code&gt; is a lot more refined and easy.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;axis-labels-legends-and-titles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Axis labels, legends, and titles&lt;/h2&gt;
&lt;p&gt;But let’s say we did want to re-name our x-axis label. Or maybe we don’t like that the variable column name is lower-case “p”.&lt;/p&gt;
&lt;p&gt;As with many things in &lt;code&gt;ggplot&lt;/code&gt;, there are many ways to get the same result. We’ll go over one way of changing titles and labels, but know that there are many more.&lt;/p&gt;
&lt;div id=&#34;changing-axis-titles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Changing axis titles&lt;/h3&gt;
&lt;p&gt;We’ll use the &lt;code&gt;labs(...)&lt;/code&gt; annotation layer to do this, which is pretty straightforward. &lt;code&gt;?labs&lt;/code&gt; shows us what we can change, and while it looks pretty basic, the real meat is in the &lt;code&gt;...&lt;/code&gt; argument, which the help says is “A list of new name-value pairs”. This means we can re-define the label on anything that is an aesthetic mapping. X and Y are aesthetic mappings, so…&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(size = 3) +
  geom_text(nudge_x = 0.05) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, let’s use an aesthetic mapping that generates a legend, like &lt;code&gt;color&lt;/code&gt;, and see what &lt;code&gt;labs&lt;/code&gt; renames:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(color = region), size = 3) +
  geom_text(nudge_x = 0.05) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;, color = &amp;#39;US Region&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;
We can rename the aesthetic mapping-relevant label using &lt;code&gt;labs&lt;/code&gt;. Even if there are multiple mapped aesthetics:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(color = region, size = total/population)) +
  geom_text(nudge_x = 0.05) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;, color = &amp;#39;US Region&amp;#39;, size = &amp;#39;Murder rate&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;titles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Titles&lt;/h3&gt;
&lt;p&gt;In &lt;code&gt;?labs&lt;/code&gt;, we also see some things that look like titles and captions. We can include those:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(color = region, size = total/population)) +
  geom_text(nudge_x = 0.05) +
  scale_x_log10() +
  scale_y_log10() +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;, color = &amp;#39;US Region&amp;#39;, size = &amp;#39;Murder rate&amp;#39;,
       title = &amp;#39;This is a title&amp;#39;, subtitle = &amp;#39;This is a subtitle&amp;#39;, caption = &amp;#39;This is a caption&amp;#39;, tag = &amp;#39;This is a tag&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now that you know how, &lt;strong&gt;always label your plots with at least a title and have meaningful axis and legend labels&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;axis-ticks&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Axis ticks&lt;/h2&gt;
&lt;p&gt;In addition to the axis labels, we may want to format or change the axis tick labels (like “1e+06” above) or even where the tick marks and lines are drawn. If we don’t specify anything, the axis labels and tick marks are drawn as best as &lt;code&gt;ggplot&lt;/code&gt; can do, but we can change this. This might be especially useful if our data has some meaningful cutoffs that aren’t found by the default, or we just don’t like where the marks fall or how they are labeled. This is easy to fix with &lt;code&gt;ggplot&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To change the tick mark labels, we have to set the tick mark locations. Then we can set a label for each tick mark. Let’s go back to our &lt;code&gt;murders&lt;/code&gt; data and, for simplicity, take the log transformation off the Y axis. We’ll use &lt;code&gt;scale_y_continuous&lt;/code&gt; to tell R &lt;em&gt;where&lt;/em&gt; to put the breaks (&lt;code&gt;breaks =&lt;/code&gt;) and &lt;em&gt;what to label&lt;/em&gt; the breaks. We have to give it one label for every break. Let’s say we just want a line at the 500’s and let’s say we want to (absurdly) use written numerics for each of the Y-axis lines. Since &lt;code&gt;scale_y_log10&lt;/code&gt; &lt;strong&gt;inherits from&lt;/strong&gt; &lt;code&gt;scale_y_continuous&lt;/code&gt;, we can just use that and add the breaks and labels:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(color = region), size = 3) +
  geom_text(nudge_x = .05) +
  scale_x_log10() +
  scale_y_log10(breaks = c(0,50, 100, 500,1000,1500),
                     labels = c(&amp;#39;Zero&amp;#39;,&amp;#39;Fifty&amp;#39;,&amp;#39;One hundred&amp;#39;,&amp;#39;Five hundred&amp;#39;,&amp;#39;One thousand&amp;#39;,&amp;#39;Fifteen hundred&amp;#39;)) +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;, color = &amp;#39;US Region&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;
We have manually set both the location and the label for the y-axis. Note that R filled in the in-between “minor” tick lines, but we can take those out. Since we are setting the location of the lines, we can do anything we want:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(color = region), size = 3) +
  geom_text(nudge_x = .05) +
  scale_x_log10() +
  scale_y_log10(breaks = c(0,50, 100, 721, 1000,1500),
                     labels = c(&amp;#39;Zero&amp;#39;,&amp;#39;Fifty&amp;#39;,&amp;#39;One hundred&amp;#39;,&amp;#39;Seven hundred twenty one&amp;#39;,&amp;#39;One thousand&amp;#39;,&amp;#39;Fifteen hundred&amp;#39;),
                     minor_breaks = NULL) +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;, color = &amp;#39;US Region&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So we can now define where axis tick lines should lie and how they should be labeled.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;additional-geometries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Additional geometries&lt;/h2&gt;
&lt;p&gt;Let’s say we are happy with our axis tick locations, but we want to add a single additional line. Maybe we want to divide at 1,000,000 population (a vertical line at 1,000,000) becuase we think those over 1,000,000 are somehow different, and we want to call attention to the data around that point. As a more general example, if we were to plot, say, car accidents by age, we would maybe want to label age 21, when people can legally purchase alcohol (and subsequently cause car accidents).&lt;/p&gt;
&lt;p&gt;This brings us to our first additional geometry beyond &lt;code&gt;geom_point&lt;/code&gt; (OK, we used &lt;code&gt;geom_text&lt;/code&gt;, but that’s more of an annotation). &lt;code&gt;geom_vline&lt;/code&gt; lets us add a single vertical line (without aesthetic mappings). If we look at &lt;code&gt;?geom_vline&lt;/code&gt; we see that it requires ones aesthetic:&lt;code&gt;xintercept&lt;/code&gt;. It also takes aesthetics like color and size, and introduces the &lt;code&gt;linetype&lt;/code&gt; aesthetic:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p + geom_point(aes(color = region), size = 3) +
  geom_text(nudge_x = .05) +
  geom_vline(aes(xintercept = 1000000), col = &amp;#39;red&amp;#39;, size = 2, linetype = 2) +
  scale_x_log10() +
  scale_y_log10(breaks = c(0,50, 100, 721, 1000,1500),
                     labels = c(&amp;#39;Zero&amp;#39;,&amp;#39;Fifty&amp;#39;,&amp;#39;One hundred&amp;#39;,&amp;#39;Seven hundred twenty one&amp;#39;,&amp;#39;One thousand&amp;#39;,&amp;#39;Fifteen hundred&amp;#39;),
                     minor_breaks = NULL) +
  labs(x = &amp;#39;Population&amp;#39;, y = &amp;#39;Total murders&amp;#39;, color = &amp;#39;US Region&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Combining geometries is as easy as adding the layers with &lt;code&gt;+&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;geom_line&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;geom_line&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;For a good old line plot, we use the line geometry at &lt;code&gt;geom_line&lt;/code&gt;. The help for &lt;code&gt;?geom_line&lt;/code&gt; tells us that we need an x and a y aesthetic (much like &lt;code&gt;geom_points&lt;/code&gt;). Since our &lt;code&gt;murders&lt;/code&gt; data isn’t really suited to a line graph, we’ll use a daily stock price. We’ll get this using &lt;code&gt;tidyquant&lt;/code&gt;, which pulls stock prices from Yahoo Finance and maintains the “tidy” format. You’ll need to &lt;code&gt;install.packages(&#39;tidyquant&#39;)&lt;/code&gt; before you run this the first time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyquant)
AAPL = tq_get(&amp;quot;AAPL&amp;quot;, from = &amp;#39;2009-01-01&amp;#39;, to = &amp;#39;2021-08-01&amp;#39;, get = &amp;#39;stock.prices&amp;#39;)
head(AAPL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 8
##   symbol date        open  high   low close     volume adjusted
##   &amp;lt;chr&amp;gt;  &amp;lt;date&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1 AAPL   2009-01-02  3.07  3.25  3.04  3.24  746015200     2.78
## 2 AAPL   2009-01-05  3.33  3.44  3.31  3.38 1181608400     2.90
## 3 AAPL   2009-01-06  3.43  3.47  3.30  3.32 1289310400     2.85
## 4 AAPL   2009-01-07  3.28  3.30  3.22  3.25  753048800     2.79
## 5 AAPL   2009-01-08  3.23  3.33  3.22  3.31  673500800     2.84
## 6 AAPL   2009-01-09  3.33  3.34  3.22  3.24  546845600     2.78&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we can plot a line graph of the Apple closing stock price over the requested date range. We want this to be a time series, so the x-axis will be the date and the y-axis will be the closing price.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(AAPL, aes(x = date, y = close)) +
  geom_line() +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/geomPath-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;geom_line&lt;/code&gt;, R will automatically sort on the x-variable. If you don’t want this, then &lt;code&gt;geom_path&lt;/code&gt; will use whatever order the data is in. Either way, if you have multiple observations for the same value on the x-axis, then you’ll get something pretty messy because R will try to connect, in some order, all the points. Let’s see an example with two stocks:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AAPLNFLX = tq_get(c(&amp;quot;AAPL&amp;quot;,&amp;quot;NFLX&amp;quot;), from = &amp;#39;2021-01-01&amp;#39;, to = &amp;#39;2021-08-01&amp;#39;, get = &amp;#39;stock.prices&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `type_convert()` only converts columns of type &amp;#39;character&amp;#39;.
## - `df` has no columns of type &amp;#39;character&amp;#39;

## Warning: `type_convert()` only converts columns of type &amp;#39;character&amp;#39;.
## - `df` has no columns of type &amp;#39;character&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(AAPLNFLX, aes(x = date, y = close)) +
  geom_line() +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple and Netflix stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That looks kinda strange. That’s because, for every date, we have two values - the NFLX and the AAPL value, so each day has a vertical line drawn between the two prices. This is nonsense, especially since what we want to see is the history of NFLX and AAPL over time.&lt;/p&gt;
&lt;p&gt;Aesthetics to the rescue! Remember, when we use an aesthetic mapping, we are able to separate out data by things like color or linetype. Let’s use color as the aesthetic here, and map it to the stock ticker:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AAPLNFLX = tq_get(c(&amp;quot;AAPL&amp;quot;,&amp;quot;NFLX&amp;quot;), from = &amp;#39;2021-01-01&amp;#39;, to = &amp;#39;2021-08-01&amp;#39;, get = &amp;#39;stock.prices&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `type_convert()` only converts columns of type &amp;#39;character&amp;#39;.
## - `df` has no columns of type &amp;#39;character&amp;#39;

## Warning: `type_convert()` only converts columns of type &amp;#39;character&amp;#39;.
## - `df` has no columns of type &amp;#39;character&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(AAPLNFLX, aes(x = date, y = close, color = symbol)) +
  geom_line() +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple and Netflix stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-23-1.png&#34; width=&#34;672&#34; /&gt;
Well there we go! We can now see each stock price over time, with a convenient legend. Later on, we’ll learn how to change the color palatte. If we don’t necessarily want a different color but we do want to separate the lines, we can use the &lt;code&gt;group&lt;/code&gt; aesthetic.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;AAPLNFLX = tq_get(c(&amp;quot;AAPL&amp;quot;,&amp;quot;NFLX&amp;quot;), from = &amp;#39;2021-01-01&amp;#39;, to = &amp;#39;2021-08-01&amp;#39;, get = &amp;#39;stock.prices&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: `type_convert()` only converts columns of type &amp;#39;character&amp;#39;.
## - `df` has no columns of type &amp;#39;character&amp;#39;

## Warning: `type_convert()` only converts columns of type &amp;#39;character&amp;#39;.
## - `df` has no columns of type &amp;#39;character&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(AAPLNFLX, aes(x = date, y = close, group = symbol)) +
  geom_line() +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple and Netflix stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Similar result as &lt;code&gt;geom_line&lt;/code&gt;, but without the color difference (which makes it rather hard to tell what you’re looking at). But if we add labels using &lt;code&gt;geom_label&lt;/code&gt;, we’ll get one label for every point, which will be overwhelming. The solution? Use some filtered data so that there is only one point for each label. But that means replacing the &lt;code&gt;data&lt;/code&gt; in &lt;code&gt;ggplot&lt;/code&gt;. Here’s how.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-different-data-with-different-geometries&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using different data with different geometries&lt;/h3&gt;
&lt;p&gt;Just as we can use different aesthetic mappings on each geometry, we can use different &lt;em&gt;data&lt;/em&gt; entirely. This is useful when we want one geometry to have one set of data (like the stock prices above), but another geometry to only have a subset of the data. Why would we want that? Well, we’d like to label just &lt;em&gt;one&lt;/em&gt; part of each of the lines in our plot, right? That means we want to label a &lt;em&gt;subset&lt;/em&gt; of the stock data.&lt;/p&gt;
&lt;p&gt;To replace data in a geometry, we just need to specify the &lt;code&gt;data =&lt;/code&gt; argument separately:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(AAPLNFLX, aes(x = date, y = close, group = symbol)) +
  geom_line() +
  geom_label(data = AAPLNFLX %&amp;gt;% group_by(symbol) %&amp;gt;% slice(100),
             aes(label = symbol),
             nudge_y = 20) +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple and Netflix stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-25-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In &lt;code&gt;geom_label&lt;/code&gt;, we specified we wanted the 100th observation from each symbol to be the label location. Then, we nudged it up along y by 20 so that it’s clear of the line.&lt;/p&gt;
&lt;p&gt;R also has a very useful &lt;code&gt;ggrepel&lt;/code&gt; package that gives us &lt;code&gt;geom_label_repel&lt;/code&gt; which takes care of the nudging for us, even in complicated situations (lots of points, lines, etc.). It does a decent job here of moving the label to a point where it doesn’t cover a lot of data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggrepel)
ggplot(AAPLNFLX, aes(x = date, y = close, group = symbol)) +
  geom_line() +
  geom_label_repel(data = AAPLNFLX %&amp;gt;% group_by(symbol) %&amp;gt;% slice(100),
             aes(label = symbol)) +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple and Netflix stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now, we don’t lose a lot of space to a legend, and we haven’t had to use color to separate the stock symbols.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiple-geometries&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiple geometries&lt;/h3&gt;
&lt;p&gt;Since this section is about adding geometries, we &lt;em&gt;can&lt;/em&gt; combine points and lines. Since lines connect points, it will look like a giant connect-the-dots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggrepel)
ggplot(AAPLNFLX, aes(x = date, y = close, group = symbol)) +
  geom_line() +
  geom_point() +
  geom_label_repel(data = AAPLNFLX %&amp;gt;% group_by(symbol) %&amp;gt;% slice(100),
             aes(label = symbol)) +
  labs(x = &amp;#39;Date&amp;#39;, y = &amp;#39;Closing price&amp;#39;, title = &amp;#39;Apple and Netflix stock price&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/03-content_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;try-it-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Try it!&lt;/h2&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Start by loading the &lt;strong&gt;dplyr&lt;/strong&gt; and &lt;strong&gt;ggplot2&lt;/strong&gt; library as well as the &lt;code&gt;murders&lt;/code&gt; and &lt;code&gt;heights&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(ggplot2)
library(dslabs)
data(heights)
data(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;With &lt;strong&gt;ggplot2&lt;/strong&gt; plots can be saved as objects. For example we can associate a dataset with a plot object like this&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(data = murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because &lt;code&gt;data&lt;/code&gt; is the first argument we don’t need to spell it out&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and we can also use the pipe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- murders %&amp;gt;% ggplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is class of the object &lt;code&gt;p&lt;/code&gt;?&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Remember that to print an object you can use the command &lt;code&gt;print&lt;/code&gt; or simply type the object.
Print the object &lt;code&gt;p&lt;/code&gt; defined in exercise one and describe what you see.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Nothing happens.&lt;/li&gt;
&lt;li&gt;A blank slate plot.&lt;/li&gt;
&lt;li&gt;A scatterplot.&lt;/li&gt;
&lt;li&gt;A histogram.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Using the pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt;, create an object &lt;code&gt;p&lt;/code&gt; but this time associated with the &lt;code&gt;heights&lt;/code&gt; dataset instead of the &lt;code&gt;murders&lt;/code&gt; dataset.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the class of the object &lt;code&gt;p&lt;/code&gt; you have just created?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now we are going to add a layer and the corresponding aesthetic mappings. For the murders data we plotted total murders versus population sizes. Explore the &lt;code&gt;murders&lt;/code&gt; data frame to remind yourself what are the names for these two variables and select the correct answer. &lt;strong&gt;Hint&lt;/strong&gt;: Look at &lt;code&gt;?murders&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;state&lt;/code&gt; and &lt;code&gt;abb&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;total_murders&lt;/code&gt; and &lt;code&gt;population_size&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;total&lt;/code&gt; and &lt;code&gt;population&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;murders&lt;/code&gt; and &lt;code&gt;size&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;To create the scatterplot we add a layer with &lt;code&gt;geom_point&lt;/code&gt;. The aesthetic mappings require us to define the x-axis and y-axis variables, respectively. So the code looks like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% ggplot(aes(x = , y = )) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;except we have to define the two variables &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;. Fill this out with the correct variable names.&lt;/p&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Note that if we don’t use argument names, we can obtain the same plot by making sure we enter the variable names in the right order like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% ggplot(aes(population, total)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remake the plot but now with total in the x-axis and population in the y-axis.&lt;/p&gt;
&lt;ol start=&#34;8&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;If instead of points we want to add text, we can use the &lt;code&gt;geom_text()&lt;/code&gt; or &lt;code&gt;geom_label()&lt;/code&gt; geometries. The following code&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% ggplot(aes(population, total)) + geom_label()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;will give us the error message: &lt;code&gt;Error: geom_label requires the following missing aesthetics: label&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Why is this?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;We need to map a character to each point through the label argument in aes.&lt;/li&gt;
&lt;li&gt;We need to let &lt;code&gt;geom_label&lt;/code&gt; know what character to use in the plot.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;geom_label&lt;/code&gt; geometry does not require x-axis and y-axis values.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geom_label&lt;/code&gt; is not a ggplot2 command.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;9&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Rewrite the code above to use abbreviation as the label through &lt;code&gt;aes&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Change the color of the labels to blue. How will we do this?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Adding a column called &lt;code&gt;blue&lt;/code&gt; to &lt;code&gt;murders&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Because each label needs a different color we map the colors through &lt;code&gt;aes&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;color&lt;/code&gt; argument in &lt;code&gt;ggplot&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Because we want all colors to be blue, we do not need to map colors, just use the color argument in &lt;code&gt;geom_label&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;11&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Rewrite the code above to make the labels blue.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now suppose we want to use color to represent the different regions. In this case which of the following is most appropriate:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Adding a column called &lt;code&gt;color&lt;/code&gt; to &lt;code&gt;murders&lt;/code&gt; with the color we want to use.&lt;/li&gt;
&lt;li&gt;Because each label needs a different color we map the colors through the color argument of &lt;code&gt;aes&lt;/code&gt; .&lt;/li&gt;
&lt;li&gt;Use the &lt;code&gt;color&lt;/code&gt; argument in &lt;code&gt;ggplot&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Because we want all colors to be blue, we do not need to map colors, just use the color argument in &lt;code&gt;geom_label&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;13&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Rewrite the code above to make the labels’ color be determined by the state’s region.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now we are going to change the x-axis to a log scale to account for the fact the distribution of population is skewed. Let’s start by defining an object &lt;code&gt;p&lt;/code&gt; holding the plot we have made up to now&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- murders %&amp;gt;%
  ggplot(aes(population, total, label = abb, color = region)) +
  geom_label()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To change the y-axis to a log scale we learned about the &lt;code&gt;scale_x_log10()&lt;/code&gt; function. Add this layer to the object &lt;code&gt;p&lt;/code&gt; to change the scale and render the plot.&lt;/p&gt;
&lt;ol start=&#34;15&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Repeat the previous exercise but now change both axes to be in the log scale.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now edit the code above to add the title “Gun murder data” to the plot. Hint: use the &lt;code&gt;labs&lt;/code&gt; function or the &lt;code&gt;ggtitle&lt;/code&gt; function.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://ggplot2.tidyverse.org/&#34; class=&#34;uri&#34;&gt;https://ggplot2.tidyverse.org/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://www.springer.com/us/book/9780387245447&#34; class=&#34;uri&#34;&gt;http://www.springer.com/us/book/9780387245447&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/rstudio/cheatsheets&#34; class=&#34;uri&#34;&gt;https://github.com/rstudio/cheatsheets&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/rstudio/cheatsheets/blob/master/LICENSE&#34; class=&#34;uri&#34;&gt;https://github.com/rstudio/cheatsheets/blob/master/LICENSE&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to the tidyverse</title>
      <link>https://ssc442.netlify.app/content/02-content/</link>
      <pubDate>Tue, 07 Sep 2021 00:00:00 +0000</pubDate>
      <guid>https://ssc442.netlify.app/content/02-content/</guid>
      <description>
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#readings&#34;&gt;Readings&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#guiding-question&#34;&gt;Guiding Question&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#final-projects&#34;&gt;Final Projects&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#teams&#34;&gt;Teams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#randomness-and-data-analytics&#34;&gt;Randomness and Data Analytics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#learning-from-data&#34;&gt;Learning From Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#formalization&#34;&gt;Formalization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-target-function&#34;&gt;The Target Function&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why-estimate-an-unknown-function&#34;&gt;Why Estimate an Unknown Function?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-parable-of-the-marbles&#34;&gt;The Parable of the Marbles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#outside-the-data&#34;&gt;Outside the Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#hoeffdings-inequality&#34;&gt;Hoeffding’s Inequality&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#an-example-of-hoeffdings-inequality&#34;&gt;An example of Hoeffding’s Inequality&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidyverse&#34;&gt;The tidyverse&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tidy-data&#34;&gt;Tidy data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#manipulating-data-frames&#34;&gt;Manipulating data frames&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#adding-a-column-with-mutate&#34;&gt;Adding a column with &lt;code&gt;mutate&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting-with-filter&#34;&gt;Subsetting with &lt;code&gt;filter&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#selecting-columns-with-select&#34;&gt;Selecting columns with &lt;code&gt;select&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-pipe&#34;&gt;The pipe: &lt;code&gt;%&amp;gt;%&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#summarizing-data&#34;&gt;Summarizing data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#summarize&#34;&gt;&lt;code&gt;summarize&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pull&#34;&gt;&lt;code&gt;pull&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#group-by&#34;&gt;Group then summarize with &lt;code&gt;group_by&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sorting-data-frames&#34;&gt;Sorting data frames&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#nested-sorting&#34;&gt;Nested sorting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-top-n&#34;&gt;The top &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tibbles&#34;&gt;Tibbles&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#tibbles-display-better&#34;&gt;Tibbles display better&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsets-of-tibbles-are-tibbles&#34;&gt;Subsets of tibbles are tibbles&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tibbles-can-have-complex-entries&#34;&gt;Tibbles can have complex entries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tibbles-can-be-grouped&#34;&gt;Tibbles can be grouped&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-tibble-using-tibble-instead-of-data.frame&#34;&gt;Create a tibble using &lt;code&gt;tibble&lt;/code&gt; instead of &lt;code&gt;data.frame&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-dot-operator&#34;&gt;The dot operator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#do&#34;&gt;&lt;code&gt;do&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-purrr-package&#34;&gt;The &lt;strong&gt;purrr&lt;/strong&gt; package&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tidyverse-conditionals&#34;&gt;Tidyverse conditionals&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#case_when&#34;&gt;&lt;code&gt;case_when&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#between&#34;&gt;&lt;code&gt;between&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lecture-video&#34;&gt;Lecture Video&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;readings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Readings&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This page.&lt;/li&gt;
&lt;li&gt;Chapter 1 of Introduction to Statistical Learning, available &lt;a href=&#34;https://www.statlearning.com/&#34;&gt;here.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Optional: The “Tidy Your Data” tutorial on &lt;a href=&#34;https://rstudio.cloud/learn/primers&#34;&gt;Rstudio Clould Primers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;guiding-question&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Guiding Question&lt;/h3&gt;
&lt;p&gt;For future lectures, the guiding questions will be more pointed and at a higher level to help steer your thinking. Here, we want to ensure you remember some basics and accordingly the questions are straightforward.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Why do we want tidy data?&lt;/li&gt;
&lt;li&gt;What are the challenges associated with shaping things into a tidy format?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;final-projects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Final Projects&lt;/h2&gt;
&lt;p&gt;Your final is a group project. Accordingly, you need to start planning soon.&lt;/p&gt;
&lt;p&gt;To aid in your planning, here are the required elements of your project (&lt;strong&gt;note: the assignment that currently exists on this site, if you find it, is old and will change a lot between now and next week&lt;/strong&gt;).&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;You must find existing data to analyze. Aggregating and merging data from multiple sources is encouraged.&lt;/li&gt;
&lt;li&gt;You must visualize 3 intersting features of that data.&lt;/li&gt;
&lt;li&gt;You must come up with some analysis—using tools from this course—which relates your data to either a prediction or a policy conclusion.&lt;/li&gt;
&lt;li&gt;You must think critically about your analysis and be able to identify potential issues/&lt;/li&gt;
&lt;li&gt;You must present your analysis as if presenting to a C-suite executive.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you have any additional questions, you can find some more information in the Assignments section of this website.&lt;/p&gt;
&lt;div id=&#34;teams&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Teams&lt;/h3&gt;
&lt;p&gt;You must form teams of 3-4 people. I will send out a survey link via email to better understand your teams. If you are in a group (and everyone agrees you’re in a group) then only one of you needs to respond to the survey.&lt;/p&gt;
&lt;p&gt;If you are not listed on another person’s team and do not respond to the survey, I will interpret this as evidence that you have opted to not form a team—or you like adventure! Accordingly, you will be automatically added to the “willing to be randomly assigned” pool and will be paired with others in the class.&lt;/p&gt;
&lt;div id=&#34;more-information-on-teams&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;More Information on Teams&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;You should strongly consider coordinating your work via Github.&lt;/li&gt;
&lt;li&gt;Your team will earn the same scores on all projects. (Note that projects are not labs / writings. They are the shorter two projects and the final project.)&lt;/li&gt;
&lt;li&gt;Teams will submit only one write-up for the mini-projects and the final.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To combat additional freeloading, we will use a reporting system. We’ll discuss that a bit later.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;randomness-and-data-analytics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Randomness and Data Analytics&lt;/h2&gt;
&lt;p&gt;And the fabulous importance of probabilistic inference…&lt;/p&gt;
&lt;p&gt;This lecture is very “high-level,” which means it is talking about abstract concepts. It is also quite important. We want to discuss &lt;strong&gt;why&lt;/strong&gt; we eventually will need ot utilize tons of difficult mathematics. Why do we care so much about hypothesis tests and the like? Moreover, we can highlight why we want our data structured to behave nicely.&lt;/p&gt;
&lt;div id=&#34;learning-from-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Learning From Data&lt;/h3&gt;
&lt;p&gt;The following are the baisc requirements for statistical learning&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;A pattern exists.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This pattern is not easily expressed in a closed mathematical form.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You have data.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;formalization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Formalization&lt;/h3&gt;
&lt;p&gt;We think of our outcome-of-interest as a &lt;strong&gt;reponse&lt;/strong&gt; or &lt;strong&gt;target&lt;/strong&gt; that we wish to predict or wish to learn something about.&lt;/p&gt;
&lt;p&gt;We generically refer to the response as &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Other aspects of the data are known as &lt;strong&gt;features, inputs, predictors&lt;/strong&gt;, or &lt;strong&gt;regressors&lt;/strong&gt;. We call one of these &lt;span class=&#34;math inline&#34;&gt;\(X_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The subscript &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; indicates that we have an &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; realized for every individual in our data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can refer to the input vector collectively as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[X = \begin{bmatrix}
x_{11} &amp;amp; x_{12} \\
x_{21} &amp;amp; x_{22} \\
\vdots &amp;amp; \vdots \\
x_{N1} &amp;amp; x_{N2}
\end{bmatrix}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We are seeking some unknown function that maps &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Put another way, we are seeking to explain &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[Y = f(X) + e\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-target-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Target Function&lt;/h3&gt;
&lt;p&gt;We call the function &lt;span class=&#34;math inline&#34;&gt;\(f: \mathcal{X} \rightarrow \mathcal{Y}\)&lt;/span&gt; the &lt;strong&gt;target function&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;How do we find the function? We don’t! We get as close as we can, though:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Observe data &lt;span class=&#34;math inline&#34;&gt;\((\mathbf{x}_1, y_1), \cdots, (\mathbf{x}_N, y_N)\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use some algorithm to approximate &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Produce final hypothesis function &lt;span class=&#34;math inline&#34;&gt;\(g \approx f\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Evaluate how well &lt;span class=&#34;math inline&#34;&gt;\(g\)&lt;/span&gt; approximates &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; and iterate as needed.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;why-estimate-an-unknown-function&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Why Estimate an Unknown Function?&lt;/h3&gt;
&lt;p&gt;With a good estimate of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; we can make predictions of &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; at &lt;strong&gt;new&lt;/strong&gt; points &lt;span class=&#34;math inline&#34;&gt;\(X = x\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can also understand which components of &lt;span class=&#34;math inline&#34;&gt;\(X = (X_1, X_2, \cdots, X_m)\)&lt;/span&gt; are important in explaining &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;, and which are (potentially) irrelevant&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;e.g. &lt;code&gt;GDP&lt;/code&gt; and &lt;code&gt;yearsindustrialized&lt;/code&gt; have a big impact on &lt;code&gt;emissions&lt;/code&gt; but &lt;code&gt;hydroutilization&lt;/code&gt; typically does not.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Depending on the complexity of &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;, we may be able to meaningfully understand how each component of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; affects &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;(But we should be careful about assigning causal interpretations, more on this later)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-parable-of-the-marbles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Parable of the Marbles&lt;/h3&gt;
&lt;p&gt;Imagine a bag of marbles with two types of marbles: ♣️ and ♦️.&lt;/p&gt;
&lt;p&gt;We are going to pick a &lt;strong&gt;sample&lt;/strong&gt; of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; marbles (with replacement).&lt;/p&gt;
&lt;p&gt;We want to learn something about &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, the &lt;strong&gt;objective&lt;/strong&gt; probability to pick a ♣️.&lt;/p&gt;
&lt;p&gt;In addition to defining the &lt;strong&gt;objective&lt;/strong&gt; probability of picking a ♣️, we have an observed fraction &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;, which will define as the fraction of ♣️ in the &lt;em&gt;sample&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Can we say anything exact and for-sure about &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; (outside the data) after observing &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; (the data)?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;No. It is possible for the sample to be all ♣️, ♣️, ♣️, ♣️, ♣️ even when the bag is is 50/50 ♦️&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;No matter what we draw, we can’t (based on that draw alone) eliminate the possibility of drawing a ♦️.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;And unless we assume that the only two values in the world are ♦️ and ♣️, we can’t rule out 💩&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;: Then why do we do things like polling (e.g. to predict the outcome of a presidential election)?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The bad case, that we draw something that has is completely misleading, is &lt;em&gt;possible&lt;/em&gt; but not &lt;strong&gt;probable&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;outside-the-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Outside the Data&lt;/h3&gt;
&lt;p&gt;Put another way, since &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; is unknown, it can take on any value outside the data we have, no matter how large the data.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is called &lt;em&gt;No Free Lunch&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You cannot know anything for sure about &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; outside the data without making assumptions.&lt;/p&gt;
&lt;p&gt;Is there any hope to know anything about &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt; outside the data set without making assumptions about &lt;span class=&#34;math inline&#34;&gt;\(f\)&lt;/span&gt;?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Yes&lt;/strong&gt;, if we are willing to give up the “for sure”&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hoeffdings-inequality&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Hoeffding’s Inequality&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Hoeffding’s Inequality&lt;/strong&gt; states, loosely, that &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; cannot be too far from &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mathbb{P}\left[|\eta - \mu| &amp;gt; \epsilon \right] \leq 2e^{-2\epsilon^2n}\]&lt;/span&gt;
&lt;span class=&#34;math inline&#34;&gt;\(\eta \approx \mu\)&lt;/span&gt; is called &lt;strong&gt;probably approximately correct&lt;/strong&gt; (PAC) learning.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;an-example-of-hoeffdings-inequality&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;An example of Hoeffding’s Inequality&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: n = 1,000. Draw a sample and observe &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;$$99% of the time, &lt;span class=&#34;math inline&#34;&gt;\(\mu - .05 \leq \eta \leq \mu+.05\)&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This is implied by setting &lt;span class=&#34;math inline&#34;&gt;\(\epsilon = 0.05\)&lt;/span&gt; and using &lt;span class=&#34;math inline&#34;&gt;\(n=1,000\)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;99.9999996% of the time &lt;span class=&#34;math inline&#34;&gt;\(\mu - .10 \leq \eta \leq \mu + .10\%\)&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;What does this mean?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If I repeatedly pick a sample of size 1,000, observe &lt;span class=&#34;math inline&#34;&gt;\(\eta\)&lt;/span&gt; and claim that &lt;span class=&#34;math inline&#34;&gt;\(\mu \in \left[\eta - .05, \eta + .05\right]\)&lt;/span&gt; (or that the error bar is &lt;span class=&#34;math inline&#34;&gt;\(\pm 0.05\)&lt;/span&gt;), I will be right 99% of the time.&lt;/p&gt;
&lt;p&gt;On any particular sample you may be wrong, but not often.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This week’s content is split into two “halves”: the critical data manipulation information contained below and a more-entertaining discussion of visualization included in the Exercises.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;tidyverse&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The tidyverse&lt;/h1&gt;
&lt;p&gt;In the first weeks’ content (or maybe that is week zero?), we demonstrated how to manipulate vectors by reordering and subsetting them through indexing. However, once we start more advanced analyses, the preferred unit for data storage is not the vector but the data frame. In this lecture, we learn to work directly with data frames, which greatly facilitate the organization of information. We will be using data frames for the majority of this class and you will use them for the majority of your data science life (however long that might be). We will focus on a specific data format referred to as &lt;em&gt;tidy&lt;/em&gt; and on specific collection of packages that are particularly helpful for working with &lt;em&gt;tidy&lt;/em&gt; data referred to as the &lt;em&gt;tidyverse&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We can load all the tidyverse packages at once by installing and loading the &lt;strong&gt;tidyverse&lt;/strong&gt; package:&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will learn how to implement the tidyverse approach throughout the book, but before delving into the details, in this chapter we introduce some of the most widely used tidyverse functionality, starting with the &lt;strong&gt;dplyr&lt;/strong&gt; package for manipulating data frames and the &lt;strong&gt;purrr&lt;/strong&gt; package for working with functions. Note that the tidyverse also includes a graphing package, &lt;strong&gt;ggplot2&lt;/strong&gt;, which we introduce later in Chapter &lt;a href=&#34;#ggplot2&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; in the Data Visualization part of the book; the &lt;strong&gt;readr&lt;/strong&gt; package discussed in Chapter &lt;a href=&#34;#importing-data&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt;; and many others. In this chapter, we first introduce the concept of &lt;em&gt;tidy data&lt;/em&gt; and then demonstrate how we use the tidyverse to work with data frames in this format.&lt;/p&gt;
&lt;div id=&#34;tidy-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tidy data&lt;/h2&gt;
&lt;p&gt;We say that a data table is in &lt;em&gt;tidy&lt;/em&gt; format if each row represents one observation and columns represent the different variables available for each of these observations. The &lt;code&gt;murders&lt;/code&gt; dataset is an example of a tidy data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)
head(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state abb region population total
## 1    Alabama  AL  South    4779736   135
## 2     Alaska  AK   West     710231    19
## 3    Arizona  AZ   West    6392017   232
## 4   Arkansas  AR  South    2915918    93
## 5 California  CA   West   37253956  1257
## 6   Colorado  CO   West    5029196    65&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each row represent a state with each of the five columns providing a different variable related to these states: name, abbreviation, region, population, and total murders.&lt;/p&gt;
&lt;p&gt;To see how the same information can be provided in different formats, consider the following example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(&amp;quot;gapminder&amp;quot;)
tidy_data &amp;lt;- gapminder %&amp;gt;%
  filter(country %in% c(&amp;quot;South Korea&amp;quot;, &amp;quot;Germany&amp;quot;) &amp;amp; !is.na(fertility)) %&amp;gt;%
  select(country, year, fertility)
head(tidy_data, 6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       country year fertility
## 1     Germany 1960      2.41
## 2 South Korea 1960      6.16
## 3     Germany 1961      2.44
## 4 South Korea 1961      5.99
## 5     Germany 1962      2.47
## 6 South Korea 1962      5.79&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tidy dataset provides fertility rates for two countries across the years. This is a tidy dataset because each row presents one observation with the three variables being country, year, and fertility rate. However, this dataset originally came in another format and was reshaped for the &lt;strong&gt;dslabs&lt;/strong&gt; package. Originally, the data was in the following format:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;##       country 1960 1961 1962
## 1     Germany 2.41 2.44 2.47
## 2 South Korea 6.16 5.99 5.79&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The same information is provided, but there are two important differences in the format: 1) each row includes several observations and 2) one of the variables, year, is stored in the header. For the tidyverse packages to be optimally used, data need to be reshaped into &lt;code&gt;tidy&lt;/code&gt; format, which you will learn to do throughout this course. For starters, though, we will use example datasets that are already in tidy format.&lt;/p&gt;
&lt;p&gt;Although not immediately obvious, as you go through the book you will start to appreciate the advantages of working in a framework in which functions use tidy formats for both inputs and outputs. You will see how this permits the data analyst to focus on more important aspects of the analysis rather than the format of the data.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Examine the built-in dataset &lt;code&gt;co2&lt;/code&gt;. Which of the following is true:&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;co2&lt;/code&gt; is tidy data: it has one year for each row.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;co2&lt;/code&gt; is not tidy: we need at least one column with a character vector.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;co2&lt;/code&gt; is not tidy: it is a matrix instead of a data frame.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;co2&lt;/code&gt; is not tidy: to be tidy we would have to wrangle it to have three columns (year, month and value), then each co2 observation would have a row.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Examine the built-in dataset &lt;code&gt;ChickWeight&lt;/code&gt;. Which of the following is true:&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;ChickWeight&lt;/code&gt; is not tidy: each chick has more than one row.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ChickWeight&lt;/code&gt; is tidy: each observation (a weight) is represented by one row. The chick from which this measurement came is one of the variables.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ChickWeight&lt;/code&gt; is not tidy: we are missing the year column.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ChickWeight&lt;/code&gt; is tidy: it is stored in a data frame.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Examine the built-in dataset &lt;code&gt;BOD&lt;/code&gt;. Which of the following is true:&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;BOD&lt;/code&gt; is not tidy: it only has six rows.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BOD&lt;/code&gt; is not tidy: the first column is just an index.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BOD&lt;/code&gt; is tidy: each row is an observation with two values (time and demand)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BOD&lt;/code&gt; is tidy: all small datasets are tidy by definition.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Which of the following built-in datasets is tidy (you can pick more than one):&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;BJsales&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;EuStockMarkets&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;DNase&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Formaldehyde&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Orange&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;UCBAdmissions&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;manipulating-data-frames&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Manipulating data frames&lt;/h2&gt;
&lt;p&gt;The &lt;strong&gt;dplyr&lt;/strong&gt; package from the &lt;strong&gt;tidyverse&lt;/strong&gt; introduces functions that perform some of the most common operations when working with data frames and uses names for these functions that are relatively easy to remember. For instance, to change the data table by adding a new column, we use &lt;code&gt;mutate&lt;/code&gt;. To filter the data table to a subset of rows, we use &lt;code&gt;filter&lt;/code&gt;. Finally, to subset the data by selecting specific columns, we use &lt;code&gt;select&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;adding-a-column-with-mutate&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Adding a column with &lt;code&gt;mutate&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;We want all the necessary information for our analysis to be included in the data table. So the first task is to add the murder rates to our murders data frame. The function &lt;code&gt;mutate&lt;/code&gt; takes the data frame as a first argument and the name and values of the variable as a second argument using the convention &lt;code&gt;name = values&lt;/code&gt;. So, to add murder rates, we use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(&amp;quot;murders&amp;quot;)
murders &amp;lt;- mutate(murders, rate = total / population * 100000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that here we used &lt;code&gt;total&lt;/code&gt; and &lt;code&gt;population&lt;/code&gt; inside the function, which are objects that are &lt;strong&gt;not&lt;/strong&gt; defined in our workspace. But why don’t we get an error?&lt;/p&gt;
&lt;p&gt;This is one of &lt;strong&gt;dplyr&lt;/strong&gt;’s main features. Functions in this package, such as &lt;code&gt;mutate&lt;/code&gt;, know to look for variables in the data frame provided in the first argument. In the call to mutate above, &lt;code&gt;total&lt;/code&gt; will have the values in &lt;code&gt;murders$total&lt;/code&gt;. This approach makes the code much more readable.&lt;/p&gt;
&lt;p&gt;We can see that the new column is added:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state abb region population total     rate
## 1    Alabama  AL  South    4779736   135 2.824424
## 2     Alaska  AK   West     710231    19 2.675186
## 3    Arizona  AZ   West    6392017   232 3.629527
## 4   Arkansas  AR  South    2915918    93 3.189390
## 5 California  CA   West   37253956  1257 3.374138
## 6   Colorado  CO   West    5029196    65 1.292453&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Although we have overwritten the original &lt;code&gt;murders&lt;/code&gt; object, this does not change the object that loaded with &lt;code&gt;data(murders)&lt;/code&gt;. If we load the &lt;code&gt;murders&lt;/code&gt; data again, the original will overwrite our mutated version.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;subsetting-with-filter&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Subsetting with &lt;code&gt;filter&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Now suppose that we want to filter the data table to only show the entries for which the murder rate is lower than 0.71. To do this we use the &lt;code&gt;filter&lt;/code&gt; function, which takes the data table as the first argument and then the conditional statement as the second. Like &lt;code&gt;mutate&lt;/code&gt;, we can use the unquoted variable names from &lt;code&gt;murders&lt;/code&gt; inside the function and it will know we mean the columns and not objects in the workspace.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(murders, rate &amp;lt;= 0.71)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           state abb        region population total      rate
## 1        Hawaii  HI          West    1360301     7 0.5145920
## 2          Iowa  IA North Central    3046355    21 0.6893484
## 3 New Hampshire  NH     Northeast    1316470     5 0.3798036
## 4  North Dakota  ND North Central     672591     4 0.5947151
## 5       Vermont  VT     Northeast     625741     2 0.3196211&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;selecting-columns-with-select&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Selecting columns with &lt;code&gt;select&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Although our data table only has six columns, some data tables include hundreds. If we want to view just a few, we can use the &lt;strong&gt;dplyr&lt;/strong&gt; &lt;code&gt;select&lt;/code&gt; function. In the code below we select three columns, assign this to a new object and then filter the new object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;new_table &amp;lt;- select(murders, state, region, rate)
filter(new_table, rate &amp;lt;= 0.71)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           state        region      rate
## 1        Hawaii          West 0.5145920
## 2          Iowa North Central 0.6893484
## 3 New Hampshire     Northeast 0.3798036
## 4  North Dakota North Central 0.5947151
## 5       Vermont     Northeast 0.3196211&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the call to &lt;code&gt;select&lt;/code&gt;, the first argument &lt;code&gt;murders&lt;/code&gt; is an object, but &lt;code&gt;state&lt;/code&gt;, &lt;code&gt;region&lt;/code&gt;, and &lt;code&gt;rate&lt;/code&gt; are variable names.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Load the &lt;strong&gt;dplyr&lt;/strong&gt; package and the murders dataset.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(dslabs)
data(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can add columns using the &lt;strong&gt;dplyr&lt;/strong&gt; function &lt;code&gt;mutate&lt;/code&gt;. This function is aware of the column names and inside the function you can call them unquoted:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders &amp;lt;- mutate(murders, population_in_millions = population / 10^6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can write &lt;code&gt;population&lt;/code&gt; rather than &lt;code&gt;murders$population&lt;/code&gt;. The function &lt;code&gt;mutate&lt;/code&gt; knows we are grabbing columns from &lt;code&gt;murders&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Use the function &lt;code&gt;mutate&lt;/code&gt; to add a murders column named &lt;code&gt;rate&lt;/code&gt; with the per 100,000 murder rate as in the example code above. Make sure you redefine &lt;code&gt;murders&lt;/code&gt; as done in the example code above ( murders &amp;lt;- [your code]) so we can keep using this variable.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;If &lt;code&gt;rank(x)&lt;/code&gt; gives you the ranks of &lt;code&gt;x&lt;/code&gt; from lowest to highest, &lt;code&gt;rank(-x)&lt;/code&gt; gives you the ranks from highest to lowest. Use the function &lt;code&gt;mutate&lt;/code&gt; to add a column &lt;code&gt;rank&lt;/code&gt; containing the rank, from highest to lowest murder rate. Make sure you redefine &lt;code&gt;murders&lt;/code&gt; so we can keep using this variable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;With &lt;strong&gt;dplyr&lt;/strong&gt;, we can use &lt;code&gt;select&lt;/code&gt; to show only certain columns. For example, with this code we would only show the states and population sizes:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;select(murders, state, population) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use &lt;code&gt;select&lt;/code&gt; to show the state names and abbreviations in &lt;code&gt;murders&lt;/code&gt;. Do not redefine &lt;code&gt;murders&lt;/code&gt;, just show the results.&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The &lt;strong&gt;dplyr&lt;/strong&gt; function &lt;code&gt;filter&lt;/code&gt; is used to choose specific rows of the data frame to keep. Unlike &lt;code&gt;select&lt;/code&gt; which is for columns, &lt;code&gt;filter&lt;/code&gt; is for rows. For example, you can show just the New York row like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(murders, state == &amp;quot;New York&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can use other logical vectors to filter rows.&lt;/p&gt;
&lt;p&gt;Use &lt;code&gt;filter&lt;/code&gt; to show the top 5 states with the highest murder rates. After we add murder rate and rank, do not change the murders dataset, just show the result. Remember that you can filter based on the &lt;code&gt;rank&lt;/code&gt; column.&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We can remove rows using the &lt;code&gt;!=&lt;/code&gt; operator. For example, to remove Florida, we would do this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;no_florida &amp;lt;- filter(murders, state != &amp;quot;Florida&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a new data frame called &lt;code&gt;no_south&lt;/code&gt; that removes states from the South region. How many states are in this category? You can use the function &lt;code&gt;nrow&lt;/code&gt; for this.&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We can also use &lt;code&gt;%in%&lt;/code&gt; to filter with &lt;strong&gt;dplyr&lt;/strong&gt;. You can therefore see the data from New York and Texas like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(murders, state %in% c(&amp;quot;New York&amp;quot;, &amp;quot;Texas&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Create a new data frame called &lt;code&gt;murders_nw&lt;/code&gt; with only the states from the Northeast and the West. How many states are in this category?&lt;/p&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Suppose you want to live in the Northeast or West &lt;strong&gt;and&lt;/strong&gt; want the murder rate to be less than 1. We want to see the data for the states satisfying these options. Note that you can use logical operators with &lt;code&gt;filter&lt;/code&gt;. Here is an example in which we filter to keep only small states in the Northeast region.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(murders, population &amp;lt; 5000000 &amp;amp; region == &amp;quot;Northeast&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Make sure &lt;code&gt;murders&lt;/code&gt; has been defined with &lt;code&gt;rate&lt;/code&gt; and &lt;code&gt;rank&lt;/code&gt; and still has all states. Create a table called &lt;code&gt;my_states&lt;/code&gt; that contains rows for states satisfying both the conditions: it is in the Northeast or West and the murder rate is less than 1. Use &lt;code&gt;select&lt;/code&gt; to show only the state name, the rate, and the rank.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-pipe&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The pipe: &lt;code&gt;%&amp;gt;%&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;With &lt;strong&gt;dplyr&lt;/strong&gt; we can perform a series of operations, for example &lt;code&gt;select&lt;/code&gt; and then &lt;code&gt;filter&lt;/code&gt;, by sending the results of one function to another using what is called the &lt;em&gt;pipe operator&lt;/em&gt;: &lt;code&gt;%&amp;gt;%&lt;/code&gt;. Some details are included below.&lt;/p&gt;
&lt;p&gt;We wrote code above to show three variables (state, region, rate) for states that have murder rates below 0.71. To do this, we defined the intermediate object &lt;code&gt;new_table&lt;/code&gt;. In &lt;strong&gt;dplyr&lt;/strong&gt; we can write code that looks more like a description of what we want to do without intermediate objects:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \mbox{original data }
\rightarrow \mbox{ select }
\rightarrow \mbox{ filter } \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For such an operation, we can use the pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt;. The code looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% select(state, region, rate) %&amp;gt;% filter(rate &amp;lt;= 0.71)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           state        region      rate
## 1        Hawaii          West 0.5145920
## 2          Iowa North Central 0.6893484
## 3 New Hampshire     Northeast 0.3798036
## 4  North Dakota North Central 0.5947151
## 5       Vermont     Northeast 0.3196211&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This line of code is equivalent to the two lines of code above. What is going on here?&lt;/p&gt;
&lt;p&gt;In general, the pipe &lt;em&gt;sends&lt;/em&gt; the result of the left side of the pipe to be the first argument of the function on the right side of the pipe. Here is a very simple example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;16 %&amp;gt;% sqrt()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can continue to pipe values along:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;16 %&amp;gt;% sqrt() %&amp;gt;% log2()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above statement is equivalent to &lt;code&gt;log2(sqrt(16))&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Remember that the pipe sends values to the first argument, so we can define other arguments as if the first argument is already defined:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;16 %&amp;gt;% sqrt() %&amp;gt;% log(base = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Therefore, when using the pipe with data frames and &lt;strong&gt;dplyr&lt;/strong&gt;, we no longer need to specify the required first argument since the &lt;strong&gt;dplyr&lt;/strong&gt; functions we have described all take the data as the first argument. In the code we wrote:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% select(state, region, rate) %&amp;gt;% filter(rate &amp;lt;= 0.71)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;murders&lt;/code&gt; is the first argument of the &lt;code&gt;select&lt;/code&gt; function, and the new data frame (formerly &lt;code&gt;new_table&lt;/code&gt;) is the first argument of the &lt;code&gt;filter&lt;/code&gt; function.&lt;/p&gt;
&lt;p&gt;Note that the pipe works well with functions where the first argument is the input data. Functions in &lt;strong&gt;tidyverse&lt;/strong&gt; packages like &lt;strong&gt;dplyr&lt;/strong&gt; have this format and can be used easily with the pipe.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt; can be used to perform operations sequentially without having to define intermediate objects. Start by redefining murder to include rate and rank.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders &amp;lt;- mutate(murders, rate =  total / population * 100000,
                  rank = rank(-rate))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the solution to the previous exercise, we did the following:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_states &amp;lt;- filter(murders, region %in% c(&amp;quot;Northeast&amp;quot;, &amp;quot;West&amp;quot;) &amp;amp;
                      rate &amp;lt; 1)

select(my_states, state, rate, rank)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt; permits us to perform both operations sequentially without having to define an intermediate variable &lt;code&gt;my_states&lt;/code&gt;. We therefore could have mutated and selected in the same line like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mutate(murders, rate =  total / population * 100000,
       rank = rank(-rate)) %&amp;gt;%
  select(state, rate, rank)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that &lt;code&gt;select&lt;/code&gt; no longer has a data frame as the first argument. The first argument is assumed to be the result of the operation conducted right before the &lt;code&gt;%&amp;gt;%&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Repeat the previous exercise, but now instead of creating a new object, show the result and only include the state, rate, and rank columns. Use a pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt; to do this in just one line.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Reset &lt;code&gt;murders&lt;/code&gt; to the original table by using &lt;code&gt;data(murders)&lt;/code&gt;. Use a pipe to create a new data frame called &lt;code&gt;my_states&lt;/code&gt; that considers only states in the Northeast or West which have a murder rate lower than 1, and contains only the state, rate and rank columns. The pipe should also have four components separated by three &lt;code&gt;%&amp;gt;%&lt;/code&gt;. The code should look something like this:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_states &amp;lt;- murders %&amp;gt;%
  mutate SOMETHING %&amp;gt;%
  filter SOMETHING %&amp;gt;%
  select SOMETHING&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;summarizing-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summarizing data&lt;/h2&gt;
&lt;p&gt;An important part of exploratory data analysis is summarizing data. The average and standard deviation are two examples of widely used summary statistics. More informative summaries can often be achieved by first splitting data into groups. In this section, we cover two new &lt;strong&gt;dplyr&lt;/strong&gt; verbs that make these computations easier: &lt;code&gt;summarize&lt;/code&gt; and &lt;code&gt;group_by&lt;/code&gt;. We learn to access resulting values using the &lt;code&gt;pull&lt;/code&gt; function.&lt;/p&gt;
&lt;div id=&#34;summarize&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;summarize&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;summarize&lt;/code&gt; function in &lt;strong&gt;dplyr&lt;/strong&gt; provides a way to compute summary statistics with intuitive and readable code. We start with a simple example based on heights. The &lt;code&gt;heights&lt;/code&gt; dataset includes heights and sex reported by students in an in-class survey.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr)
library(dslabs)
data(heights)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following code computes the average and standard deviation for females:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- heights %&amp;gt;%
  filter(sex == &amp;quot;Female&amp;quot;) %&amp;gt;%
  summarize(average = mean(height), standard_deviation = sd(height))
s&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    average standard_deviation
## 1 64.93942           3.760656&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This takes our original data table as input, filters it to keep only females, and then produces a new summarized table with just the average and the standard deviation of heights. We get to choose the names of the columns of the resulting table. For example, above we decided to use &lt;code&gt;average&lt;/code&gt; and &lt;code&gt;standard_deviation&lt;/code&gt;, but we could have used other names just the same.&lt;/p&gt;
&lt;p&gt;Because the resulting table stored in &lt;code&gt;s&lt;/code&gt; is a data frame, we can access the components with the accessor &lt;code&gt;$&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s$average&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 64.93942&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s$standard_deviation&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.760656&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with most other &lt;strong&gt;dplyr&lt;/strong&gt; functions, &lt;code&gt;summarize&lt;/code&gt; is aware of the variable names and we can use them directly. So when inside the call to the &lt;code&gt;summarize&lt;/code&gt; function we write &lt;code&gt;mean(height)&lt;/code&gt;, the function is accessing the column with the name “height” and then computing the average of the resulting numeric vector. We can compute any other summary that operates on vectors and returns a single value. For example, we can add the median, minimum, and maximum heights like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  filter(sex == &amp;quot;Female&amp;quot;) %&amp;gt;%
  summarize(median = median(height), minimum = min(height),
            maximum = max(height))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     median minimum maximum
## 1 64.98031      51      79&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can obtain these three values with just one line using the &lt;code&gt;quantile&lt;/code&gt; function: for example, &lt;code&gt;quantile(x, c(0,0.5,1))&lt;/code&gt; returns the min (0th percentile), median (50th percentile), and max (100th percentile) of the vector &lt;code&gt;x&lt;/code&gt;. However, if we attempt to use a function like this that returns two or more values inside &lt;code&gt;summarize&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  filter(sex == &amp;quot;Female&amp;quot;) %&amp;gt;%
  summarize(range = quantile(height, c(0, 0.5, 1)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;we will receive an error: &lt;code&gt;Error: expecting result of length one, got : 2&lt;/code&gt;. With the function &lt;code&gt;summarize&lt;/code&gt;, we can only call functions that return a single value. In Section &lt;a href=&#34;#do&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt;, we will learn how to deal with functions that return more than one value.&lt;/p&gt;
&lt;p&gt;For another example of how we can use the &lt;code&gt;summarize&lt;/code&gt; function, let’s compute the average murder rate for the United States. Remember our data table includes total murders and population size for each state and we have already used &lt;strong&gt;dplyr&lt;/strong&gt; to add a murder rate column:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders &amp;lt;- murders %&amp;gt;% mutate(rate = total/population*100000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that the US murder rate is &lt;strong&gt;not&lt;/strong&gt; the average of the state murder rates:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summarize(murders, mean(rate))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mean(rate)
## 1   2.779125&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because in the computation above the small states are given the same weight as the large ones. The US murder rate is the total number of murders in the US divided by the total US population. So the correct computation is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us_murder_rate &amp;lt;- murders %&amp;gt;%
  summarize(rate = sum(total) / sum(population) * 100000)
us_murder_rate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       rate
## 1 3.034555&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This computation counts larger states proportionally to their size which results in a larger value.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pull&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;pull&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;us_murder_rate&lt;/code&gt; object defined above represents just one number. Yet we are storing it in a data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(us_murder_rate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;since, as most &lt;strong&gt;dplyr&lt;/strong&gt; functions, &lt;code&gt;summarize&lt;/code&gt; always returns a data frame.&lt;/p&gt;
&lt;p&gt;This might be problematic if we want to use this result with functions that require a numeric value. Here we show a useful trick for accessing values stored in data when using pipes: when a data object is piped that object and its columns can be accessed using the &lt;code&gt;pull&lt;/code&gt; function. To understand what we mean take a look at this line of code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us_murder_rate %&amp;gt;% pull(rate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.034555&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This returns the value in the &lt;code&gt;rate&lt;/code&gt; column of &lt;code&gt;us_murder_rate&lt;/code&gt; making it equivalent to &lt;code&gt;us_murder_rate$rate&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;To get a number from the original data table with one line of code we can type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;us_murder_rate &amp;lt;- murders %&amp;gt;%
  summarize(rate = sum(total) / sum(population) * 100000) %&amp;gt;%
  pull(rate)

us_murder_rate&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.034555&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is now a numeric:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(us_murder_rate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;group-by&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Group then summarize with &lt;code&gt;group_by&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A common operation in data exploration is to first split data into groups and then compute summaries for each group. For example, we may want to compute the average and standard deviation for men’s and women’s heights separately. The &lt;code&gt;group_by&lt;/code&gt; function helps us do this.&lt;/p&gt;
&lt;p&gt;If we type this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;% group_by(sex)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,050 × 2
## # Groups:   sex [2]
##    sex    height
##    &amp;lt;fct&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 Male       75
##  2 Male       70
##  3 Male       68
##  4 Male       74
##  5 Male       61
##  6 Female     65
##  7 Female     66
##  8 Female     62
##  9 Female     66
## 10 Male       67
## # … with 1,040 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result does not look very different from &lt;code&gt;heights&lt;/code&gt;, except we see &lt;code&gt;Groups: sex [2]&lt;/code&gt; when we print the object. Although not immediately obvious from its appearance, this is now a special data frame called a &lt;em&gt;grouped data frame&lt;/em&gt;, and &lt;strong&gt;dplyr&lt;/strong&gt; functions, in particular &lt;code&gt;summarize&lt;/code&gt;, will behave differently when acting on this object. Conceptually, you can think of this table as many tables, with the same columns but not necessarily the same number of rows, stacked together in one object. When we summarize the data after grouping, this is what happens:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  group_by(sex) %&amp;gt;%
  summarize(average = mean(height), standard_deviation = sd(height))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 3
##   sex    average standard_deviation
##   &amp;lt;fct&amp;gt;    &amp;lt;dbl&amp;gt;              &amp;lt;dbl&amp;gt;
## 1 Female    64.9               3.76
## 2 Male      69.3               3.61&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;summarize&lt;/code&gt; function applies the summarization to each group separately.&lt;/p&gt;
&lt;p&gt;For another example, let’s compute the median murder rate in the four regions of the country:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;%
  group_by(region) %&amp;gt;%
  summarize(median_rate = median(rate))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 × 2
##   region        median_rate
##   &amp;lt;fct&amp;gt;               &amp;lt;dbl&amp;gt;
## 1 Northeast            1.80
## 2 South                3.40
## 3 North Central        1.97
## 4 West                 1.29&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sorting-data-frames&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sorting data frames&lt;/h2&gt;
&lt;p&gt;When examining a dataset, it is often convenient to sort the table by the different columns. We know about the &lt;code&gt;order&lt;/code&gt; and &lt;code&gt;sort&lt;/code&gt; function, but for ordering entire tables, the &lt;strong&gt;dplyr&lt;/strong&gt; function &lt;code&gt;arrange&lt;/code&gt; is useful. For example, here we order the states by population size:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;%
  arrange(population) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  state abb        region population total       rate
## 1              Wyoming  WY          West     563626     5  0.8871131
## 2 District of Columbia  DC         South     601723    99 16.4527532
## 3              Vermont  VT     Northeast     625741     2  0.3196211
## 4         North Dakota  ND North Central     672591     4  0.5947151
## 5               Alaska  AK          West     710231    19  2.6751860
## 6         South Dakota  SD North Central     814180     8  0.9825837&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;arrange&lt;/code&gt; we get to decide which column to sort by. To see the states by murder rate, from lowest to highest, we arrange by &lt;code&gt;rate&lt;/code&gt; instead:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;%
  arrange(rate) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           state abb        region population total      rate
## 1       Vermont  VT     Northeast     625741     2 0.3196211
## 2 New Hampshire  NH     Northeast    1316470     5 0.3798036
## 3        Hawaii  HI          West    1360301     7 0.5145920
## 4  North Dakota  ND North Central     672591     4 0.5947151
## 5          Iowa  IA North Central    3046355    21 0.6893484
## 6         Idaho  ID          West    1567582    12 0.7655102&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the default behavior is to order in ascending order. In &lt;strong&gt;dplyr&lt;/strong&gt;, the function &lt;code&gt;desc&lt;/code&gt; transforms a vector so that it is in descending order. To sort the table in descending order, we can type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;%
  arrange(desc(rate))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;nested-sorting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Nested sorting&lt;/h3&gt;
&lt;p&gt;If we are ordering by a column with ties, we can use a second column to break the tie. Similarly, a third column can be used to break ties between first and second and so on. Here we order by &lt;code&gt;region&lt;/code&gt;, then within region we order by murder rate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;%
  arrange(region, rate) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           state abb    region population total      rate
## 1       Vermont  VT Northeast     625741     2 0.3196211
## 2 New Hampshire  NH Northeast    1316470     5 0.3798036
## 3         Maine  ME Northeast    1328361    11 0.8280881
## 4  Rhode Island  RI Northeast    1052567    16 1.5200933
## 5 Massachusetts  MA Northeast    6547629   118 1.8021791
## 6      New York  NY Northeast   19378102   517 2.6679599&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-top-n&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The top &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;In the code above, we have used the function &lt;code&gt;head&lt;/code&gt; to avoid having the page fill up with the entire dataset. If we want to see a larger proportion, we can use the &lt;code&gt;top_n&lt;/code&gt; function. This function takes a data frame as it’s first argument, the number of rows to show in the second, and the variable to filter by in the third. Here is an example of how to see the top 5 rows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% top_n(5, rate)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  state abb        region population total      rate
## 1 District of Columbia  DC         South     601723    99 16.452753
## 2            Louisiana  LA         South    4533372   351  7.742581
## 3             Maryland  MD         South    5773552   293  5.074866
## 4             Missouri  MO North Central    5988927   321  5.359892
## 5       South Carolina  SC         South    4625364   207  4.475323&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that rows are not sorted by &lt;code&gt;rate&lt;/code&gt;, only filtered. If we want to sort, we need to use &lt;code&gt;arrange&lt;/code&gt;.
Note that if the third argument is left blank, &lt;code&gt;top_n&lt;/code&gt; filters by the last column.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For these exercises, we will be using the data from the survey collected by the United States National Center for Health Statistics (NCHS). This center has conducted a series of health and nutrition surveys since the 1960’s. Starting in 1999, about 5,000 individuals of all ages have been interviewed every year and they complete the health examination component of the survey. Part of the data is made available via the &lt;strong&gt;NHANES&lt;/strong&gt; package. Once you install the &lt;strong&gt;NHANES&lt;/strong&gt; package, you can load the data like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(NHANES)
data(NHANES)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;NHANES&lt;/strong&gt; data has many missing values. The &lt;code&gt;mean&lt;/code&gt; and &lt;code&gt;sd&lt;/code&gt; functions in R will return &lt;code&gt;NA&lt;/code&gt; if any of the entries of the input vector is an &lt;code&gt;NA&lt;/code&gt;. Here is an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(na_example)
mean(na_example)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(na_example)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To ignore the &lt;code&gt;NA&lt;/code&gt;s we can use the &lt;code&gt;na.rm&lt;/code&gt; argument:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(na_example, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.301754&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(na_example, na.rm = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.22338&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s now explore the NHANES data.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We will provide some basic facts about blood pressure. First let’s select a group to set the standard. We will use 20-to-29-year-old females. &lt;code&gt;AgeDecade&lt;/code&gt; is a categorical variable with these ages. Note that the category is coded like ” 20-29”, with a space in front! What is the average and standard deviation of systolic blood pressure as saved in the &lt;code&gt;BPSysAve&lt;/code&gt; variable? Save it to a variable called &lt;code&gt;ref&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Hint: Use &lt;code&gt;filter&lt;/code&gt; and &lt;code&gt;summarize&lt;/code&gt; and use the &lt;code&gt;na.rm = TRUE&lt;/code&gt; argument when computing the average and standard deviation. You can also filter the NA values using &lt;code&gt;filter&lt;/code&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Using a pipe, assign the average to a numeric variable &lt;code&gt;ref_avg&lt;/code&gt;. Hint: Use the code similar to above and then &lt;code&gt;pull&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now report the min and max values for the same group.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compute the average and standard deviation for females, but for each age group separately rather than a selected decade as in question 1. Note that the age groups are defined by &lt;code&gt;AgeDecade&lt;/code&gt;. Hint: rather than filtering by age and gender, filter by &lt;code&gt;Gender&lt;/code&gt; and then use &lt;code&gt;group_by&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Repeat exercise 4 for males.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We can actually combine both summaries for exercises 4 and 5 into one line of code. This is because &lt;code&gt;group_by&lt;/code&gt; permits us to group by more than one variable. Obtain one big summary table using &lt;code&gt;group_by(AgeDecade, Gender)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For males between the ages of 40-49, compare systolic blood pressure across race as reported in the &lt;code&gt;Race1&lt;/code&gt; variable. Order the resulting table from lowest to highest average systolic blood pressure.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;tibbles&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tibbles&lt;/h2&gt;
&lt;p&gt;Tidy data must be stored in data frames. We introduced the data frame in Section &lt;a href=&#34;#data-frames&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; and have been using the &lt;code&gt;murders&lt;/code&gt; data frame throughout the book. In Section &lt;a href=&#34;#group-by&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; we introduced the &lt;code&gt;group_by&lt;/code&gt; function, which permits stratifying data before computing summary statistics. But where is the group information stored in the data frame?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% group_by(region)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 51 × 6
## # Groups:   region [4]
##    state                abb   region    population total  rate
##    &amp;lt;chr&amp;gt;                &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 Alabama              AL    South        4779736   135  2.82
##  2 Alaska               AK    West          710231    19  2.68
##  3 Arizona              AZ    West         6392017   232  3.63
##  4 Arkansas             AR    South        2915918    93  3.19
##  5 California           CA    West        37253956  1257  3.37
##  6 Colorado             CO    West         5029196    65  1.29
##  7 Connecticut          CT    Northeast    3574097    97  2.71
##  8 Delaware             DE    South         897934    38  4.23
##  9 District of Columbia DC    South         601723    99 16.5 
## 10 Florida              FL    South       19687653   669  3.40
## # … with 41 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that there are no columns with this information. But, if you look closely at the output above, you see the line &lt;code&gt;A tibble&lt;/code&gt; followd by dimensions. We can learn the class of the returned object using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;% group_by(region) %&amp;gt;% class()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;grouped_df&amp;quot; &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;tbl&lt;/code&gt;, pronounced tibble, is a special kind of data frame. The functions &lt;code&gt;group_by&lt;/code&gt; and &lt;code&gt;summarize&lt;/code&gt; always return this type of data frame. The &lt;code&gt;group_by&lt;/code&gt; function returns a special kind of &lt;code&gt;tbl&lt;/code&gt;, the &lt;code&gt;grouped_df&lt;/code&gt;. We will say more about these later. For consistency, the &lt;strong&gt;dplyr&lt;/strong&gt; manipulation verbs (&lt;code&gt;select&lt;/code&gt;, &lt;code&gt;filter&lt;/code&gt;, &lt;code&gt;mutate&lt;/code&gt;, and &lt;code&gt;arrange&lt;/code&gt;) preserve the class of the input: if they receive a regular data frame they return a regular data frame, while if they receive a tibble they return a tibble. But tibbles are the preferred format in the tidyverse and as a result tidyverse functions that produce a data frame from scratch return a tibble. For example, in Chapter &lt;a href=&#34;#importing-data&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; we will see that tidyverse functions used to import data create tibbles.&lt;/p&gt;
&lt;p&gt;Tibbles are very similar to data frames. In fact, you can think of them as a modern version of data frames. Nonetheless there are three important differences which we describe next.&lt;/p&gt;
&lt;div id=&#34;tibbles-display-better&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tibbles display better&lt;/h3&gt;
&lt;p&gt;The print method for tibbles is more readable than that of a data frame. To see this, compare the outputs of typing &lt;code&gt;murders&lt;/code&gt; and the output of murders if we convert it to a tibble. We can do this using &lt;code&gt;as_tibble(murders)&lt;/code&gt;. If using RStudio, output for a tibble adjusts to your window size. To see this, change the width of your R console and notice how more/less columns are shown.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;subsets-of-tibbles-are-tibbles&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Subsets of tibbles are tibbles&lt;/h3&gt;
&lt;p&gt;If you subset the columns of a data frame, you may get back an object that is not a data frame, such as a vector or scalar. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(murders[,4])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is not a data frame. With tibbles this does not happen:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(as_tibble(murders)[,4])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful in the tidyverse since functions require data frames as input.&lt;/p&gt;
&lt;p&gt;With tibbles, if you want to access the vector that defines a column, and not get back a data frame, you need to use the accessor &lt;code&gt;$&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(as_tibble(murders)$population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A related feature is that tibbles will give you a warning if you try to access a column that does not exist. If we accidentally write &lt;code&gt;Population&lt;/code&gt; instead of &lt;code&gt;population&lt;/code&gt; this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders$Population&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;returns a &lt;code&gt;NULL&lt;/code&gt; with no warning, which can make it harder to debug. In contrast, if we try this with a tibble we get an informative warning:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as_tibble(murders)$Population&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Unknown or uninitialised column: `Population`.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tibbles-can-have-complex-entries&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tibbles can have complex entries&lt;/h3&gt;
&lt;p&gt;While data frame columns need to be vectors of numbers, strings, or logical values, tibbles can have more complex objects, such as lists or functions. Also, we can create tibbles with functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(id = c(1, 2, 3), func = c(mean, median, sd))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 × 2
##      id func  
##   &amp;lt;dbl&amp;gt; &amp;lt;list&amp;gt;
## 1     1 &amp;lt;fn&amp;gt;  
## 2     2 &amp;lt;fn&amp;gt;  
## 3     3 &amp;lt;fn&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;tibbles-can-be-grouped&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Tibbles can be grouped&lt;/h3&gt;
&lt;p&gt;The function &lt;code&gt;group_by&lt;/code&gt; returns a special kind of tibble: a grouped tibble. This class stores information that lets you know which rows are in which groups. The tidyverse functions, in particular the &lt;code&gt;summarize&lt;/code&gt; function, are aware of the group information.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-tibble-using-tibble-instead-of-data.frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Create a tibble using &lt;code&gt;tibble&lt;/code&gt; instead of &lt;code&gt;data.frame&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;It is sometimes useful for us to create our own data frames. To create a data frame in the tibble format, you can do this by using the &lt;code&gt;tibble&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grades &amp;lt;- tibble(names = c(&amp;quot;John&amp;quot;, &amp;quot;Juan&amp;quot;, &amp;quot;Jean&amp;quot;, &amp;quot;Yao&amp;quot;),
                     exam_1 = c(95, 80, 90, 85),
                     exam_2 = c(90, 85, 85, 90))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that base R (without packages loaded) has a function with a very similar name, &lt;code&gt;data.frame&lt;/code&gt;, that can be used to create a regular data frame rather than a tibble. One other important difference is that by default &lt;code&gt;data.frame&lt;/code&gt; coerces characters into factors without providing a warning or message:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grades &amp;lt;- data.frame(names = c(&amp;quot;John&amp;quot;, &amp;quot;Juan&amp;quot;, &amp;quot;Jean&amp;quot;, &amp;quot;Yao&amp;quot;),
                     exam_1 = c(95, 80, 90, 85),
                     exam_2 = c(90, 85, 85, 90))
class(grades$names)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To avoid this, we use the rather cumbersome argument &lt;code&gt;stringsAsFactors&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;grades &amp;lt;- data.frame(names = c(&amp;quot;John&amp;quot;, &amp;quot;Juan&amp;quot;, &amp;quot;Jean&amp;quot;, &amp;quot;Yao&amp;quot;),
                     exam_1 = c(95, 80, 90, 85),
                     exam_2 = c(90, 85, 85, 90),
                     stringsAsFactors = FALSE)
class(grades$names)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To convert a regular data frame to a tibble, you can use the &lt;code&gt;as_tibble&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as_tibble(grades) %&amp;gt;% class()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-dot-operator&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The dot operator&lt;/h2&gt;
&lt;p&gt;One of the advantages of using the pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt; is that we do not have to keep naming new objects as we manipulate the data frame. As a quick reminder, if we want to compute the median murder rate for states in the southern states, instead of typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tab_1 &amp;lt;- filter(murders, region == &amp;quot;South&amp;quot;)
tab_2 &amp;lt;- mutate(tab_1, rate = total / population * 10^5)
rates &amp;lt;- tab_2$rate
median(rates)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.398069&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can avoid defining any new intermediate objects by instead typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;filter(murders, region == &amp;quot;South&amp;quot;) %&amp;gt;%
  mutate(rate = total / population * 10^5) %&amp;gt;%
  summarize(median = median(rate)) %&amp;gt;%
  pull(median)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.398069&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can do this because each of these functions takes a data frame as the first argument. But what if we want to access a component of the data frame. For example, what if the &lt;code&gt;pull&lt;/code&gt; function was not available and we wanted to access &lt;code&gt;tab_2$rate&lt;/code&gt;? What data frame name would we use? The answer is the dot operator.&lt;/p&gt;
&lt;p&gt;For example to access the rate vector without the &lt;code&gt;pull&lt;/code&gt; function we could use&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rates &amp;lt;-   filter(murders, region == &amp;quot;South&amp;quot;) %&amp;gt;%
  mutate(rate = total / population * 10^5) %&amp;gt;%
  .$rate
median(rates)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.398069&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the next section, we will see other instances in which using the &lt;code&gt;.&lt;/code&gt; is useful.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;do&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;code&gt;do&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The tidyverse functions know how to interpret grouped tibbles. Furthermore, to facilitate stringing commands through the pipe &lt;code&gt;%&amp;gt;%&lt;/code&gt;, tidyverse functions consistently return data frames, since this assures that the output of a function is accepted as the input of another. But most R functions do not recognize grouped tibbles nor do they return data frames. The &lt;code&gt;quantile&lt;/code&gt; function is an example we described in Section &lt;a href=&#34;#summarize&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt;. The &lt;code&gt;do&lt;/code&gt; function serves as a bridge between R functions such as &lt;code&gt;quantile&lt;/code&gt; and the tidyverse. The &lt;code&gt;do&lt;/code&gt; function understands grouped tibbles and always returns a data frame.&lt;/p&gt;
&lt;p&gt;In Section &lt;a href=&#34;#summarize&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt;, we noted that if we attempt to use &lt;code&gt;quantile&lt;/code&gt; to obtain the min, median and max in one call, we will receive an error: &lt;code&gt;Error: expecting result of length one, got : 2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(heights)
heights %&amp;gt;%
  filter(sex == &amp;quot;Female&amp;quot;) %&amp;gt;%
  summarize(range = quantile(height, c(0, 0.5, 1)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use the &lt;code&gt;do&lt;/code&gt; function to fix this.&lt;/p&gt;
&lt;p&gt;First we have to write a function that fits into the tidyverse approach: that is, it receives a data frame and returns a data frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_summary &amp;lt;- function(dat){
  x &amp;lt;- quantile(dat$height, c(0, 0.5, 1))
  tibble(min = x[1], median = x[2], max = x[3])
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now apply the function to the heights dataset to obtain the summaries:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  group_by(sex) %&amp;gt;%
  my_summary&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 3
##     min median   max
##   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1    50   68.5  82.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But this is not what we want. We want a summary for each sex and the code returned just one summary. This is because &lt;code&gt;my_summary&lt;/code&gt; is not part of the tidyverse and does not know how to handled grouped tibbles. &lt;code&gt;do&lt;/code&gt; makes this connection:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  group_by(sex) %&amp;gt;%
  do(my_summary(.))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 × 4
## # Groups:   sex [2]
##   sex      min median   max
##   &amp;lt;fct&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Female    51   65.0  79  
## 2 Male      50   69    82.7&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that here we need to use the dot operator. The tibble created by &lt;code&gt;group_by&lt;/code&gt; is piped to &lt;code&gt;do&lt;/code&gt;. Within the call to &lt;code&gt;do&lt;/code&gt;, the name of this tibble is &lt;code&gt;.&lt;/code&gt; and we want to send it to &lt;code&gt;my_summary&lt;/code&gt;. If you do not use the dot, then &lt;code&gt;my_summary&lt;/code&gt; has &lt;em&gt;no argument&lt;/em&gt; and returns an error telling us that &lt;code&gt;argument &#34;dat&#34;&lt;/code&gt; is missing. You can see the error by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  group_by(sex) %&amp;gt;%
  do(my_summary())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you do not use the parenthesis, then the function is not executed and instead &lt;code&gt;do&lt;/code&gt; tries to return the function. This gives an error because &lt;code&gt;do&lt;/code&gt; must always return a data frame. You can see the error by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  group_by(sex) %&amp;gt;%
  do(my_summary)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-purrr-package&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The &lt;strong&gt;purrr&lt;/strong&gt; package&lt;/h2&gt;
&lt;p&gt;In Section &lt;a href=&#34;#vectorization&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; we learned about the &lt;code&gt;sapply&lt;/code&gt; function, which permitted us to apply the same function to each element of a vector. We constructed a function and used &lt;code&gt;sapply&lt;/code&gt; to compute the sum of the first &lt;code&gt;n&lt;/code&gt; integers for several values of &lt;code&gt;n&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_s_n &amp;lt;- function(n){
  x &amp;lt;- 1:n
  sum(x)
}
n &amp;lt;- 1:25
s_n &amp;lt;- sapply(n, compute_s_n)
s_n&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]   1   3   6  10  15  21  28  36  45  55  66  78  91 105 120 136 153 171 190
## [20] 210 231 253 276 300 325&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This type of operation, applying the same function or procedure to elements of an object, is quite common in data analysis. The &lt;strong&gt;purrr&lt;/strong&gt; package includes functions similar to &lt;code&gt;sapply&lt;/code&gt; but that better interact with other tidyverse functions. The main advantage is that we can better control the output type of functions. In contrast, &lt;code&gt;sapply&lt;/code&gt; can return several different object types; for example, we might expect a numeric result from a line of code, but &lt;code&gt;sapply&lt;/code&gt; might convert our result to character under some circumstances. &lt;strong&gt;purrr&lt;/strong&gt; functions will never do this: they will return objects of a specified type or return an error if this is not possible.&lt;/p&gt;
&lt;p&gt;The first &lt;strong&gt;purrr&lt;/strong&gt; function we will learn is &lt;code&gt;map&lt;/code&gt;, which works very similar to &lt;code&gt;sapply&lt;/code&gt; but always, without exception, returns a list:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(purrr) # or library(tidyverse)
n &amp;lt;- 1:25
s_n &amp;lt;- map(n, compute_s_n)
class(s_n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want a numeric vector, we can instead use &lt;code&gt;map_dbl&lt;/code&gt; which always returns a vector of numeric values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s_n &amp;lt;- map_dbl(n, compute_s_n)
class(s_n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This produces the same results as the &lt;code&gt;sapply&lt;/code&gt; call shown above.&lt;/p&gt;
&lt;p&gt;A particularly useful &lt;strong&gt;purrr&lt;/strong&gt; function for interacting with the rest of the tidyverse is &lt;code&gt;map_df&lt;/code&gt;, which always returns a tibble data frame. However, the function being called needs to return a vector or a list with names. For this reason, the following code would result in a &lt;code&gt;Argument 1 must have names&lt;/code&gt; error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s_n &amp;lt;- map_df(n, compute_s_n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to change the function to make this work:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_s_n &amp;lt;- function(n){
  x &amp;lt;- 1:n
  tibble(sum = sum(x))
}
s_n &amp;lt;- map_df(n, compute_s_n)
head(s_n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 × 1
##     sum
##   &amp;lt;int&amp;gt;
## 1     1
## 2     3
## 3     6
## 4    10
## 5    15
## 6    21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;strong&gt;purrr&lt;/strong&gt; package provides much more functionality not covered here. For more details you can consult &lt;a href=&#34;https://jennybc.github.io/purrr-tutorial/&#34;&gt;this online resource&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tidyverse-conditionals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Tidyverse conditionals&lt;/h2&gt;
&lt;p&gt;A typical data analysis will often involve one or more conditional operations. In Section &lt;a href=&#34;#conditionals&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; we described the &lt;code&gt;ifelse&lt;/code&gt; function, which we will use extensively in this book. In this section we present two &lt;strong&gt;dplyr&lt;/strong&gt; functions that provide further functionality for performing conditional operations.&lt;/p&gt;
&lt;div id=&#34;case_when&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;case_when&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;case_when&lt;/code&gt; function is useful for vectorizing conditional statements. It is similar to &lt;code&gt;ifelse&lt;/code&gt; but can output any number of values, as opposed to just &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;. Here is an example splitting numbers into negative, positive, and 0:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(-2, -1, 0, 1, 2)
case_when(x &amp;lt; 0 ~ &amp;quot;Negative&amp;quot;,
          x &amp;gt; 0 ~ &amp;quot;Positive&amp;quot;,
          x == 0  ~ &amp;quot;Zero&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Negative&amp;quot; &amp;quot;Negative&amp;quot; &amp;quot;Zero&amp;quot;     &amp;quot;Positive&amp;quot; &amp;quot;Positive&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A common use for this function is to define categorical variables based on existing variables. For example, suppose we want to compare the murder rates in four groups of states: &lt;em&gt;New England&lt;/em&gt;, &lt;em&gt;West Coast&lt;/em&gt;, &lt;em&gt;South&lt;/em&gt;, and &lt;em&gt;other&lt;/em&gt;. For each state, we need to ask if it is in New England, if it is not we ask if it is in the West Coast, if not we ask if it is in the South, and if not we assign &lt;em&gt;other&lt;/em&gt;. Here is how we use &lt;code&gt;case_when&lt;/code&gt; to do this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders %&amp;gt;%
  mutate(group = case_when(
    abb %in% c(&amp;quot;ME&amp;quot;, &amp;quot;NH&amp;quot;, &amp;quot;VT&amp;quot;, &amp;quot;MA&amp;quot;, &amp;quot;RI&amp;quot;, &amp;quot;CT&amp;quot;) ~ &amp;quot;New England&amp;quot;,
    abb %in% c(&amp;quot;WA&amp;quot;, &amp;quot;OR&amp;quot;, &amp;quot;CA&amp;quot;) ~ &amp;quot;West Coast&amp;quot;,
    region == &amp;quot;South&amp;quot; ~ &amp;quot;South&amp;quot;,
    TRUE ~ &amp;quot;Other&amp;quot;)) %&amp;gt;%
  group_by(group) %&amp;gt;%
  summarize(rate = sum(total) / sum(population) * 10^5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 × 2
##   group        rate
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 New England  1.72
## 2 Other        2.71
## 3 South        3.63
## 4 West Coast   2.90&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;between&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;between&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;A common operation in data analysis is to determine if a value falls inside an interval. We can check this using conditionals. For example, to check if the elements of a vector &lt;code&gt;x&lt;/code&gt; are between &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; we can type&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;gt;= a &amp;amp; x &amp;lt;= b&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this can become cumbersome, especially within the tidyverse approach. The &lt;code&gt;between&lt;/code&gt; function performs the same operation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;between(x, a, b)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Load the &lt;code&gt;murders&lt;/code&gt; dataset. Which of the following is true?&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;murders&lt;/code&gt; is in tidy format and is stored in a tibble.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;murders&lt;/code&gt; is in tidy format and is stored in a data frame.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;murders&lt;/code&gt; is not in tidy format and is stored in a tibble.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;murders&lt;/code&gt; is not in tidy format and is stored in a data frame.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Use &lt;code&gt;as_tibble&lt;/code&gt; to convert the &lt;code&gt;murders&lt;/code&gt; data table into a tibble and save it in an object called &lt;code&gt;murders_tibble&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the &lt;code&gt;group_by&lt;/code&gt; function to convert &lt;code&gt;murders&lt;/code&gt; into a tibble that is grouped by region.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Write tidyverse code that is equivalent to this code:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;exp(mean(log(murders$population)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Write it using the pipe so that each function is called without arguments. Use the dot operator to access the population. Hint: The code should start with &lt;code&gt;murders %&amp;gt;%&lt;/code&gt;.&lt;/p&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Use the &lt;code&gt;map_df&lt;/code&gt; to create a data frame with three columns named &lt;code&gt;n&lt;/code&gt;, &lt;code&gt;s_n&lt;/code&gt;, and &lt;code&gt;s_n_2&lt;/code&gt;. The first column should contain the numbers 1 through 100. The second and third columns should each contain the sum of 1 through &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; the row number.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;lecture-video&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Lecture Video&lt;/h2&gt;
&lt;p&gt;All videos are in the SSC442 Mediaspace channel &lt;a href=&#34;https://mediaspace.msu.edu/channel/SSC442+-+Spring+2021+-+KIRKPATRICK/199607633/subscribe&#34;&gt;available here &lt;i class=&#34;fas fa-film&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/p&gt;
&lt;!---
# Videos

`
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/D6WqHA8TDWQ&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
`{=html}
--&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;I discovered the &lt;code&gt;emo::ji()&lt;/code&gt; function at 8:55am. My wife joked that I would find a way to use the poop emoji by 9:00am. It is now 8:59am. She was right.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;If you have not installed this package already, you must use &lt;code&gt;install.packages(&#34;tidyverse&#34;)&lt;/code&gt; prior to the &lt;code&gt;library()&lt;/code&gt; call you see below.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualizations in Practice</title>
      <link>https://ssc442.netlify.app/content/04-content/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ssc442.netlify.app/content/04-content/</guid>
      <description>
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://ssc442.netlify.app/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#readings&#34;&gt;Readings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#guiding-questions&#34;&gt;Guiding Questions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-visualization-principles&#34;&gt;Data visualization principles&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#encoding-data-using-visual-cues&#34;&gt;Encoding data using visual cues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#avoid-psuedo-3d-plots&#34;&gt;Avoid Psuedo-3D Plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#avoid-too-many-significant-digits&#34;&gt;Avoid too many significant digits&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#know-your-audience&#34;&gt;Know your audience&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#know-when-to-include-0&#34;&gt;Know when to include 0&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#do-not-distort-quantities&#34;&gt;Do not distort quantities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#order-categories-by-a-meaningful-value&#34;&gt;Order categories by a meaningful value&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#show-the-data&#34;&gt;Show the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#faceting&#34;&gt;Faceting&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#use-common-axes-with-facets&#34;&gt;Use common axes with facets&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#align-plots-vertically-to-see-horizontal-changes-and-horizontally-to-see-vertical-changes&#34;&gt;Align plots vertically to see horizontal changes and horizontally to see vertical changes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#facet-grids&#34;&gt;Facet grids&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visual-cues-to-be-compared-should-be-adjacent-continued&#34;&gt;Visual cues to be compared should be adjacent, continued&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#use-color&#34;&gt;Use color&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#think-of-the-color-blind&#34;&gt;Think of the color blind&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#using-a-discrete-color-palette&#34;&gt;Using a discrete color palette&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-a-continuous-color-palette&#34;&gt;Using a continuous color palette&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#gridextra-and-grid.arrange&#34;&gt;gridExtra and &lt;code&gt;grid.arrange&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;readings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Readings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;This page.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;guiding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Guiding Questions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Why do we create visualizations? What types of data are best suited for visuals?&lt;/li&gt;
&lt;li&gt;How do we best visualize the variability in our data?&lt;/li&gt;
&lt;li&gt;What makes a visual compelling?&lt;/li&gt;
&lt;li&gt;What are the worst visuals? Which of these are most frequently used? Why?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As with last week’s content, the technical aspects of this lecture will be explored in greater detail in the Thursday practical lecture. Today, we will focus on some principles.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The greatest value of a picture is when it forces us to notice what we never expected to see.” – John Tukey&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;data-visualization-principles&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data visualization principles&lt;/h1&gt;
&lt;p&gt;We have already provided some rules to follow as we created plots for our examples. Here, we aim to provide some general principles we can use as a guide for effective data visualization. Much of this section is based on a talk by Karl Broman&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; titled “Creating Effective Figures and Tables”&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; and includes some of the figures which were made with code that Karl makes available on his GitHub repository&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, as well as class notes from Peter Aldhous’ Introduction to Data Visualization course&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;. Following Karl’s approach, we show some examples of plot styles we should avoid, explain how to improve them, and use these as motivation for a list of principles. We compare and contrast plots that follow these principles to those that don’t.&lt;/p&gt;
&lt;p&gt;The principles are mostly based on research related to how humans detect patterns and make visual comparisons. The preferred approaches are those that best fit the way our brains process visual information. When deciding on a visualization approach, it is also important to keep our goal in mind. We may be comparing a viewable number of quantities, describing distributions for categories or numeric values, comparing the data from two groups, or describing the relationship between two variables. As a final note, we want to emphasize that for a data scientist it is important to adapt and optimize graphs to the audience. For example, an exploratory plot made for ourselves will be different than a chart intended to communicate a finding to a general audience.&lt;/p&gt;
&lt;p&gt;As with the discussion above, we will be using these libraries—note the addition of &lt;strong&gt;gridExtra&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(dslabs)
library(gridExtra)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;encoding-data-using-visual-cues&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Encoding data using visual cues&lt;/h3&gt;
&lt;p&gt;We start by describing some principles for encoding data. There are several approaches at our disposal including position, aligned lengths, angles, area, brightness, and color hue.&lt;/p&gt;
&lt;p&gt;To illustrate how some of these strategies compare, let’s suppose we want to report the results from two hypothetical polls regarding browser preference taken in 2000 and then 2015. For each year, we are simply comparing five quantities – the five percentages. A widely used graphical representation of percentages, popularized by Microsoft Excel, is the pie chart:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/piechart-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we are representing quantities with both areas and angles, since both the angle and area of each pie slice are proportional to the quantity the slice represents. This turns out to be a sub-optimal choice since, as demonstrated by perception studies, humans are not good at precisely quantifying angles and are even worse when area is the only available visual cue. The donut chart is an example of a plot that uses only area:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/donutchart-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;To see how hard it is to quantify angles and area, note that the rankings and all the percentages in the plots above changed from 2000 to 2015. Can you determine the actual percentages and rank the browsers’ popularity? Can you see how the percentages changed from 2000 to 2015? It is not easy to tell from the plot. In fact, the &lt;code&gt;pie&lt;/code&gt; R function help file states that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pie charts are a very bad way of displaying information. The eye is good at judging linear measures and bad at judging relative areas. A bar chart or dot chart is a preferable way of displaying this type of data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this case, simply showing the numbers is not only clearer, but would also save on printing costs if printing a paper copy:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Browser
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2000
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
2015
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Opera
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Safari
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
22
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Firefox
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
23
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
21
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Chrome
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
26
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
29
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
IE
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
28
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
27
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The preferred way to plot these quantities is to use length and position as visual cues, since humans are much better at judging linear measures. The barplot uses this approach by using bars of length proportional to the quantities of interest. By adding horizontal lines at strategically chosen values, in this case at every multiple of 10, we ease the visual burden of quantifying through the position of the top of the bars. Compare and contrast the information we can extract from the two figures.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/two-barplots-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how much easier it is to see the differences in the barplot. In fact, we can now determine the actual percentages by following a horizontal line to the x-axis.&lt;/p&gt;
&lt;p&gt;If for some reason you need to make a pie chart, label each pie slice with its respective percentage so viewers do not have to infer them from the angles or area:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/excel-barplot-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In general, when displaying quantities, position and length are preferred over angles and/or area. Brightness and color are even harder to quantify than angles. But, as we will see later, they are sometimes useful when more than two dimensions must be displayed at once.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;avoid-psuedo-3d-plots&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Avoid Psuedo-3D Plots&lt;/h3&gt;
&lt;p&gt;The figure below, taken from the scientific literature&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;,
shows three variables: dose, drug type and survival. Although your screen/book page is flat and two-dimensional, the plot tries to imitate three dimensions and assigned a dimension to each variable.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/fig8b.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Image courtesy of Karl Broman)&lt;/p&gt;
&lt;p&gt;Humans are not good at seeing in three dimensions (which explains why it is hard to parallel park) and our limitation is even worse with regard to pseudo-three-dimensions. To see this, try to determine the values of the survival variable in the plot above. Can you tell when the purple ribbon intersects the red one? This is an example in which we can easily use color to represent the categorical variable instead of using a pseudo-3D:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;##First read data
url &amp;lt;- &amp;quot;https://github.com/kbroman/Talk_Graphs/raw/master/R/fig8dat.csv&amp;quot;
dat &amp;lt;- read.csv(url)

##Now make alternative plot
dat %&amp;gt;% gather(drug, survival, -log.dose) %&amp;gt;%
  mutate(drug = gsub(&amp;quot;Drug.&amp;quot;,&amp;quot;&amp;quot;,drug)) %&amp;gt;%
  ggplot(aes(log.dose, survival, color = drug)) +
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/colors-for-different-lines-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how much easier it is to determine the survival values.&lt;/p&gt;
&lt;p&gt;Pseudo-3D is sometimes used completely gratuitously: plots are made to look 3D even when the 3rd dimension does not represent a quantity. This only adds confusion and makes it harder to relay your message. Here are two examples:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/fig1e.png&#34; /&gt;
&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/fig2d.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Images courtesy of Karl Broman)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;avoid-too-many-significant-digits&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Avoid too many significant digits&lt;/h3&gt;
&lt;p&gt;By default, statistical software like R returns many significant digits. The default behavior in R is to show 7 significant digits. That many digits often adds no information and the added visual clutter can make it hard for the viewer to understand the message. As an example, here are the per 10,000 disease rates, computed from totals and population in R, for California across the five decades:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
state
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Measles
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pertussis
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Polio
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1940
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37.8826320
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.3397861
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8266512
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1950
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13.9124205
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.7467350
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.9742639
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1960
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.1386471
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2640419
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1970
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.9767889
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1980
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3743467
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.0515466
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;We are reporting precision up to 0.00001 cases per 10,000, a very small value in the context of the changes that are occurring across the dates. In this case, two significant figures is more than enough and clearly makes the point that rates are decreasing:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
state
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Measles
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Pertussis
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
Polio
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1940
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1950
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1960
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1970
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1980
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Useful ways to change the number of significant digits or to round numbers are &lt;code&gt;signif&lt;/code&gt; and &lt;code&gt;round&lt;/code&gt;. You can define the number of significant digits globally by setting options like this: &lt;code&gt;options(digits = 3)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Another principle related to displaying tables is to place values being compared on columns rather than rows. Note that our table above is easier to read than this one:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
state
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
disease
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1940
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1950
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1960
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1970
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
1980
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Measles
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
37.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
13.9
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
14.1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.4
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Pertussis
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
18.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4.7
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
California
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Polio
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.8
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2.0
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;know-your-audience&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Know your audience&lt;/h3&gt;
&lt;p&gt;Graphs can be used for 1) our own exploratory data analysis, 2) to convey a message to experts, or 3) to help tell a story to a general audience. Make sure that the intended audience understands each element of the plot.&lt;/p&gt;
&lt;p&gt;As a simple example, consider that for your own exploration it may be more useful to log-transform data and then plot it. However, for a general audience that is unfamiliar with converting logged values back to the original measurements, using a log-scale for the axis instead of log-transformed values will be much easier to digest.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;know-when-to-include-0&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Know when to include 0&lt;/h3&gt;
&lt;p&gt;When using barplots, it is misinformative not to start the bars at 0. This is because, by using a barplot, we are implying the length is proportional to the quantities being displayed. By avoiding 0, relatively small differences can be made to look much bigger than they actually are. This approach is often used by politicians or media organizations trying to exaggerate a difference. Below is an illustrative example used by Peter Aldhous in this lecture: &lt;a href=&#34;http://paldhous.github.io/ucb/2016/dataviz/week2.html&#34;&gt;http://paldhous.github.io/ucb/2016/dataviz/week2.html&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/class2_8.jpg&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Source: Fox News, via Media Matters&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;From the plot above, it appears that apprehensions have almost tripled when, in fact, they have only increased by about 16%. Starting the graph at 0 illustrates this clearly:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/barplot-from-zero-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is another example, described in detail in a Flowing Data blog post:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/Bush-cuts.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Source: Fox News, via Flowing Data&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;This plot makes a 13% increase look like a five fold change. Here is the appropriate plot:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/barplot-from-zero-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Finally, here is an extreme example that makes a very small difference of under 2% look like a 10-100 fold change:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/venezuela-election.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Source:
Venezolana de Televisión via Pakistan Today&lt;a href=&#34;#fn8&#34; class=&#34;footnote-ref&#34; id=&#34;fnref8&#34;&gt;&lt;sup&gt;8&lt;/sup&gt;&lt;/a&gt; and Diego Mariano.)&lt;/p&gt;
&lt;p&gt;Here is the appropriate plot:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/barplot-from-zero-3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;When using position rather than length, it is then not necessary to include 0. This is particularly the case when we want to compare differences between groups relative to the within-group variability. Here is an illustrative example showing country average life expectancy stratified across continents in 2012:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/points-plot-not-from-zero-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that in the plot on the left, which includes 0, the space between 0 and 43 adds no information and makes it harder to compare the between and within group variability.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;do-not-distort-quantities&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Do not distort quantities&lt;/h3&gt;
&lt;p&gt;During President Barack Obama’s 2011 State of the Union Address, the following chart was used to compare the US GDP to the GDP of four competing nations:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/state-of-the-union.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;(Source: The 2011 State of the Union Address&lt;a href=&#34;#fn9&#34; class=&#34;footnote-ref&#34; id=&#34;fnref9&#34;&gt;&lt;sup&gt;9&lt;/sup&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Judging by the area of the circles, the US appears to have an economy over five times larger than China’s and over 30 times larger than France’s. However, if we look at the actual numbers, we see that this is not the case. The actual ratios are 2.6 and 5.8 times bigger than China and France, respectively. The reason for this distortion is that the radius, rather than the area, was made to be proportional to the quantity, which implies that the proportion between the areas is squared: 2.6 turns into 6.5 and 5.8 turns into 34.1. Here is a comparison of the circles we get if we make the value proportional to the radius and to the area:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gdp &amp;lt;- c(14.6, 5.7, 5.3, 3.3, 2.5)
gdp_data &amp;lt;- data.frame(Country = rep(c(&amp;quot;United States&amp;quot;, &amp;quot;China&amp;quot;, &amp;quot;Japan&amp;quot;, &amp;quot;Germany&amp;quot;, &amp;quot;France&amp;quot;),2),
           y = factor(rep(c(&amp;quot;Radius&amp;quot;,&amp;quot;Area&amp;quot;),each=5), levels = c(&amp;quot;Radius&amp;quot;, &amp;quot;Area&amp;quot;)),
           GDP= c(gdp^2/min(gdp^2), gdp/min(gdp))) %&amp;gt;%
   mutate(Country = reorder(Country, GDP))
gdp_data %&amp;gt;%
  ggplot(aes(Country, y, size = GDP)) +
  geom_point(show.legend = FALSE, color = &amp;quot;blue&amp;quot;) +
  scale_size(range = c(2,25)) +
  coord_flip() +
  ylab(&amp;quot;&amp;quot;) + xlab(&amp;quot;&amp;quot;) # identical to labs(y = &amp;quot;&amp;quot;, x = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/area-not-radius-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not surprisingly, &lt;strong&gt;ggplot2&lt;/strong&gt; defaults to using area rather than
radius. Of course, in this case, we really should not be using area at all since we can use position and length:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gdp_data %&amp;gt;%
  filter(y == &amp;quot;Area&amp;quot;) %&amp;gt;%
  ggplot(aes(Country, GDP)) +
  geom_bar(stat = &amp;quot;identity&amp;quot;, width = 0.5) +
  labs(y = &amp;quot;GDP in trillions of US dollars&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/barplot-better-than-area-1.png&#34; width=&#34;50%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;order-categories-by-a-meaningful-value&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Order categories by a meaningful value&lt;/h3&gt;
&lt;p&gt;When one of the axes is used to show categories, as is done in barplots, the default &lt;strong&gt;ggplot2&lt;/strong&gt; behavior is to order the categories alphabetically when they are defined by character strings. If they are defined by factors, they are ordered by the factor levels. We rarely want to use alphabetical order. Instead, we should order by a meaningful quantity. In all the cases above, the barplots were ordered by the values being displayed. The exception was the graph showing barplots comparing browsers. In this case, we kept the order the same across the barplots to ease the comparison. Specifically, instead of ordering the browsers separately in the two years, we ordered both years by the average value of 2000 and 2015.&lt;/p&gt;
&lt;p&gt;We previously learned how to use the &lt;code&gt;reorder&lt;/code&gt; function, which helps us achieve this goal.
To appreciate how the right order can help convey a message, suppose we want to create a plot to compare the murder rate across states. We are particularly interested in the most dangerous and safest states. Note the difference when we order alphabetically (the default) versus when we order by the actual rate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(murders)
p1 &amp;lt;- murders %&amp;gt;% mutate(murder_rate = total / population * 100000) %&amp;gt;%
  ggplot(aes(x = state, y = murder_rate)) +
  geom_bar(stat=&amp;quot;identity&amp;quot;) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 8))  +
  xlab(&amp;quot;&amp;quot;)

p2 &amp;lt;- murders %&amp;gt;% mutate(murder_rate = total / population * 100000) %&amp;gt;%
  mutate(state = reorder(state, murder_rate)) %&amp;gt;% # here&amp;#39;s the magic!
  ggplot(aes(x = state, y = murder_rate)) +
  geom_bar(stat=&amp;quot;identity&amp;quot;) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 8))  +
  xlab(&amp;quot;&amp;quot;)

grid.arrange(p1, p2, ncol = 2) # we&amp;#39;ll cover this later&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/do-not-order-alphabetically-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can make the second plot like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(murders)
murders %&amp;gt;% mutate(murder_rate = total / population * 100000) %&amp;gt;%
  mutate(state = reorder(state, murder_rate)) %&amp;gt;%
  ggplot(aes(state, murder_rate)) +
  geom_bar(stat=&amp;quot;identity&amp;quot;) +
  coord_flip() +
  theme(axis.text.y = element_text(size = 6)) +
  xlab(&amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;reorder&lt;/code&gt; function lets us reorder groups as well. Earlier we saw an example related to income distributions across regions. Here are the two versions plotted against each other:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/reorder-boxplot-example-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first orders the regions alphabetically, while the second orders them by the group’s median.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;show-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Show the data&lt;/h2&gt;
&lt;p&gt;We have focused on displaying single quantities across categories. We now shift our attention to displaying data, with a focus on comparing groups.&lt;/p&gt;
&lt;p&gt;To motivate our first principle, “show the data”, we go back to our artificial example of describing heights to a person who is unaware of some basic facts about the population of interest (and is otherwise unsophisticated). This time let’s assume that this person is interested in the difference in heights between males and females. A commonly seen plot used for comparisons between groups, popularized by software such as Microsoft Excel, is the dynamite plot, which shows the average and standard errors.&lt;a href=&#34;#fn10&#34; class=&#34;footnote-ref&#34; id=&#34;fnref10&#34;&gt;&lt;sup&gt;10&lt;/sup&gt;&lt;/a&gt; The plot looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/show-data-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The average of each group is represented by the top of each bar and the antennae extend out from the average to the average plus two standard errors. If all ET receives is this plot, he will have little information on what to expect if he meets a group of human males and females. The bars go to 0: does this mean there are tiny humans measuring less than one foot? Are all males taller than the tallest females? Is there a range of heights? ET can’t answer these questions since we have provided almost no information on the height distribution.&lt;/p&gt;
&lt;p&gt;This brings us to our first principle: show the data. This simple &lt;strong&gt;ggplot2&lt;/strong&gt; code already generates a more informative plot than the barplot by simply showing all the data points:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  ggplot(aes(sex, height)) +
  geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/show-data-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For example, this plot gives us an idea of the range of the data. However, this plot has limitations as well, since we can’t really see all the 238 and 812 points plotted for females and males, respectively, and many points are plotted on top of each other. As we have previously described, visualizing the distribution is much more informative. But before doing this, we point out two ways we can improve a plot showing all the points.&lt;/p&gt;
&lt;p&gt;The first is to add &lt;em&gt;jitter&lt;/em&gt;, which adds a small random shift to each point. In this case, adding horizontal jitter does not alter the interpretation, since the point heights do not change, but we minimize the number of points that fall on top of each other and, therefore, get a better visual sense of how the data is distributed. A second improvement comes from using &lt;em&gt;alpha blending&lt;/em&gt;: making the points somewhat transparent. The more points fall on top of each other, the darker the plot, which also helps us get a sense of how the points are distributed. Here is the same plot with jitter and alpha blending:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  ggplot(aes(sex, height)) +
  geom_jitter(width = 0.1, alpha = 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/show-points-with-jitter-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now we start getting a sense that, on average, males are taller than females. We also note dark horizontal bands of points, demonstrating that many report values that are rounded to the nearest integer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;faceting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Faceting&lt;/h2&gt;
&lt;p&gt;Looking at the previous plot, it’s easy to tell that males tend to be taller than females. Before, we showed how we can plot two distributions over each other using an aesthetic mapping. Something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  ggplot(aes(x = height, fill = sex)) +
  geom_histogram(alpha = .5, show.legend = TRUE) +
  labs(fill = &amp;#39;Sex&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;
Sometimes, putting the plots on top of each other, even with a well-chosen alpha, does not clearly communicate the differences in the distribution. When we want to compare side-by-side, we will often use &lt;strong&gt;facets&lt;/strong&gt;. Facets are a bit like supercharged aesthetic mapping because they let us separate plots based on categorical variables, but instead of putting them together, we can have side-by-side plots.&lt;/p&gt;
&lt;p&gt;Two functions in &lt;code&gt;ggplot&lt;/code&gt; give facets: &lt;code&gt;facet_wrap&lt;/code&gt; and &lt;code&gt;facet_grid&lt;/code&gt;. We’ll use &lt;code&gt;facet_grid&lt;/code&gt; as this is a little more powerful.&lt;/p&gt;
&lt;p&gt;Facets are added as an additional layer like this: &lt;code&gt;+ facet_grid(. ~ sex)&lt;/code&gt;. Inside the function, we have a “formula” that is written without quotes (which is unusual for R). Since &lt;code&gt;facet_grid&lt;/code&gt; takes a “formula”, all we have to do to facet is decide how we want to lay out our plots. If we want each of the faceting groups to lie along the vertical axis, we put the variable on which we want to facet before the “~”, and after the “~” we simply put a period. If we want the groups to lie along the horizontal axis, we put the variable after the “~” and the period before. In the example, we’ll separate the histogram by drawing them side by side along the horizontal axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  ggplot(aes(x = height)) +
  geom_histogram(binwidth = 1, color=&amp;quot;black&amp;quot;) +
  facet_grid(.~sex)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; /&gt;
This would be the result if we took the females, plotted the histogram, then took the males, made another histogram, and then put them side by side. But we do it in one command by adding &lt;code&gt;+facet_grid(...)&lt;/code&gt;&lt;/p&gt;
&lt;div id=&#34;use-common-axes-with-facets&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use common axes with facets&lt;/h3&gt;
&lt;p&gt;Since we have plots side-by-side, they can have different scales along the x-axis (or along the y-axis if we were stacking with &lt;code&gt;sex ~ .&lt;/code&gt;). We want to be careful here - if we don’t have matching scales on these axes, then it’ll be really hard to visually see differences in the distribution.&lt;/p&gt;
&lt;p&gt;As an example of what not to do, and to show that we can use the &lt;code&gt;scales&lt;/code&gt; argument in &lt;code&gt;facet_grid&lt;/code&gt;, we can allow the x-axis to freely scale between the plots. This makes it hard to tell that males are, on average, taller because the average male height, despite being larger than the average female height (70 vs. 65 or so) &lt;em&gt;falls in the same location within the plot box&lt;/em&gt;. Note that 80 is the extreme edge for the left plot, but not in the right plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, color=&amp;quot;black&amp;quot;) +
  facet_grid(. ~ sex, scales = &amp;quot;free_x&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/common-axes-histograms-wrong-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;align-plots-vertically-to-see-horizontal-changes-and-horizontally-to-see-vertical-changes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Align plots vertically to see horizontal changes and horizontally to see vertical changes&lt;/h3&gt;
&lt;p&gt;In these histograms, the visual cue related to decreases or increases in height are shifts to the left or right, respectively: horizontal changes. Aligning the plots vertically helps us see this change when the axes are fixed:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;heights %&amp;gt;%
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, color=&amp;quot;black&amp;quot;) +
  facet_grid(. ~ sex)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/common-axes-histograms-right-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- heights %&amp;gt;%
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, color=&amp;quot;black&amp;quot;) +
  facet_grid(sex~.)
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot makes it much easier to notice that men’s heights are, on average, higher.&lt;/p&gt;
&lt;p&gt;The sample size of females is smaller than of males – that is, we have more males in the data. Try &lt;code&gt;table(heights$sex)&lt;/code&gt; to see this. It’s also clear from the above plot because the height of the bars on the y-axis (&lt;code&gt;count&lt;/code&gt;) are smaller for females. If we are interested in the distribution within our sample, this is useful. If we’re interested in the distribution of females vs. the distribution of males, we might want to re-scale the y-axis.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;- heights %&amp;gt;%
  ggplot(aes(height)) +
  geom_histogram(binwidth = 1, color=&amp;quot;black&amp;quot;) +
  facet_grid(sex~., scales = &amp;#39;free_y&amp;#39;)
p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We still have &lt;code&gt;count&lt;/code&gt; on the y-axis, so we didn’t switch to density (though it would look the same). Instead, we rescaled the y-axis, which gives us a different perspective but still contains the count information.&lt;/p&gt;
&lt;p&gt;If we want the more compact summary provided by boxplots, we then align them horizontally since, by default, boxplots move up and down with changes in height. Following our &lt;em&gt;show the data&lt;/em&gt; principle, we then overlay all the data points:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 &amp;lt;- heights %&amp;gt;%
  ggplot(aes(sex, height)) +
  geom_boxplot(coef=3) +
  geom_jitter(width = 0.1, alpha = 0.2) +
  ylab(&amp;quot;Height in inches&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now contrast and compare these three plots, based on exactly the same data:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/show-the-data-comparison-1.png&#34; width=&#34;100%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how much more we learn from the two plots on the right. Barplots are useful for showing one number, but not very useful when we want to describe distributions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;facet-grids&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Facet grids&lt;/h3&gt;
&lt;p&gt;As the name implies, &lt;code&gt;facet_grid&lt;/code&gt; can make more than just side-by-plots. If we specify variables on boths sides of the “~”, we get a grid of plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gapminder::gapminder %&amp;gt;%
  filter(year %in% c(1952,1972, 1992, 2002)) %&amp;gt;%
  filter(continent != &amp;#39;Oceania&amp;#39;) %&amp;gt;%
  ggplot(aes(x = lifeExp)) +
  geom_density() +
  facet_grid(continent ~ year)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This makes it easy to read the life expectancy distribution over time (left-to-right) and across continents (up-and-down). It makes it easy to see that Africa has spread it’s life expectancy distribution (some improved, some didn’t), while Europe has become more clustered at the top end over time. Faceting in a grid is very helpful when you have a time dimension.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visual-cues-to-be-compared-should-be-adjacent-continued&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visual cues to be compared should be adjacent, continued&lt;/h3&gt;
&lt;p&gt;For each continent, let’s compare income in 1970 versus 2010. When comparing income data across regions between 1970 and 2010, we made a figure similar to the one below, but this time we investigate continents rather than regions.&lt;/p&gt;
&lt;p&gt;Note that there are two &lt;code&gt;gapminder&lt;/code&gt; datasets, one in &lt;code&gt;dslabs&lt;/code&gt; and one in the &lt;code&gt;gapminder&lt;/code&gt; package. The &lt;code&gt;dslabs&lt;/code&gt; version has more data, so I will switch to that here by using &lt;code&gt;dslabs::gapminder&lt;/code&gt; as our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dslabs::gapminder %&amp;gt;%
  filter(year %in% c(1970, 2010) &amp;amp; !is.na(gdp)) %&amp;gt;%
  mutate(dollars_per_day = gdp/population/365) %&amp;gt;%
  mutate(labels = paste(year, continent)) %&amp;gt;%  # creating text labels
  ggplot(aes(x = labels, y = dollars_per_day)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.25)) +
  scale_y_continuous(trans = &amp;quot;log2&amp;quot;) +
  ylab(&amp;quot;Income in dollars per day&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/boxplots-not-adjacent-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The default in &lt;strong&gt;ggplot2&lt;/strong&gt; is to order labels alphabetically so the labels with 1970 come before the labels with 2010, making the comparisons challenging because a continent’s distribution in 1970 is visually far from its distribution in 2010. It is much easier to make the comparison between 1970 and 2010 for each continent when the boxplots for that continent are next to each other:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dslabs::gapminder %&amp;gt;%
  filter(year %in% c(1970, 2010) &amp;amp; !is.na(gdp)) %&amp;gt;%
  mutate(dollars_per_day = gdp/population/365) %&amp;gt;%
  mutate(labels = paste(continent, year)) %&amp;gt;%
  ggplot(aes(labels, dollars_per_day)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .25)) +
  scale_y_continuous(trans = &amp;quot;log2&amp;quot;) +
  ylab(&amp;quot;Income in dollars per day&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/boxplot-adjacent-comps-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;use-color&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Use color&lt;/h3&gt;
&lt;p&gt;The comparison becomes even easier to make if we use color to denote the two things we want to compare. Now we do not have to make the labels column and can just use &lt;code&gt;continent&lt;/code&gt; on the x-axis:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/boxplot-adjacent-comps-with-color-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;think-of-the-color-blind&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Think of the color blind&lt;/h2&gt;
&lt;p&gt;About 10% of the population is color blind. Unfortunately, the default colors used in &lt;strong&gt;ggplot2&lt;/strong&gt; are not optimal for this group. However, &lt;strong&gt;ggplot2&lt;/strong&gt; does make it easy to change the color palette used in the plots. An example of how we can use a color blind friendly palette is described here: &lt;a href=&#34;http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette&#34;&gt;http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette&lt;/a&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color_blind_friendly_cols &amp;lt;-
  c(&amp;quot;#999999&amp;quot;, &amp;quot;#E69F00&amp;quot;, &amp;quot;#56B4E9&amp;quot;, &amp;quot;#009E73&amp;quot;,
    &amp;quot;#F0E442&amp;quot;, &amp;quot;#0072B2&amp;quot;, &amp;quot;#D55E00&amp;quot;, &amp;quot;#CC79A7&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the colors
&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/color-blind-friendly-colors-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From &lt;a href=&#34;http://www.pnas.org/content/pnas/early/2017/01/24/1617948114.full.pdf&#34;&gt;Seafood Prices Reveal Impacts of a Major Ecological Disturbance&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/Colorblind_example.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There are several resources that can help you select colors, for example this one: &lt;a href=&#34;http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/&#34;&gt;http://bconnelly.net/2013/10/creating-colorblind-friendly-figures/&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;using-a-discrete-color-palette&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using a discrete color palette&lt;/h3&gt;
&lt;p&gt;If you’re simply trying to differentiate between groups by using color, there are many ways of changing your color palette in &lt;code&gt;ggplot&lt;/code&gt;. Most use &lt;code&gt;scale_fill_discrete&lt;/code&gt; or &lt;code&gt;scale_color_discrete&lt;/code&gt; (depending on the aesthetic for which you’re setting the color).&lt;/p&gt;
&lt;p&gt;The easiest way of getting good-looking (e.g. non-default) colors is the &lt;code&gt;scale_fill_viridis_d&lt;/code&gt; function, which “inherits” (takes the place of and has the properties of) &lt;code&gt;scale_fill_discrete&lt;/code&gt;. Viridis has four color palettes and each is designed to be used to maximize the differentiation between colors.&lt;/p&gt;
&lt;p&gt;We will subset our &lt;code&gt;dslabs::gapminder&lt;/code&gt; dataset to five different years and take a look at what Viridis colors can do across those five:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp = dslabs::gapminder %&amp;gt;%
filter(year == 1990 | year == 1995 | year==2000 |  year == 2005 | year==2010 ) %&amp;gt;%
ggplot(aes(x = continent, y = gdp/population, fill = as.factor(year)))  + coord_flip()

gp + geom_boxplot()  + labs(title = &amp;#39;Default&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The default uses five different colors plucked seemingly at random. They are actually drawn from a palette of default ggplot colors.&lt;/p&gt;
&lt;p&gt;Let’s try Viridis&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp = dslabs::gapminder %&amp;gt;%
filter(year == 1990 | year == 1995 | year==2000 |  year == 2005 | year==2010 ) %&amp;gt;%
ggplot(aes(x = continent, y = gdp/population, fill = as.factor(year)))  + coord_flip() + labs(fill = &amp;#39;Year&amp;#39;)

viridis_a = gp + geom_boxplot()  + labs(title = &amp;#39;Viridis A&amp;#39;) + scale_fill_viridis_d(option = &amp;#39;A&amp;#39;)
viridis_b = gp + geom_boxplot()  + labs(title = &amp;#39;Viridis B&amp;#39;) + scale_fill_viridis_d(option = &amp;#39;B&amp;#39;)
viridis_c = gp + geom_boxplot()  + labs(title = &amp;#39;Viridis C&amp;#39;) + scale_fill_viridis_d(option = &amp;#39;C&amp;#39;)
viridis_d = gp + geom_boxplot()  + labs(title = &amp;#39;Viridis D&amp;#39;) + scale_fill_viridis_d(option = &amp;#39;D&amp;#39;)

grid.arrange(viridis_a, viridis_b, viridis_c, viridis_d)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Viridis uses a better palette of colors that, though distinct, have some cohesiveness to them.&lt;/p&gt;
&lt;p&gt;We can also use a custom palette, like the colorblind palette from before. If the palette has more entries than we have (N) distinct categories, R reverts to the default.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gp = dslabs::gapminder %&amp;gt;%
filter(year == 1990 | year == 1995 | year==2000 |  year == 2005 | year==2010 ) %&amp;gt;%
ggplot(aes(x = continent, y = gdp/population, fill = as.factor(year)))  + coord_flip() + labs(fill = &amp;#39;Year&amp;#39;)

custom_a = gp + geom_boxplot()  + labs(title = &amp;#39;Viridis A&amp;#39;) + scale_fill_discrete(type = color_blind_friendly_cols)
custom_b = gp + geom_boxplot()  + labs(title = &amp;#39;Viridis A&amp;#39;) + scale_fill_discrete(type = color_blind_friendly_cols[1:3])

grid.arrange(custom_a, custom_b)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the lower plot, we only give it a length-3 vector of colors, and it needs 5, so it returns to default.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-a-continuous-color-palette&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Using a continuous color palette&lt;/h3&gt;
&lt;p&gt;We may often want to use the color to indicate a numeric value instead of simply using it to delineate groupings. When this is the case, the &lt;code&gt;fill&lt;/code&gt; or &lt;code&gt;color&lt;/code&gt; aesthetic is set to a continuous value. For instance, if one were to plot election results by precinct, we may represent precincts with heavy Republican support as dark red, swing districts as purple or white, and Democratic districts as blue. The intensity of red/blue indicates how heavily slanted votes in that precinct were in the election. This is known as a &lt;em&gt;color ramp&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Lets plot one country’s GDP by year, but have the color indicate the life expectancy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dslabs::gapminder %&amp;gt;%
  filter(country==&amp;#39;Romania&amp;#39; &amp;amp; year&amp;gt;1980) %&amp;gt;%
  ggplot(aes(x = year, y = gdp/population, color = life_expectancy)) +
  scale_fill_continuous() +
  geom_point(size = 5) +
  labs(x = &amp;#39;Year&amp;#39;, y = &amp;#39;GDP Per Capita&amp;#39;, fill = &amp;#39;Life Expectancy&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We can see that GDP per capita went up, then down in 1989 (fall of the Soviet Union), then up after that. The color ramp tells us that life expectancy reached 75 years near the end, and it certainly improved in the post-2000 era.&lt;/p&gt;
&lt;p&gt;We can set some of the points on the ramp manually - here, the ramp starts at dark blue and ends at light blue, but what if we wanted to start at red, and at blue, and cross white in the middle? Easy! We use &lt;code&gt;scale_color_gradient2&lt;/code&gt; and specify the colors for low, mid, and high, and specify the midpoint at 72.5 years.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dslabs::gapminder %&amp;gt;%
  filter(country==&amp;#39;Romania&amp;#39; &amp;amp; year&amp;gt;1980) %&amp;gt;%
  ggplot(aes(x = year, y = gdp/population, color = life_expectancy)) +
  scale_color_gradient2(low = &amp;#39;red&amp;#39;, mid = &amp;#39;white&amp;#39;, high = &amp;#39;blue&amp;#39;, midpoint = 72.5) +
  geom_point(size = 5) +
  labs(x = &amp;#39;Year&amp;#39;, y = &amp;#39;GDP Per Capita&amp;#39;, fill = &amp;#39;Life Expectancy&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The midpoint specification is extra useful when there is a threshold (like 50% of the vote) that indicates a different qualitative outcome.&lt;/p&gt;
&lt;p&gt;The gradient2 method does not always work with the colorblind discrete palette - the colors interpolated may be in the range in which colorblindness tends to be a problem:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dslabs::gapminder %&amp;gt;%
  filter(country==&amp;#39;Romania&amp;#39; &amp;amp; year&amp;gt;1980) %&amp;gt;%
  ggplot(aes(x = year, y = gdp/population, color = life_expectancy)) +
  scale_color_gradient2(low = color_blind_friendly_cols[3], mid = color_blind_friendly_cols[4], high = color_blind_friendly_cols[5], midpoint = 72.5) +
  geom_point(size = 5) +
  labs(x = &amp;#39;Year&amp;#39;, y = &amp;#39;GDP Per Capita&amp;#39;, fill = &amp;#39;Life Expectancy&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/04-content_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;gridextra-and-grid.arrange&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;gridExtra and &lt;code&gt;grid.arrange&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;The &lt;code&gt;gridExtra&lt;/code&gt; package has been used a few times in this lesson to combine plots using the &lt;code&gt;grid.arrange&lt;/code&gt; function. The use is pretty intuitive - you save your plots as objects &lt;code&gt;plot1 &amp;lt;- ggplot(data, aes(x = var1))&lt;/code&gt; and &lt;code&gt;plot2 &amp;lt;- ggplot(data, aes(x = var2))&lt;/code&gt;, and then use &lt;code&gt;grid.arrange(plot1, plot2)&lt;/code&gt; to combine. The function will align as best it can, and there are more advanced &lt;a href=&#34;https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html&#34;&gt;grob-based functions&lt;/a&gt; that can adjust and align axes between plots, but we won’t get into them. If we want to set the layout, we can specify &lt;code&gt;nrow&lt;/code&gt; and &lt;code&gt;ncol&lt;/code&gt; to set the rows and columns.&lt;/p&gt;
&lt;p&gt;The very-useful &lt;code&gt;patchwork&lt;/code&gt; package is quickly replacing &lt;code&gt;grid.arrange&lt;/code&gt; and provides more flexibility.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://kbroman.org/&#34; class=&#34;uri&#34;&gt;http://kbroman.org/&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.biostat.wisc.edu/~kbroman/presentations/graphs2017.pdf&#34; class=&#34;uri&#34;&gt;https://www.biostat.wisc.edu/~kbroman/presentations/graphs2017.pdf&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://github.com/kbroman/Talk_Graphs&#34; class=&#34;uri&#34;&gt;https://github.com/kbroman/Talk_Graphs&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://paldhous.github.io/ucb/2016/dataviz/index.html&#34; class=&#34;uri&#34;&gt;http://paldhous.github.io/ucb/2016/dataviz/index.html&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://projecteuclid.org/download/pdf_1/euclid.ss/1177010488&#34; class=&#34;uri&#34;&gt;https://projecteuclid.org/download/pdf_1/euclid.ss/1177010488&lt;/a&gt;&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://mediamatters.org/blog/2013/04/05/fox-news-newest-dishonest-chart-immigration-enf/193507&#34; class=&#34;uri&#34;&gt;http://mediamatters.org/blog/2013/04/05/fox-news-newest-dishonest-chart-immigration-enf/193507&lt;/a&gt;&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://flowingdata.com/2012/08/06/fox-news-continues-charting-excellence/&#34; class=&#34;uri&#34;&gt;http://flowingdata.com/2012/08/06/fox-news-continues-charting-excellence/&lt;/a&gt;&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn8&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.pakistantoday.com.pk/2018/05/18/whats-at-stake-in-venezuelan-presidential-vote&#34; class=&#34;uri&#34;&gt;https://www.pakistantoday.com.pk/2018/05/18/whats-at-stake-in-venezuelan-presidential-vote&lt;/a&gt;&lt;a href=&#34;#fnref8&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn9&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=kl2g40GoRxg&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=kl2g40GoRxg&lt;/a&gt;&lt;a href=&#34;#fnref9&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn10&#34;&gt;&lt;p&gt;If you’re unfamiliar, standard errors are defined later in the course—do not confuse them with the standard deviation of the data.&lt;a href=&#34;#fnref10&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Probability and Statistics</title>
      <link>https://ssc442.netlify.app/content/05-content/</link>
      <pubDate>Tue, 09 Feb 2021 00:00:00 +0000</pubDate>
      <guid>https://ssc442.netlify.app/content/05-content/</guid>
      <description>
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#required-reading&#34;&gt;Required Reading&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#supplemental-readings&#34;&gt;Supplemental Readings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#guiding-questions&#34;&gt;Guiding Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#discrete-probability&#34;&gt;Discrete probability&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#relative-frequency&#34;&gt;Relative frequency&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#notation&#34;&gt;Notation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#probability-distributions&#34;&gt;Probability distributions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#monte-carlo-simulations-for-categorical-data&#34;&gt;Monte Carlo simulations for categorical data&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#setting-the-random-seed&#34;&gt;Setting the random seed&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#with-and-without-replacement&#34;&gt;With and without replacement&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#independence&#34;&gt;Independence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conditional-probabilities&#34;&gt;Conditional probabilities&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#addition-and-multiplication-rules&#34;&gt;Addition and multiplication rules&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#multiplication-rule&#34;&gt;Multiplication rule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#multiplication-rule-under-independence&#34;&gt;Multiplication rule under independence&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#addition-rule&#34;&gt;Addition rule&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combinations-and-permutations&#34;&gt;Combinations and permutations&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#monte-carlo-example&#34;&gt;Monte Carlo example&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#examples&#34;&gt;Examples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#monty-hall-problem&#34;&gt;Monty Hall problem&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#birthday-problem&#34;&gt;Birthday problem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#infinity-in-practice&#34;&gt;Infinity in practice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#theoretical-continuous-distributions&#34;&gt;Theoretical continuous distributions&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#theoretical-distributions-as-approximations&#34;&gt;Theoretical distributions as approximations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-probability-density&#34;&gt;The probability density&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#monte-carlo-simulations-for-continuous-variables&#34;&gt;Monte Carlo simulations for continuous variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#continuous-distributions&#34;&gt;Continuous distributions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#random-variables&#34;&gt;Random variables&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#definition-of-random-variables&#34;&gt;Definition of Random variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sampling-models&#34;&gt;Sampling models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-probability-distribution-of-a-random-variable&#34;&gt;The probability distribution of a random variable&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#distributions-versus-probability-distributions&#34;&gt;Distributions versus probability distributions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#notation-for-random-variables&#34;&gt;Notation for random variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-expected-value-and-standard-error&#34;&gt;The expected value and standard error&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#population-sd-versus-the-sample-sd&#34;&gt;Population SD versus the sample SD&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#central-limit-theorem&#34;&gt;Central Limit Theorem&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#how-large-is-large-in-the-central-limit-theorem&#34;&gt;How large is large in the Central Limit Theorem?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#statistical-properties-of-averages&#34;&gt;Statistical properties of averages&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#law-of-large-numbers&#34;&gt;Law of large numbers&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#misinterpreting-law-of-averages&#34;&gt;Misinterpreting law of averages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;required-reading&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Required Reading&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;This page.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;supplemental-readings&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Supplemental Readings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i class=&#34;fas fa-external-link-square-alt&#34;&gt;&lt;/i&gt; &lt;a href=&#34;https://hbr.org/2016/11/why-its-so-hard-for-us-to-visualize-uncertainty&#34;&gt;Why It’s So Hard for Us to Visualize Uncertainty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;i class=&#34;fab fa-youtube&#34;&gt;&lt;/i&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=0L1tGo-DvD0&#34;&gt;Amanda Cox’s keynote address at the 2017 OpenVis Conf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;i class=&#34;fas fa-external-link-square-alt&#34;&gt;&lt;/i&gt; &lt;a href=&#34;https://eagereyes.org/blog/2017/communicating-uncertainty-when-lives-are-on-the-line&#34;&gt;Communicating Uncertainty When Lives Are on the Line&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;i class=&#34;fas fa-external-link-square-alt&#34;&gt;&lt;/i&gt; &lt;a href=&#34;https://flowingdata.com/2016/11/15/showing-uncertainty-during-the-live-election-forecast/&#34;&gt;Showing uncertainty during the live election forecast&lt;/a&gt; &amp;amp; &lt;a href=&#34;https://flowingdata.com/2017/06/27/trolling-the-uncertainty-dial/&#34;&gt;Trolling the uncertainty dial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;guiding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Guiding Questions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Why is uncertainty inherently a major part of data analytics?&lt;/li&gt;
&lt;li&gt;How have past attempts to visualize uncertainty failed?&lt;/li&gt;
&lt;li&gt;What is the right way to visualize election uncertainty?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As with last week, today’s lecture will ask you to work with &lt;code&gt;R&lt;/code&gt; during the lecture.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;discrete-probability&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Discrete probability&lt;/h1&gt;
&lt;p&gt;We start by covering some basic principles related to categorical data. The subset of probability is referred to as &lt;em&gt;discrete probability&lt;/em&gt;. It will help us understand the probability theory we will later introduce for numeric and continuous data, which is much more common in data science applications. Discrete probability is more useful in card games and therefore we use these as examples.&lt;/p&gt;
&lt;div id=&#34;relative-frequency&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Relative frequency&lt;/h3&gt;
&lt;p&gt;The word probability is used in everyday language. Answering questions about probability is often hard, if not impossible. Here we discuss a mathematical definition of &lt;em&gt;probability&lt;/em&gt; that does permit us to give precise answers to certain questions.&lt;/p&gt;
&lt;p&gt;For example, if I have 2 red beads and 3 blue beads inside an urn&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; (most probability books use this archaic term, so we do too) and I pick one at random, what is the probability of picking a red one? Our intuition tells us that the answer is 2/5 or 40%. A precise definition can be given by noting that there are five possible outcomes of which two satisfy the condition necessary for the event “pick a red bead”. Since each of the five outcomes has the same chance of occurring, we conclude that the probability is .4 for red and .6 for blue.&lt;/p&gt;
&lt;p&gt;A more tangible way to think about the probability of an event is as the proportion of times the event occurs when we repeat the experiment an infinite number of times, independently, and under the same conditions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;notation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Notation&lt;/h3&gt;
&lt;p&gt;We use the notation &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(A)\)&lt;/span&gt; to denote the probability of event &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; happening. We use the very general term &lt;em&gt;event&lt;/em&gt; to refer to things that can happen when something occurs by chance. In our previous example, the event was “picking a red bead”. In a political poll in which we call 100 likely voters at random, an example of an event is “calling 48 Democrats and 52 Republicans”.&lt;/p&gt;
&lt;p&gt;In data science applications, we will often deal with continuous variables. These events will often be things like “is this person taller than 6 feet”. In this case, we write events in a more mathematical form: &lt;span class=&#34;math inline&#34;&gt;\(X \geq 6\)&lt;/span&gt;. We will see more of these examples later. Here we focus on categorical data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;probability-distributions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Probability distributions&lt;/h3&gt;
&lt;p&gt;If we know the relative frequency of the different categories, defining a distribution for categorical outcomes is relatively straightforward. We simply assign a probability to each category. In cases that can be thought of as beads in an urn, for each bead type, their proportion defines the distribution.&lt;/p&gt;
&lt;p&gt;If we are randomly calling likely voters from a population that is 44% Democrat, 44% Republican, 10% undecided, and 2% Green Party, these proportions define the probability for each group. The probability distribution is:&lt;/p&gt;
&lt;table&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Pr(picking a Republican)&lt;/td&gt;
&lt;td&gt;=&lt;/td&gt;
&lt;td&gt;0.44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Pr(picking a Democrat)&lt;/td&gt;
&lt;td&gt;=&lt;/td&gt;
&lt;td&gt;0.44&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;Pr(picking an undecided)&lt;/td&gt;
&lt;td&gt;=&lt;/td&gt;
&lt;td&gt;0.10&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Pr(picking a Green)&lt;/td&gt;
&lt;td&gt;=&lt;/td&gt;
&lt;td&gt;0.02&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;monte-carlo-simulations-for-categorical-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monte Carlo simulations for categorical data&lt;/h2&gt;
&lt;p&gt;Computers provide a way to actually perform the simple random experiment described above: pick a bead at random from a bag that contains three blue beads and two red ones. Random number generators permit us to mimic the process of picking at random.&lt;/p&gt;
&lt;p&gt;An example is the &lt;code&gt;sample&lt;/code&gt; function in R. We demonstrate its use in the code below. First, we use the function &lt;code&gt;rep&lt;/code&gt; to generate the urn:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beads &amp;lt;- rep(c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;), times = c(2,3))
beads&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;red&amp;quot;  &amp;quot;red&amp;quot;  &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and then use &lt;code&gt;sample&lt;/code&gt; to pick a bead at random:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample(beads, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;red&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This line of code produces one random outcome. We want to repeat this experiment an infinite number of times, but it is impossible to repeat forever. Instead, we repeat the experiment a large enough number of times to make the results practically equivalent to repeating forever. &lt;strong&gt;This is an example of a &lt;em&gt;Monte Carlo&lt;/em&gt; simulation&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Much of what mathematical and theoretical statisticians study, which we do not cover in this class, relates to providing rigorous definitions of “practically equivalent” as well as studying how close a large number of experiments gets us to what happens in the limit. Later in this lecture, we provide a practical approach to deciding what is “large enough”.&lt;/p&gt;
&lt;p&gt;To perform our first Monte Carlo simulation, we use the &lt;code&gt;replicate&lt;/code&gt; function, which permits us to repeat the same task any number of times. Here, we repeat the random event &lt;span class=&#34;math inline&#34;&gt;\(B =\)&lt;/span&gt; 10,000 times:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10000
events &amp;lt;- replicate(B, sample(beads, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now see if our definition actually is in agreement with this Monte Carlo simulation approximation. We can use &lt;code&gt;table&lt;/code&gt; to see the distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tab &amp;lt;- table(events)
tab&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## events
## blue  red 
## 6025 3975&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and &lt;code&gt;prop.table&lt;/code&gt; gives us the proportions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prop.table(tab)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## events
##   blue    red 
## 0.6025 0.3975&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The numbers above are the estimated probabilities provided by this Monte Carlo simulation. Statistical theory, not covered here, tells us that as &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; gets larger, the estimates get closer to 3/5=.6 and 2/5=.4.&lt;/p&gt;
&lt;p&gt;Although this is a simple and not very useful example, we will use Monte Carlo simulations to estimate probabilities in cases in which it is harder to compute the exact ones. Before delving into more complex examples, we use simple ones to demonstrate the computing tools available in R.&lt;/p&gt;
&lt;div id=&#34;setting-the-random-seed&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Setting the random seed&lt;/h3&gt;
&lt;p&gt;Before we continue, we will briefly explain the following important line of code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1986)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Throughout this class, we use random number generators. This implies that many of the results presented can actually change by chance, which then suggests that a frozen version of the class may show a different result than what you obtain when you try to code as shown in the class. This is actually fine since the results are random and change from time to time. However, if you want to ensure that results are exactly the same every time you run them, you can set R’s random number generation seed to a specific number. Above we set it to 1986. We want to avoid using the same seed everytime. A popular way to pick the seed is the year - month - day. For example, we picked 1986 on December 20, 2018: &lt;span class=&#34;math inline&#34;&gt;\(2018 - 12 - 20 = 1986\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;You can learn more about setting the seed by looking at the documentation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?set.seed&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the exercises, we may ask you to set the seed to assure that the results you obtain are exactly what we expect them to be.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;with-and-without-replacement&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;With and without replacement&lt;/h3&gt;
&lt;p&gt;The function &lt;code&gt;sample&lt;/code&gt; has an argument that permits us to pick more than one element from the urn. However, by default, this selection occurs &lt;em&gt;without replacement&lt;/em&gt;: after a bead is selected, it is not put back in the bag. Notice what happens when we ask to randomly select five beads:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample(beads, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;red&amp;quot;  &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot; &amp;quot;red&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample(beads, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;red&amp;quot;  &amp;quot;red&amp;quot;  &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample(beads, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;blue&amp;quot; &amp;quot;red&amp;quot;  &amp;quot;blue&amp;quot; &amp;quot;red&amp;quot;  &amp;quot;blue&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This results in rearrangements that always have three blue and two red beads. If we ask that six beads be selected, we get an error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sample(beads, 6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;Error in sample.int(length(x), size, replace, prob) :   cannot take a sample larger than the population when &#39;replace = FALSE&#39;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;However, the &lt;code&gt;sample&lt;/code&gt; function can be used directly, without the use of &lt;code&gt;replicate&lt;/code&gt;, to repeat the same experiment of picking 1 out of the 5 beads, continually, under the same conditions. To do this, we sample &lt;em&gt;with replacement&lt;/em&gt;: return the bead back to the urn after selecting it.
We can tell &lt;code&gt;sample&lt;/code&gt; to do this by changing the &lt;code&gt;replace&lt;/code&gt; argument, which defaults to &lt;code&gt;FALSE&lt;/code&gt;, to &lt;code&gt;replace = TRUE&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;events &amp;lt;- sample(beads, B, replace = TRUE)
prop.table(table(events))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## events
##   blue    red 
## 0.6017 0.3983&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not surprisingly, we get results very similar to those previously obtained with &lt;code&gt;replicate&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;independence&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Independence&lt;/h2&gt;
&lt;p&gt;We say two events are independent if the outcome of one does not affect the other. The classic example is coin tosses. Every time we toss a fair coin, the probability of seeing heads is 1/2 regardless of what previous tosses have revealed. The same is true when we pick beads from an urn with replacement. In the example above, the probability of red is 0.40 regardless of previous draws.&lt;/p&gt;
&lt;p&gt;Many examples of events that are not independent come from card games. When we deal the first card, the probability of getting a King is 1/13 since there are thirteen possibilities: Ace, Deuce, Three, &lt;span class=&#34;math inline&#34;&gt;\(\dots\)&lt;/span&gt;, Ten, Jack, Queen, King, and Ace. Now if we deal a King for the first card, and don’t replace it into the deck, the probabilities of a second card being a King is less because there are only three Kings left: the probability is 3 out of 51. These events are therefore &lt;strong&gt;not independent&lt;/strong&gt;: the first outcome affected the next one.&lt;/p&gt;
&lt;p&gt;To see an extreme case of non-independent events, consider our example of drawing five beads at random &lt;strong&gt;without&lt;/strong&gt; replacement:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- sample(beads, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you have to guess the color of the first bead, you will predict blue since blue has a 60% chance. But if I show you the result of the last four outcomes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x[2:5]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot; &amp;quot;blue&amp;quot; &amp;quot;red&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;would you still guess blue? Of course not. Now you know that the probability of red is 1 since the only bead left is red. The events are not independent, so the probabilities change.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conditional-probabilities&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conditional probabilities&lt;/h2&gt;
&lt;p&gt;When events are not independent, &lt;em&gt;conditional probabilities&lt;/em&gt; are useful. We already saw an example of a conditional probability: we computed the probability that a second dealt card is a King given that the first was a King. In probability, we use the following notation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(\mbox{Card 2 is a king} \mid \mbox{Card 1 is a king}) = 3/51
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We use the &lt;span class=&#34;math inline&#34;&gt;\(\mid\)&lt;/span&gt; as shorthand for “given that” or “conditional on”.&lt;/p&gt;
&lt;p&gt;When two events, say &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, are independent, we have:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(A \mid B) = \mbox{Pr}(A)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is the mathematical way of saying: the fact that &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; happened does not affect the probability of &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; happening. In fact, this can be considered the mathematical definition of independence.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;addition-and-multiplication-rules&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Addition and multiplication rules&lt;/h2&gt;
&lt;div id=&#34;multiplication-rule&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiplication rule&lt;/h3&gt;
&lt;p&gt;If we want to know the probability of two events, say &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, occurring, we can use the multiplication rule:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(A \mbox{ and } B) = \mbox{Pr}(A)\mbox{Pr}(B \mid A)
\]&lt;/span&gt;
Let’s use Blackjack as an example. In Blackjack, you are assigned two random cards. After you see what you have, you can ask for more. The goal is to get closer to 21 than the dealer, without going over. Face cards are worth 10 points and Aces are worth 11 or 1 (you choose).&lt;/p&gt;
&lt;p&gt;So, in a Blackjack game, to calculate the chances of getting a 21 by drawing an Ace and then a face card, we compute the probability of the first being an Ace and multiply by the probability of drawing a face card or a 10 given that the first was an Ace: &lt;span class=&#34;math inline&#34;&gt;\(1/13 \times 16/51 \approx 0.025\)&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The multiplication rule also applies to more than two events. We can use induction to expand for more events:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(A \mbox{ and } B \mbox{ and } C) = \mbox{Pr}(A)\mbox{Pr}(B \mid A)\mbox{Pr}(C \mid A \mbox{ and } B)
\]&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;multiplication-rule-under-independence&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Multiplication rule under independence&lt;/h3&gt;
&lt;p&gt;When we have independent events, then the multiplication rule becomes simpler:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(A \mbox{ and } B \mbox{ and } C) = \mbox{Pr}(A)\mbox{Pr}(B)\mbox{Pr}(C)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;But we have to be very careful before using this since assuming independence can result in very different and incorrect probability calculations when we don’t actually have independence.&lt;/p&gt;
&lt;p&gt;As an example, imagine a court case in which the suspect was described as having a mustache and a beard. The defendant has a mustache and a beard and the prosecution brings in an “expert” to testify that 1/10 men have beards and 1/5 have mustaches, so using the multiplication rule we conclude that only &lt;span class=&#34;math inline&#34;&gt;\(1/10 \times 1/5\)&lt;/span&gt; or 0.02 have both.&lt;/p&gt;
&lt;p&gt;But to multiply like this we need to assume independence! Say the conditional probability of a man having a mustache conditional on him having a beard is .95. So the correct calculation probability is much higher: &lt;span class=&#34;math inline&#34;&gt;\(1/10 \times 95/100 = 0.095\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The multiplication rule also gives us a general formula for computing conditional probabilities:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(B \mid A) = \frac{\mbox{Pr}(A \mbox{ and } B)}{ \mbox{Pr}(A)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To illustrate how we use these formulas and concepts in practice, we will use several examples related to card games.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;addition-rule&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Addition rule&lt;/h3&gt;
&lt;p&gt;The addition rule tells us that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(A \mbox{ or } B) = \mbox{Pr}(A) + \mbox{Pr}(B) - \mbox{Pr}(A \mbox{ and } B)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This rule is intuitive: think of a Venn diagram. If we simply add the probabilities, we count the intersection twice so we need to substract one instance.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/venn-diagram-addition-rule-1.png&#34; width=&#34;35%&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;combinations-and-permutations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Combinations and permutations&lt;/h2&gt;
&lt;p&gt;In our very first example, we imagined an urn with five beads. As a reminder, to compute the probability distribution of one draw, we simply listed out all the possibilities. There were 5 and so then, for each event, we counted how many of these possibilities were associated with the event. The resulting probability of choosing a blue bead is 3/5 because out of the five possible outcomes, three were blue.&lt;/p&gt;
&lt;p&gt;For more complicated cases, the computations are not as straightforward. For instance, what is the probability that if I draw five cards without replacement, I get all cards of the same suit, what is known as a “flush” in poker? In a discrete probability course you learn theory on how to make these computations. Here we focus on how to use R code to compute the answers.&lt;/p&gt;
&lt;p&gt;First, let’s construct a deck of cards. For this, we will use the &lt;code&gt;expand.grid&lt;/code&gt; and &lt;code&gt;paste&lt;/code&gt; functions. We use &lt;code&gt;paste&lt;/code&gt; to create strings by joining smaller strings. To do this, we take the number and suit of a card and create the card name like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;number &amp;lt;- &amp;quot;Three&amp;quot;
suit &amp;lt;- &amp;quot;Hearts&amp;quot;
paste(number, suit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Three Hearts&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;paste&lt;/code&gt; also works on pairs of vectors performing the operation element-wise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste(letters[1:5], as.character(1:5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;a 1&amp;quot; &amp;quot;b 2&amp;quot; &amp;quot;c 3&amp;quot; &amp;quot;d 4&amp;quot; &amp;quot;e 5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function &lt;code&gt;expand.grid&lt;/code&gt; gives us all the combinations of entries of two vectors. For example, if you have blue and black pants and white, grey, and plaid shirts, all your combinations are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;expand.grid(pants = c(&amp;quot;blue&amp;quot;, &amp;quot;black&amp;quot;), shirt = c(&amp;quot;white&amp;quot;, &amp;quot;grey&amp;quot;, &amp;quot;plaid&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   pants shirt
## 1  blue white
## 2 black white
## 3  blue  grey
## 4 black  grey
## 5  blue plaid
## 6 black plaid&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is how we generate a deck of cards:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;suits &amp;lt;- c(&amp;quot;Diamonds&amp;quot;, &amp;quot;Clubs&amp;quot;, &amp;quot;Hearts&amp;quot;, &amp;quot;Spades&amp;quot;)
numbers &amp;lt;- c(&amp;quot;Ace&amp;quot;, &amp;quot;Deuce&amp;quot;, &amp;quot;Three&amp;quot;, &amp;quot;Four&amp;quot;, &amp;quot;Five&amp;quot;, &amp;quot;Six&amp;quot;, &amp;quot;Seven&amp;quot;,
             &amp;quot;Eight&amp;quot;, &amp;quot;Nine&amp;quot;, &amp;quot;Ten&amp;quot;, &amp;quot;Jack&amp;quot;, &amp;quot;Queen&amp;quot;, &amp;quot;King&amp;quot;)
deck &amp;lt;- expand.grid(number=numbers, suit=suits)
deck &amp;lt;- paste(deck$number, deck$suit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the deck constructed, we can double check that the probability of a King in the first card is 1/13 by computing the proportion of possible outcomes that satisfy our condition:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kings &amp;lt;- paste(&amp;quot;King&amp;quot;, suits)
mean(deck %in% kings)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.07692308&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, how about the conditional probability of the second card being a King given that the first was a King? Earlier, we deduced that if one King is already out of the deck and there are 51 left, then this probability is 3/51. Let’s confirm by listing out all possible outcomes.&lt;/p&gt;
&lt;p&gt;To do this, we can use the &lt;code&gt;permutations&lt;/code&gt; function from the &lt;strong&gt;gtools&lt;/strong&gt; package. For any list of size &lt;code&gt;n&lt;/code&gt;, this function computes all the different combinations we can get when we select &lt;code&gt;r&lt;/code&gt; items. Here are all the ways we can choose two numbers from a list consisting of &lt;code&gt;1,2,3&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gtools)
permutations(3, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    2
## [2,]    1    3
## [3,]    2    1
## [4,]    2    3
## [5,]    3    1
## [6,]    3    2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the order matters here: 3,1 is different than 1,3. Also, note that (1,1), (2,2), and (3,3) do not appear because once we pick a number, it can’t appear again.&lt;/p&gt;
&lt;p&gt;Optionally, we can add a vector. If you want to see five random seven digit phone numbers out of all possible phone numbers (without repeats), you can type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all_phone_numbers &amp;lt;- permutations(10, 7, v = 0:9)
n &amp;lt;- nrow(all_phone_numbers)
index &amp;lt;- sample(n, 5)
all_phone_numbers[index,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3] [,4] [,5] [,6] [,7]
## [1,]    1    3    8    0    6    7    5
## [2,]    2    9    1    6    4    8    0
## [3,]    5    1    6    0    9    8    2
## [4,]    7    4    6    0    2    8    1
## [5,]    4    6    5    9    2    8    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of using the numbers 1 through 10, the default, it uses what we provided through &lt;code&gt;v&lt;/code&gt;: the digits 0 through 9.&lt;/p&gt;
&lt;p&gt;To compute all possible ways we can choose two cards when the order matters, we type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hands &amp;lt;- permutations(52, 2, v = deck)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a matrix with two columns and 2652 rows. With a matrix we can get the first and second cards like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;first_card &amp;lt;- hands[,1]
second_card &amp;lt;- hands[,2]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the cases for which the first hand was a King can be computed like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kings &amp;lt;- paste(&amp;quot;King&amp;quot;, suits)
sum(first_card %in% kings)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 204&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get the conditional probability, we compute what fraction of these have a King in the second card:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(first_card%in%kings &amp;amp; second_card%in%kings) / sum(first_card%in%kings)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.05882353&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is exactly 3/51, as we had already deduced. Notice that the code above is equivalent to:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(first_card%in%kings &amp;amp; second_card%in%kings) / mean(first_card%in%kings)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.05882353&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which uses &lt;code&gt;mean&lt;/code&gt; instead of &lt;code&gt;sum&lt;/code&gt; and is an R version of:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\mbox{Pr}(A \mbox{ and } B)}{ \mbox{Pr}(A)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;How about if the order doesn’t matter? For example, in Blackjack if you get an Ace and a face card in the first draw, it is called a &lt;em&gt;Natural 21&lt;/em&gt; and you win automatically. If we wanted to compute the probability of this happening, we would enumerate the &lt;em&gt;combinations&lt;/em&gt;, not the permutations, since the order does not matter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;combinations(3,2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    1    2
## [2,]    1    3
## [3,]    2    3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the second line, the outcome does not include (2,1) because (1,2) already was enumerated. The same applies to (3,1) and (3,2).&lt;/p&gt;
&lt;p&gt;So to compute the probability of a &lt;em&gt;Natural 21&lt;/em&gt; in Blackjack, we can do this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aces &amp;lt;- paste(&amp;quot;Ace&amp;quot;, suits)

facecard &amp;lt;- c(&amp;quot;King&amp;quot;, &amp;quot;Queen&amp;quot;, &amp;quot;Jack&amp;quot;, &amp;quot;Ten&amp;quot;)
facecard &amp;lt;- expand.grid(number = facecard, suit = suits)
facecard &amp;lt;- paste(facecard$number, facecard$suit)

hands &amp;lt;- combinations(52, 2, v = deck)
mean(hands[,1] %in% aces &amp;amp; hands[,2] %in% facecard)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04826546&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the last line, we assume the Ace comes first. This is only because we know the way &lt;code&gt;combination&lt;/code&gt; enumerates possibilities and it will list this case first. But to be safe, we could have written this and produced the same answer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean((hands[,1] %in% aces &amp;amp; hands[,2] %in% facecard) |
       (hands[,2] %in% aces &amp;amp; hands[,1] %in% facecard))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04826546&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;monte-carlo-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Monte Carlo example&lt;/h3&gt;
&lt;p&gt;Instead of using &lt;code&gt;combinations&lt;/code&gt; to deduce the exact probability of a Natural 21, we can use a Monte Carlo to estimate this probability. In this case, we draw two cards over and over and keep track of how many 21s we get. We can use the function sample to draw two cards without replacements:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;hand &amp;lt;- sample(deck, 2)
hand&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Queen Clubs&amp;quot;  &amp;quot;Seven Spades&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then check if one card is an Ace and the other a face card or a 10. Going forward, we include 10 when we say &lt;em&gt;face card&lt;/em&gt;. Now we need to check both possibilities:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(hands[1] %in% aces &amp;amp; hands[2] %in% facecard) |
  (hands[2] %in% aces &amp;amp; hands[1] %in% facecard)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we repeat this 10,000 times, we get a very good approximation of the probability of a Natural 21.&lt;/p&gt;
&lt;p&gt;Let’s start by writing a function that draws a hand and returns TRUE if we get a 21. The function does not need any arguments because it uses objects defined in the global environment.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blackjack &amp;lt;- function(){
   hand &amp;lt;- sample(deck, 2)
  (hand[1] %in% aces &amp;amp; hand[2] %in% facecard) |
    (hand[2] %in% aces &amp;amp; hand[1] %in% facecard)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we do have to check both possibilities: Ace first or Ace second because we are not using the &lt;code&gt;combinations&lt;/code&gt; function. The function returns &lt;code&gt;TRUE&lt;/code&gt; if we get a 21 and &lt;code&gt;FALSE&lt;/code&gt; otherwise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;blackjack()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can play this game, say, 10,000 times:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10000
results &amp;lt;- replicate(B, blackjack())
mean(results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0475&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;examples&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;In this section, we describe two discrete probability popular examples: the Monty Hall problem and the birthday problem. We use R to help illustrate the mathematical concepts.&lt;/p&gt;
&lt;div id=&#34;monty-hall-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Monty Hall problem&lt;/h3&gt;
&lt;p&gt;In the 1970s, there was a game show called “Let’s Make a Deal” and Monty Hall was the host. At some point in the game, contestants were asked to pick one of three doors. Behind one door there was a prize. The other doors had a goat behind them to show the contestant they had lost. After the contestant picked a door, before revealing whether the chosen door contained a prize, Monty Hall would open one of the two remaining doors and show the contestant there was no prize behind that door. Then he would ask “Do you want to switch doors?” What would you do?&lt;/p&gt;
&lt;p&gt;We can use probability to show that if you stick with the original door choice, your chances of winning a prize remain 1 in 3. However, if you switch to the other door, your chances of winning double to 2 in 3! This seems counterintuitive. Many people incorrectly think both chances are 1 in 2 since you are choosing between 2 options. You can watch a detailed mathematical explanation on Khan Academy&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; or read one on Wikipedia&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;. Below we use a Monte Carlo simulation to see which strategy is better. Note that this code is written longer than it should be for pedagogical purposes.&lt;/p&gt;
&lt;p&gt;Let’s start with the stick strategy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10000
monty_hall &amp;lt;- function(strategy){
  doors &amp;lt;- as.character(1:3)
  prize &amp;lt;- sample(c(&amp;quot;car&amp;quot;, &amp;quot;goat&amp;quot;, &amp;quot;goat&amp;quot;))
  prize_door &amp;lt;- doors[prize == &amp;quot;car&amp;quot;]
  my_pick  &amp;lt;- sample(doors, 1)
  show &amp;lt;- sample(doors[!doors %in% c(my_pick, prize_door)],1)
  stick &amp;lt;- my_pick
  stick == prize_door
  switch &amp;lt;- doors[!doors%in%c(my_pick, show)]
  choice &amp;lt;- ifelse(strategy == &amp;quot;stick&amp;quot;, stick, switch)
  choice == prize_door
}
stick &amp;lt;- replicate(B, monty_hall(&amp;quot;stick&amp;quot;))
mean(stick)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3416&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;switch &amp;lt;- replicate(B, monty_hall(&amp;quot;switch&amp;quot;))
mean(switch)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.6682&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we write the code, we note that the lines starting with &lt;code&gt;my_pick&lt;/code&gt; and &lt;code&gt;show&lt;/code&gt; have no influence on the last logical operation when we stick to our original choice anyway. From this we should realize that the chance is 1 in 3, what we began with. When we switch,
the Monte Carlo estimate confirms the 2/3 calculation. This helps us gain some insight by showing that we are removing a door, &lt;code&gt;show&lt;/code&gt;, that is definitely not a winner from our choices. We also see that unless we get it right when we first pick, you win: 1 - 1/3 = 2/3.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;birthday-problem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Birthday problem&lt;/h3&gt;
&lt;p&gt;Suppose you are in a classroom with 50 people. If we assume this is a randomly selected group of 50 people, what is the chance that at least two people have the same birthday? Although it is somewhat advanced, we can deduce this mathematically. We will do this later. Here we use a Monte Carlo simulation. For simplicity, we assume nobody was born on February 29. This actually doesn’t change the answer much.&lt;/p&gt;
&lt;p&gt;First, note that birthdays can be represented as numbers between 1 and 365, so a sample of 50 birthdays can be obtained like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 50
bdays &amp;lt;- sample(1:365, n, replace = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To check if in this particular set of 50 people we have at least two with the same birthday, we can use the function &lt;code&gt;duplicated&lt;/code&gt;, which returns &lt;code&gt;TRUE&lt;/code&gt; whenever an element of a vector is a duplicate. Here is an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;duplicated(c(1,2,3,1,4,3,5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second time 1 and 3 appear, we get a &lt;code&gt;TRUE&lt;/code&gt;. So to check if two birthdays were the same, we simply use the &lt;code&gt;any&lt;/code&gt; and &lt;code&gt;duplicated&lt;/code&gt; functions like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;any(duplicated(bdays))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, we see that it did happen. At least two people had the same birthday.&lt;/p&gt;
&lt;p&gt;To estimate the probability of a shared birthday in the group, we repeat this experiment by sampling sets of 50 birthdays over and over:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10000
same_birthday &amp;lt;- function(n){
  bdays &amp;lt;- sample(1:365, n, replace=TRUE)
  any(duplicated(bdays))
}
results &amp;lt;- replicate(B, same_birthday(50))
mean(results)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.9691&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Were you expecting the probability to be this high?&lt;/p&gt;
&lt;p&gt;People tend to underestimate these probabilities. To get an intuition as to why it is so high, think about what happens when the group size is close to 365. At this stage, we run out of days and the probability is one.&lt;/p&gt;
&lt;p&gt;Say we want to use this knowledge to bet with friends about two people having the same birthday in a group of people. When are the chances larger than 50%? Larger than 75%?&lt;/p&gt;
&lt;p&gt;Let’s create a look-up table. We can quickly create a function to compute this for any group size:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_prob &amp;lt;- function(n, B=10000){
  results &amp;lt;- replicate(B, same_birthday(n))
  mean(results)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the function &lt;code&gt;sapply&lt;/code&gt;, we can perform element-wise operations on any function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- seq(1,60)
prob &amp;lt;- sapply(n, compute_prob)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now make a plot of the estimated probabilities of two people having the same birthday in a group of size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
prob &amp;lt;- sapply(n, compute_prob)
qplot(n, prob)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/birthday-problem-mc-probabilities-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now let’s compute the exact probabilities rather than use Monte Carlo approximations. Not only do we get the exact answer using math, but the computations are much faster since we don’t have to generate experiments.&lt;/p&gt;
&lt;p&gt;To make the math simpler, instead of computing the probability of it happening, we will compute the probability of it not happening. For this, we use the multiplication rule.&lt;/p&gt;
&lt;p&gt;Let’s start with the first person. The probability that person 1 has a unique birthday is 1. The probability that person 2 has a unique birthday, given that person 1 already took one, is 364/365. Then, given that the first two people have unique birthdays, person 3 is left with 363 days to choose from. We continue this way and find the chances of all 50 people having a unique birthday is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
1 \times \frac{364}{365}\times\frac{363}{365} \dots \frac{365-n + 1}{365}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;We can write a function that does this for any number:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;exact_prob &amp;lt;- function(n){
  prob_unique &amp;lt;- seq(365,365-n+1)/365
  1 - prod( prob_unique)
}
eprob &amp;lt;- sapply(n, exact_prob)
qplot(n, prob) + geom_line(aes(n, eprob), col = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/birthday-problem-exact-probabilities-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows that the Monte Carlo simulation provided a very good estimate of the exact probability. Had it not been possible to compute the exact probabilities, we would have still been able to accurately estimate the probabilities.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;infinity-in-practice&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Infinity in practice&lt;/h2&gt;
&lt;p&gt;The theory described here requires repeating experiments over and over forever. In practice we can’t do this.
In the examples above, we used &lt;span class=&#34;math inline&#34;&gt;\(B=10,000\)&lt;/span&gt; Monte Carlo experiments and it turned out that this provided accurate estimates. The larger this number, the more accurate the estimate becomes until the approximaton is so good that your computer can’t tell the difference. But in more complex calculations, 10,000 may not be nearly enough. Also, for some calculations, 10,000 experiments might not be computationally feasible. In practice, we won’t know what the answer is, so we won’t know if our Monte Carlo estimate is accurate. We know that the larger &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, the better the approximation. But how big do we need it to be? This is actually a challenging question and answering it often requires advanced theoretical statistics training.&lt;/p&gt;
&lt;p&gt;One practical approach we will describe here is to check for the stability of the estimate. The following is an example with the birthday problem for a group of 25 people.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10^seq(1, 5, len = 100)
compute_prob &amp;lt;- function(B, n=25){
  same_day &amp;lt;- replicate(B, same_birthday(n))
  mean(same_day)
}
prob &amp;lt;- sapply(B, compute_prob)
qplot(log10(B), prob, geom = &amp;quot;line&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/monte-carlo-convergence-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this plot, we can see that the values start to stabilize (that is, they vary less than .01) around 1000. Note that the exact probability, which we know in this case, is 0.5686997.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;One ball will be drawn at random from a box containing: 3 cyan balls, 5 magenta balls, and 7 yellow balls. What is the probability that the ball will be cyan?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is the probability that the ball will not be cyan?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Instead of taking just one draw, consider taking two draws. You take the second draw without returning the first draw to the box. We call this sampling &lt;strong&gt;without&lt;/strong&gt; replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now repeat the experiment, but this time, after taking the first draw and recording the color, return it to the box and shake the box. We call this sampling &lt;strong&gt;with&lt;/strong&gt; replacement. What is the probability that the first draw is cyan and that the second draw is not cyan?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Two events &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; are independent if &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(A \mbox{ and } B) = \mbox{Pr}(A) P(B)\)&lt;/span&gt;. Under which situation are the draws independent?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;You don’t replace the draw.&lt;/li&gt;
&lt;li&gt;You replace the draw.&lt;/li&gt;
&lt;li&gt;Neither&lt;/li&gt;
&lt;li&gt;Both&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Say you’ve drawn 5 balls from the box, with replacement, and all have been yellow. What is the probability that the next one is yellow?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;If you roll a 6-sided die six times, what is the probability of not seeing a 6?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Two teams, say the Celtics and the Cavs, are playing a seven game series. The Cavs are a better team and have a 60% chance of winning each game. What is the probability that the Celtics win &lt;strong&gt;at least&lt;/strong&gt; one game?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a Monte Carlo simulation to confirm your answer to the previous problem. Use &lt;code&gt;B &amp;lt;- 10000&lt;/code&gt; simulations. Hint: use the following code to generate the results of the first four games:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;celtic_wins &amp;lt;- sample(c(0,1), 4, replace = TRUE, prob = c(0.6, 0.4))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Celtics must win one of these 4 games.&lt;/p&gt;
&lt;ol start=&#34;10&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Two teams, say the Cavs and the Warriors, are playing a seven game championship series. The first to win four games, therefore, wins the series. The teams are equally good so they each have a 50-50 chance of winning each game. If the Cavs lose the first game, what is the probability that they win the series?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Confirm the results of the previous question with a Monte Carlo simulation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Two teams, &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt;, are playing a seven game series. Team &lt;span class=&#34;math inline&#34;&gt;\(A\)&lt;/span&gt; is better than team &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; and has a &lt;span class=&#34;math inline&#34;&gt;\(p&amp;gt;0.5\)&lt;/span&gt; chance of winning each game. Given a value &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;, the probability of winning the series for the underdog team &lt;span class=&#34;math inline&#34;&gt;\(B\)&lt;/span&gt; can be computed with the following function based on a Monte Carlo simulation:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prob_win &amp;lt;- function(p){
  B &amp;lt;- 10000
  result &amp;lt;- replicate(B, {
    b_win &amp;lt;- sample(c(1,0), 7, replace = TRUE, prob = c(1-p, p))
    sum(b_win)&amp;gt;=4
  })
  mean(result)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use the function &lt;code&gt;sapply&lt;/code&gt; to compute the probability, call it &lt;code&gt;Pr&lt;/code&gt;, of winning for &lt;code&gt;p &amp;lt;- seq(0.5, 0.95, 0.025)&lt;/code&gt;. Then plot the result.&lt;/p&gt;
&lt;ol start=&#34;13&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Repeat the exercise above, but now keep the probability fixed at &lt;code&gt;p &amp;lt;- 0.75&lt;/code&gt; and compute the probability for different series lengths: best of 1 game, 3 games, 5 games,… Specifically, &lt;code&gt;N &amp;lt;- seq(1, 25, 2)&lt;/code&gt;. Hint: use this function:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;prob_win &amp;lt;- function(N, p=0.75){
  B &amp;lt;- 10000
  result &amp;lt;- replicate(B, {
    b_win &amp;lt;- sample(c(1,0), N, replace = TRUE, prob = c(1-p, p))
    sum(b_win)&amp;gt;=(N+1)/2
  })
  mean(result)
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;In previous lectures, we explained why when summarizing a list of numeric values, such as heights, it is not useful to construct a distribution that defines a proportion to each possible outcome. For example, if we measure every single person in a very large population of size &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; with extremely high precision, since no two people are exactly the same height, we need to assign the proportion &lt;span class=&#34;math inline&#34;&gt;\(1/n\)&lt;/span&gt; to each observed value and attain no useful summary at all. Similarly, when defining probability distributions, it is not useful to assign a very small probability to every single height.&lt;/p&gt;
&lt;p&gt;Just as when using distributions to summarize numeric data, it is much more practical to define a function that operates on intervals rather than single values. The standard way of doing this is using the &lt;em&gt;cumulative distribution function&lt;/em&gt; (CDF).&lt;/p&gt;
&lt;p&gt;We described empirical cumulative distribution function (eCDF) as a basic summary of a list of numeric values. As an example, we earlier defined the height distribution for adult male students. Here, we define the vector &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; to contain these heights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(dslabs)
data(heights)
x &amp;lt;- heights %&amp;gt;% filter(sex==&amp;quot;Male&amp;quot;) %&amp;gt;% pull(height)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We defined the empirical distribution function as:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;F &amp;lt;- function(a) mean(x&amp;lt;=a)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which, for any value &lt;code&gt;a&lt;/code&gt;, gives the proportion of values in the list &lt;code&gt;x&lt;/code&gt; that are smaller or equal than &lt;code&gt;a&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Keep in mind that we have not yet introduced probability in the context of CDFs. Let’s do this by asking the following: if I pick one of the male students at random, what is the chance that he is taller than 70.5 inches? Because every student has the same chance of being picked, the answer to this is equivalent to the proportion of students that are taller than 70.5 inches. Using the CDF we obtain an answer by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 - F(70)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3768473&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once a CDF is defined, we can use this to compute the probability of any subset. For instance, the probability of a student being between height &lt;code&gt;a&lt;/code&gt; and height &lt;code&gt;b&lt;/code&gt; is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;F(b)-F(a)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because we can compute the probability for any possible event this way, the cumulative probability function defines the probability distribution for picking a height at random from our vector of heights &lt;code&gt;x&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theoretical-continuous-distributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Theoretical continuous distributions&lt;/h2&gt;
&lt;p&gt;The normal distribution is a useful approximation to many naturally occurring distributions, including that of height. The cumulative distribution for the normal distribution is defined by a mathematical formula which in &lt;code&gt;R&lt;/code&gt; can be obtained with the function &lt;code&gt;pnorm&lt;/code&gt;. We say that a random quantity is normally distributed with average &lt;code&gt;m&lt;/code&gt; and standard deviation &lt;code&gt;s&lt;/code&gt; if its probability distribution is defined by:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;F(a) = pnorm(a, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is useful because if we are willing to use the normal approximation for, say, height, we don’t need the entire dataset to answer questions such as: what is the probability that a randomly selected student is taller then 70 inches? We just need the average height and standard deviation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- mean(x)
s &amp;lt;- sd(x)
1 - pnorm(70.5, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.371369&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;theoretical-distributions-as-approximations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Theoretical distributions as approximations&lt;/h3&gt;
&lt;p&gt;The normal distribution is derived mathematically: we do not need data to define it. For practicing data scientists, almost everything we do involves data. Data is always, technically speaking, discrete. For example, we could consider our height data categorical with each specific height a unique category. The probability distribution is defined by the proportion of students reporting each height. Here is a plot of that probability distribution:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/plot-of-height-frequencies-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;While most students rounded up their heights to the nearest inch, others reported values with more precision. One student reported his height to be 69.6850393700787, which is 177 centimeters. The probability assigned to this height is 0.0012315 or 1 in 812. The probability for 70 inches is much higher at 0.1059113, but does it really make sense to think of the probability of being exactly 70 inches as being different than 69.6850393700787? Clearly it is much more useful for data analytic purposes to treat this outcome as a continuous numeric variable, keeping in mind that very few people, or perhaps none, are exactly 70 inches, and that the reason we get more values at 70 is because people round to the nearest inch.&lt;/p&gt;
&lt;p&gt;With continuous distributions, the probability of a singular value is not even defined. For example, it does not make sense to ask what is the probability that a normally distributed value is 70. Instead, we define probabilities for intervals. We thus could ask what is the probability that someone is between 69.5 and 70.5.&lt;/p&gt;
&lt;p&gt;In cases like height, in which the data is rounded, the normal approximation is particularly useful if we deal with intervals that include exactly one round number. For example, the normal distribution is useful for approximating the proportion of students reporting values in intervals like the following three:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(x &amp;lt;= 68.5) - mean(x &amp;lt;= 67.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.114532&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(x &amp;lt;= 69.5) - mean(x &amp;lt;= 68.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1194581&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(x &amp;lt;= 70.5) - mean(x &amp;lt;= 69.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1219212&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how close we get with the normal approximation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pnorm(68.5, m, s) - pnorm(67.5, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1031077&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pnorm(69.5, m, s) - pnorm(68.5, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1097121&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pnorm(70.5, m, s) - pnorm(69.5, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1081743&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, the approximation is not as useful for other intervals. For instance, notice how the approximation breaks down when we try to estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(x &amp;lt;= 70.9) - mean(x&amp;lt;=70.1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02216749&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;with&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pnorm(70.9, m, s) - pnorm(70.1, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.08359562&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In general, we call this situation &lt;em&gt;discretization&lt;/em&gt;. Although the true height distribution is continuous, the reported heights tend to be more common at discrete values, in this case, due to rounding. As long as we are aware of how to deal with this reality, the normal approximation can still be a very useful tool.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-probability-density&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The probability density&lt;/h3&gt;
&lt;p&gt;For categorical distributions, we can define the probability of a category. For example, a roll of a die, let’s call it &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;, can be 1,2,3,4,5 or 6. The probability of 4 is defined as:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(X=4) = 1/6
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The CDF can then easily be defined:
&lt;span class=&#34;math display&#34;&gt;\[
F(4) = \mbox{Pr}(X\leq 4) =  \mbox{Pr}(X = 4) +  \mbox{Pr}(X = 3) +  \mbox{Pr}(X = 2) +  \mbox{Pr}(X = 1)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Although for continuous distributions the probability of a single value &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(X=x)\)&lt;/span&gt; is not defined, there is a theoretical definition that has a similar interpretation. The probability density at &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is defined as the function &lt;span class=&#34;math inline&#34;&gt;\(f(a)\)&lt;/span&gt; such that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
F(a) = \mbox{Pr}(X\leq a) = \int_{-\infty}^a f(x)\, dx
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;For those that know calculus, remember that the integral is related to a sum: it is the sum of bars with widths approximating 0. If you don’t know calculus, you can think of &lt;span class=&#34;math inline&#34;&gt;\(f(x)\)&lt;/span&gt; as a curve for which the area under that curve up to the value &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;, gives you the probability &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(X\leq a)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For example, to use the normal approximation to estimate the probability of someone being taller than 76 inches, we use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 - pnorm(76, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.03206008&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which mathematically is the grey area below:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/intergrals-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The curve you see is the probability density for the normal distribution. In R, we get this using the function &lt;code&gt;dnorm&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Although it may not be immediately obvious why knowing about probability densities is useful, understanding this concept will be essential to those wanting to fit models to data for which predefined functions are not available.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;monte-carlo-simulations-for-continuous-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Monte Carlo simulations for continuous variables&lt;/h2&gt;
&lt;p&gt;R provides functions to generate normally distributed outcomes. Specifically, the &lt;code&gt;rnorm&lt;/code&gt; function takes three arguments: size, average (defaults to 0), and standard deviation (defaults to 1) and produces random numbers. Here is an example of how we could generate data that looks like our reported heights:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- length(x)
m &amp;lt;- mean(x)
s &amp;lt;- sd(x)
simulated_heights &amp;lt;- rnorm(n, m, s)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not surprisingly, the distribution looks normal:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/simulated-heights-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This is one of the most useful functions in R as it will permit us to generate data that mimics natural events and answers questions related to what could happen by chance by running Monte Carlo simulations.&lt;/p&gt;
&lt;p&gt;If, for example, we pick 800 males at random, what is the distribution of the tallest person? How rare is a seven footer in a group of 800 males? The following Monte Carlo simulation helps us answer that question:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10000
tallest &amp;lt;- replicate(B, {
  simulated_data &amp;lt;- rnorm(800, m, s)
  max(simulated_data)
})&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Having a seven footer is quite rare:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(tallest &amp;gt;= 7*12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0172&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the resulting distribution:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/simulated-tallest-height-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Note that it does not look normal.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;continuous-distributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Continuous distributions&lt;/h2&gt;
&lt;p&gt;The normal distribution is not the only useful theoretical distribution. Other continuous distributions that we may encounter are the student-t, Chi-square, exponential, gamma, beta, and beta-binomial. &lt;code&gt;R&lt;/code&gt; provides functions to compute the density, the quantiles, the cumulative distribution functions and to generate Monte Carlo simulations. &lt;code&gt;R&lt;/code&gt; uses a convention that lets us remember the names, namely using the letters &lt;code&gt;d&lt;/code&gt;, &lt;code&gt;q&lt;/code&gt;, &lt;code&gt;p&lt;/code&gt;, and &lt;code&gt;r&lt;/code&gt; in front of a shorthand for the distribution. We have already seen the functions &lt;code&gt;dnorm&lt;/code&gt;, &lt;code&gt;pnorm&lt;/code&gt;, and &lt;code&gt;rnorm&lt;/code&gt; for the normal distribution. The functions &lt;code&gt;qnorm&lt;/code&gt; gives us the quantiles. We can therefore draw a distribution like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- seq(-4, 4, length.out = 100)
qplot(x, f, geom = &amp;quot;line&amp;quot;, data = data.frame(x, f = dnorm(x)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the student-t, described later as we move toward hypothesis testing, the shorthand &lt;code&gt;t&lt;/code&gt; is used so the functions are &lt;code&gt;dt&lt;/code&gt; for the density, &lt;code&gt;qt&lt;/code&gt; for the quantiles, &lt;code&gt;pt&lt;/code&gt; for the cumulative distribution function, and &lt;code&gt;rt&lt;/code&gt; for Monte Carlo simulation.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is 5 feet or shorter?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is 6 feet or taller?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Assume the distribution of female heights is approximated by a normal distribution with a mean of 64 inches and a standard deviation of 3 inches. If we pick a female at random, what is the probability that she is between 61 and 67 inches?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Repeat the exercise above, but convert everything to centimeters. That is, multiply every height, including the standard deviation, by 2.54. What is the answer now?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Notice that the answer to the question does not change when you change units. This makes sense since the answer to the question should not be affected by what units we use. In fact, if you look closely, you notice that 61 and 64 are both 1 SD away from the average. Compute the probability that a randomly picked, normally distributed random variable is within 1 SD from the average.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To see the math that explains why the answers to questions 3, 4, and 5 are the same, suppose we have a random variable with average &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt; and standard error &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;. Suppose we ask the probability of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; being smaller or equal to &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;. Remember that, by definition, &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\((a - m)/s\)&lt;/span&gt; standard deviations &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; away from the average &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;. The probability is:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}(X \leq a)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Now we subtract &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; to both sides and then divide both sides by &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}\left(\frac{X-m}{s} \leq \frac{a-m}{s} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The quantity on the left is a standard normal random variable. It has an average of 0 and a standard error of 1. We will call it &lt;span class=&#34;math inline&#34;&gt;\(Z\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{Pr}\left(Z \leq \frac{a-m}{s} \right)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So, no matter the units, the probability of &lt;span class=&#34;math inline&#34;&gt;\(X\leq a\)&lt;/span&gt; is the same as the probability of a standard normal variable being less than &lt;span class=&#34;math inline&#34;&gt;\((a - m)/s\)&lt;/span&gt;. If &lt;code&gt;mu&lt;/code&gt; is the average and &lt;code&gt;sigma&lt;/code&gt; the standard error, which of the following R code would give us the right answer in every situation:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;mean(X&amp;lt;=a)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pnorm((a - m)/s)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pnorm((a - m)/s, m, s)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;pnorm(a)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Imagine the distribution of male adults is approximately normal with an expected value of 69 and a standard deviation of 3. How tall is the male in the 99th percentile? Hint: use &lt;code&gt;qnorm&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The distribution of IQ scores is approximately normally distributed. The average is 100 and the standard deviation is 15. Suppose you want to know the distribution of the highest IQ across all graduating classes if 10,000 people are born each in your school district. Run a Monte Carlo simulation with &lt;code&gt;B=1000&lt;/code&gt; generating 10,000 IQ scores and keeping the highest. Make a histogram.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;random-variables&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Random variables&lt;/h1&gt;
&lt;p&gt;In data science, we often deal with data that is affected by chance in some way: the data comes from a random sample, the data is affected by measurement error, or the data measures some outcome that is random in nature. Being able to quantify the uncertainty introduced by randomness is one of the most important jobs of a data analyst. Statistical inference offers a framework, as well as several practical tools, for doing this. The first step is to learn how to mathematically describe random variables.&lt;/p&gt;
&lt;p&gt;In this section, we introduce random variables and their properties starting with their application to games of chance. We then describe some of the events surrounding the financial crisis of 2007-2008&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt; using probability theory. This financial crisis was in part caused by underestimating the risk of certain securities&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt; sold by financial institutions. Specifically, the risks of mortgage-backed securities (MBS) and collateralized debt obligations (CDO) were grossly underestimated. These assets were sold at prices that assumed most homeowners would make their monthly payments, and the probability of this not occurring was calculated as being low. A combination of factors resulted in many more defaults than were expected, which led to a price crash of these securities. As a consequence, banks lost so much money that they needed government bailouts to avoid closing down completely.&lt;/p&gt;
&lt;div id=&#34;definition-of-random-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Definition of Random variables&lt;/h2&gt;
&lt;p&gt;Random variables are numeric outcomes resulting from random processes. We can easily generate random variables using some of the simple examples we have shown. For example, define &lt;code&gt;X&lt;/code&gt; to be 1 if a bead is blue and red otherwise:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;beads &amp;lt;- rep( c(&amp;quot;red&amp;quot;, &amp;quot;blue&amp;quot;), times = c(2,3))
X &amp;lt;- ifelse(sample(beads, 1) == &amp;quot;blue&amp;quot;, 1, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here &lt;code&gt;X&lt;/code&gt; is a random variable: every time we select a new bead the outcome changes randomly. See below:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ifelse(sample(beads, 1) == &amp;quot;blue&amp;quot;, 1, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ifelse(sample(beads, 1) == &amp;quot;blue&amp;quot;, 1, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ifelse(sample(beads, 1) == &amp;quot;blue&amp;quot;, 1, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Sometimes it’s 1 and sometimes it’s 0.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;sampling-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sampling models&lt;/h2&gt;
&lt;p&gt;Many data generation procedures, those that produce the data we study, can be modeled quite well as draws from an urn. For instance, we can model the process of polling likely voters as drawing 0s (Republicans) and 1s (Democrats) from an urn containing the 0 and 1 code for all likely voters. In epidemiological studies, we often assume that the subjects in our study are a random sample from the population of interest. The data related to a specific outcome can be modeled as a random sample from an urn containing the outcome for the entire population of interest. Similarly, in experimental research, we often assume that the individual organisms we are studying, for example worms, flies, or mice, are a random sample from a larger population. Randomized experiments can also be modeled by draws from an urn given the way individuals are assigned into groups: when getting assigned, you draw your group at random. Sampling models are therefore ubiquitous in data science. Casino games offer a plethora of examples of real-world situations in which sampling models are used to answer specific questions. We will therefore start with such examples.&lt;/p&gt;
&lt;p&gt;Suppose a very small casino hires you to consult on whether they should set up roulette wheels. To keep the example simple, we will assume that 1,000 people will play and that the only game you can play on the roulette wheel is to bet on red or black. The casino wants you to predict how much money they will make or lose. They want a range of values and, in particular, they want to know what’s the chance of losing money. If this probability is too high, they will pass on installing roulette wheels.&lt;/p&gt;
&lt;p&gt;We are going to define a random variable &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; that will represent the casino’s total winnings. Let’s start by constructing the urn. A roulette wheel has 18 red pockets, 18 black pockets and 2 green ones. So playing a color in one game of roulette is equivalent to drawing from this urn:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color &amp;lt;- rep(c(&amp;quot;Black&amp;quot;, &amp;quot;Red&amp;quot;, &amp;quot;Green&amp;quot;), c(18, 18, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 1,000 outcomes from 1,000 people playing are independent draws from this urn. If red comes up, the gambler wins and the casino loses a dollar, so we draw a -1. Otherwise, the casino wins a dollar and we draw a 1. To construct our random variable &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;, we can use this code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1000
X &amp;lt;- sample(ifelse(color == &amp;quot;Red&amp;quot;, -1, 1),  n, replace = TRUE)
X[1:10]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] -1  1  1 -1 -1 -1  1  1  1  1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because we know the proportions of 1s and -1s, we can generate the draws with one line of code, without defining &lt;code&gt;color&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We call this a &lt;strong&gt;sampling model&lt;/strong&gt; since we are modeling the random behavior of roulette with the sampling of draws from an urn. The total winnings &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is simply the sum of these 1,000 independent draws:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;X &amp;lt;- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
S &amp;lt;- sum(X)
S&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 22&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-probability-distribution-of-a-random-variable&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The probability distribution of a random variable&lt;/h2&gt;
&lt;p&gt;If you run the code above, you see that &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; changes every time. This is, of course, because &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is a &lt;strong&gt;random variable&lt;/strong&gt;. The probability distribution of a random variable tells us the probability of the observed value falling at any given interval. So, for example, if we want to know the probability that we lose money, we are asking the probability that &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is in the interval &lt;span class=&#34;math inline&#34;&gt;\(S&amp;lt;0\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note that if we can define a cumulative distribution function &lt;span class=&#34;math inline&#34;&gt;\(F(a) = \mbox{Pr}(S\leq a)\)&lt;/span&gt;, then we will be able to answer any question related to the probability of events defined by our random variable &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;, including the event &lt;span class=&#34;math inline&#34;&gt;\(S&amp;lt;0\)&lt;/span&gt;. We call this &lt;span class=&#34;math inline&#34;&gt;\(F\)&lt;/span&gt; the random variable’s &lt;em&gt;distribution function&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We can estimate the distribution function for the random variable &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; by using a Monte Carlo simulation to generate many realizations of the random variable. With this code, we run the experiment of having 1,000 people play roulette, over and over, specifically &lt;span class=&#34;math inline&#34;&gt;\(B = 10,000\)&lt;/span&gt; times:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1000
B &amp;lt;- 10000
roulette_winnings &amp;lt;- function(n){
  X &amp;lt;- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S &amp;lt;- replicate(B, roulette_winnings(n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can ask the following: in our simulations, how often did we get sums less than or equal to &lt;code&gt;a&lt;/code&gt;?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(S &amp;lt;= a)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This will be a very good approximation of &lt;span class=&#34;math inline&#34;&gt;\(F(a)\)&lt;/span&gt; and we can easily answer the casino’s question: how likely is it that we will lose money? We can see it is quite low:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(S&amp;lt;0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0456&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can visualize the distribution of &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; by creating a histogram showing the probability &lt;span class=&#34;math inline&#34;&gt;\(F(b)-F(a)\)&lt;/span&gt; for several intervals &lt;span class=&#34;math inline&#34;&gt;\((a,b]\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/05-content_files/figure-html/normal-approximates-distribution-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We see that the distribution appears to be approximately normal. A qq-plot will confirm that the normal approximation is close to a perfect approximation for this distribution. If, in fact, the distribution is normal, then all we need to define the distribution is the average and the standard deviation. Because we have the original values from which the distribution is created, we can easily compute these with &lt;code&gt;mean(S)&lt;/code&gt; and &lt;code&gt;sd(S)&lt;/code&gt;. The blue curve you see added to the histogram above is a normal density with this average and standard deviation.&lt;/p&gt;
&lt;p&gt;This average and this standard deviation have special names. They are referred to as the &lt;em&gt;expected value&lt;/em&gt; and &lt;em&gt;standard error&lt;/em&gt; of the random variable &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;. We will say more about these in the next section.&lt;/p&gt;
&lt;p&gt;Statistical theory provides a way to derive the distribution of random variables defined as independent random draws from an urn. Specifically, in our example above, we can show that &lt;span class=&#34;math inline&#34;&gt;\((S+n)/2\)&lt;/span&gt; follows a binomial distribution. We therefore do not need to run for Monte Carlo simulations to know the probability distribution of &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt;. We did this for illustrative purposes.&lt;/p&gt;
&lt;p&gt;We can use the function &lt;code&gt;dbinom&lt;/code&gt; and &lt;code&gt;pbinom&lt;/code&gt; to compute the probabilities exactly. For example, to compute &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(S &amp;lt; 0)\)&lt;/span&gt; we note that:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{Pr}(S &amp;lt; 0) = \mbox{Pr}((S+n)/2 &amp;lt; (0+n)/2)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and we can use the &lt;code&gt;pbinom&lt;/code&gt; to compute &lt;span class=&#34;math display&#34;&gt;\[\mbox{Pr}(S \leq 0)\]&lt;/span&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1000
pbinom(n/2, size = n, prob = 10/19)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.05109794&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Because this is a discrete probability function, to get &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(S &amp;lt; 0)\)&lt;/span&gt; rather than &lt;span class=&#34;math inline&#34;&gt;\(\mbox{Pr}(S \leq 0)\)&lt;/span&gt;, we write:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pbinom(n/2-1, size = n, prob = 10/19)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04479591&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the details of the binomial distribution, you can consult any basic probability book or even Wikipedia&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here we do not cover these details. Instead, we will discuss an incredibly useful approximation provided by mathematical theory that applies generally to sums and averages of draws from any urn: the Central Limit Theorem (CLT).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;distributions-versus-probability-distributions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Distributions versus probability distributions&lt;/h2&gt;
&lt;p&gt;Before we continue, let’s make an important distinction and connection between the distribution of a list of numbers and a probability distribution. In the visualization lectures, we described how any list of numbers &lt;span class=&#34;math inline&#34;&gt;\(x_1,\dots,x_n\)&lt;/span&gt; has a distribution. The definition is quite straightforward. We define &lt;span class=&#34;math inline&#34;&gt;\(F(a)\)&lt;/span&gt; as the function that tells us what proportion of the list is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;. Because they are useful summaries when the distribution is approximately normal, we define the average and standard deviation. These are defined with a straightforward operation of the vector containing the list of numbers &lt;code&gt;x&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- sum(x)/length(x)
s &amp;lt;- sqrt(sum((x - m)^2) / length(x))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A random variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; has a distribution function. To define this, we do not need a list of numbers. It is a theoretical concept. In this case, we define the distribution as the &lt;span class=&#34;math inline&#34;&gt;\(F(a)\)&lt;/span&gt; that answers the question: what is the probability that &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is less than or equal to &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;? There is no list of numbers.&lt;/p&gt;
&lt;p&gt;However, if &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is defined by drawing from an urn with numbers in it, then there is a list: the list of numbers inside the urn. In this case, the distribution of that list is the probability distribution of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; and the average and standard deviation of that list are the expected value and standard error of the random variable.&lt;/p&gt;
&lt;p&gt;Another way to think about it that does not involve an urn is to run a Monte Carlo simulation and generate a very large list of outcomes of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. These outcomes are a list of numbers. The distribution of this list will be a very good approximation of the probability distribution of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. The longer the list, the better the approximation. The average and standard deviation of this list will approximate the expected value and standard error of the random variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;notation-for-random-variables&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Notation for random variables&lt;/h2&gt;
&lt;p&gt;In statistical textbooks, upper case letters are used to denote random variables and we follow this convention here. Lower case letters are used for observed values. You will see some notation that includes both. For example, you will see events defined as &lt;span class=&#34;math inline&#34;&gt;\(X \leq x\)&lt;/span&gt;. Here &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is a random variable, making it a random event, and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; is an arbitrary value and not random. So, for example, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; might represent the number on a die roll and &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; will represent an actual value we see 1, 2, 3, 4, 5, or 6. So in this case, the probability of &lt;span class=&#34;math inline&#34;&gt;\(X=x\)&lt;/span&gt; is 1/6 regardless of the observed value &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. This notation is a bit strange because, when we ask questions about probability, &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is not an observed quantity. Instead, it’s a random quantity that we will see in the future. We can talk about what we expect it to be, what values are probable, but not what it is. But once we have data, we do see a realization of &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;. So data scientists talk of what could have been after we see what actually happened.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-expected-value-and-standard-error&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The expected value and standard error&lt;/h2&gt;
&lt;p&gt;We have described sampling models for draws. We will now go over the mathematical theory that lets us approximate the probability distributions for the sum of draws. Once we do this, we will be able to help the casino predict how much money they will make. The same approach we use for the sum of draws will be useful for describing the distribution of averages and proportion which we will need to understand how polls work.&lt;/p&gt;
&lt;p&gt;The first important concept to learn is the &lt;em&gt;expected value&lt;/em&gt;.
In statistics books, it is common to use letter &lt;span class=&#34;math inline&#34;&gt;\(\mbox{E}\)&lt;/span&gt; like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{E}[X]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;to denote the expected value of the random variable &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A random variable will vary around its expected value in a way that if you take the average of many, many draws, the average of the draws will approximate the expected value, getting closer and closer the more draws you take.&lt;/p&gt;
&lt;p&gt;Theoretical statistics provides techniques that facilitate the calculation of expected values in different circumstances. For example, a useful formula tells us that the &lt;em&gt;expected value of a random variable defined by one draw is the average of the numbers in the urn&lt;/em&gt;. In the urn used to model betting on red in roulette, we have 20 one dollars and 18 negative one dollars. The expected value is thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}[X] = (20 + -18)/38
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which is about 5 cents. It is a bit counterintuitive to say that &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; varies around 0.05, when the only values it takes is 1 and -1. One way to make sense of the expected value in this context is by realizing that if we play the game over and over, the casino wins, on average, 5 cents per game. A Monte Carlo simulation confirms this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;B &amp;lt;- 10^6
x &amp;lt;- sample(c(-1,1), B, replace = TRUE, prob=c(9/19, 10/19))
mean(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.05169&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In general, if the urn has two possible outcomes, say &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, with proportions &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(1-p\)&lt;/span&gt; respectively, the average is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{E}[X] = ap + b(1-p)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To see this, notice that if there are &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; beads in the urn, then we have &lt;span class=&#34;math inline&#34;&gt;\(np\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;s and &lt;span class=&#34;math inline&#34;&gt;\(n(1-p)\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;s and because the average is the sum, &lt;span class=&#34;math inline&#34;&gt;\(n\times a \times p + n\times b \times (1-p)\)&lt;/span&gt;, divided by the total &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, we get that the average is &lt;span class=&#34;math inline&#34;&gt;\(ap + b(1-p)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Now the reason we define the expected value is because this mathematical definition turns out to be useful for approximating the probability distributions of sum, which then is useful for describing the distribution of averages and proportions. The first useful fact is that the &lt;em&gt;expected value of the sum of the draws&lt;/em&gt; is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{}\mbox{number of draws } \times \mbox{ average of the numbers in the urn}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So if 1,000 people play roulette, the casino expects to win, on average, about 1,000 &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; $0.05 = $50. But this is an expected value. How different can one observation be from the expected value? The casino really needs to know this. What is the range of possibilities? If negative numbers are too likely, they will not install roulette wheels. Statistical theory once again answers this question. The &lt;em&gt;standard error&lt;/em&gt; (SE) gives us an idea of the size of the variation around the expected value. In statistics books, it’s common to use:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mbox{SE}[X]\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;to denote the standard error of a random variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If our draws are independent&lt;/strong&gt;, then the &lt;em&gt;standard error of the sum&lt;/em&gt; is given by the equation:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\sqrt{\mbox{number of draws }} \times \mbox{ standard deviation of the numbers in the urn}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Using the definition of standard deviation, we can derive, with a bit of math, that if an urn contains two values &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; with proportions &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\((1-p)\)&lt;/span&gt;, respectively, the standard deviation is:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\mid b - a \mid \sqrt{p(1-p)}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;So in our roulette example, the standard deviation of the values inside the urn is: &lt;span class=&#34;math inline&#34;&gt;\(\mid 1 - (-1) \mid \sqrt{10/19 \times 9/19}\)&lt;/span&gt; or:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;2 * sqrt(90)/19&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.998614&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The standard error tells us the typical difference between a random variable and its expectation. Since one draw is obviously the sum of just one draw, we can use the formula above to calculate that the random variable defined by one draw has an expected value of 0.05 and a standard error of about 1. This makes sense since we either get 1 or -1, with 1 slightly favored over -1.&lt;/p&gt;
&lt;p&gt;Using the formula above, the sum of 1,000 people playing has standard error of about $32:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1000
sqrt(n) * 2 * sqrt(90)/19&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 31.57895&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a result, when 1,000 people bet on red, the casino is expected to win $50 with a standard error of $32. It therefore seems like a safe bet. But we still haven’t answered the question: how likely is it to lose money? Here the CLT will help.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advanced note&lt;/strong&gt;: Before continuing we should point out that exact probability calculations for the casino winnings can be performed with the binomial distribution. However, here we focus on the CLT, which can be generally applied to sums of random variables in a way that the binomial distribution can’t.&lt;/p&gt;
&lt;div id=&#34;population-sd-versus-the-sample-sd&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Population SD versus the sample SD&lt;/h3&gt;
&lt;p&gt;The standard deviation of a list &lt;code&gt;x&lt;/code&gt; (below we use heights as an example) is defined as the square root of the average of the squared differences:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
x &amp;lt;- heights$height
m &amp;lt;- mean(x)
s &amp;lt;- sqrt(mean((x-m)^2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using mathematical notation we write:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mu = \frac{1}{n} \sum_{i=1}^n x_i \\
\sigma =  \sqrt{\frac{1}{n} \sum_{i=1}^n (x_i - \mu)^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;However, be aware that the &lt;code&gt;sd&lt;/code&gt; function returns a slightly different result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;identical(s, sd(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s-sd(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.001942661&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is because the &lt;code&gt;sd&lt;/code&gt; function R does not return the &lt;code&gt;sd&lt;/code&gt; of the list, but rather uses a formula that estimates standard deviations of a population from a random sample &lt;span class=&#34;math inline&#34;&gt;\(X_1, \dots, X_N\)&lt;/span&gt; which, for reasons not discussed here, divide the sum of squares by the &lt;span class=&#34;math inline&#34;&gt;\(N-1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\bar{X} = \frac{1}{N} \sum_{i=1}^N X_i, \,\,\,\,
s =  \sqrt{\frac{1}{N-1} \sum_{i=1}^N (X_i - \bar{X})^2}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You can see that this is the case by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- length(x)
s-sd(x)*sqrt((n-1) / n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For all the theory discussed here, you need to compute the actual standard deviation as defined:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(mean((x-m)^2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So be careful when using the &lt;code&gt;sd&lt;/code&gt; function in R. However, keep in mind that throughout the book we sometimes use the &lt;code&gt;sd&lt;/code&gt; function when we really want the actual SD. This is because when the list size is big, these two are practically equivalent since &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{(N-1)/N} \approx 1\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;central-limit-theorem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Central Limit Theorem&lt;/h2&gt;
&lt;p&gt;The Central Limit Theorem (CLT) tells us that when the number of draws, also called the &lt;em&gt;sample size&lt;/em&gt;, is large, the probability distribution of the sum of the independent draws is approximately normal. Because sampling models are used for so many data generation processes, the CLT is considered one of the most important mathematical insights in history.&lt;/p&gt;
&lt;p&gt;Previously, we discussed that if we know that the distribution of a list of numbers is approximated by the normal distribution, all we need to describe the list are the average and standard deviation. We also know that the same applies to probability distributions. If a random variable has a probability distribution that is approximated with the normal distribution, then all we need to describe the probability distribution are the average and standard deviation, referred to as the expected value and standard error.&lt;/p&gt;
&lt;p&gt;We previously ran this Monte Carlo simulation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1000
B &amp;lt;- 10000
roulette_winnings &amp;lt;- function(n){
  X &amp;lt;- sample(c(-1,1), n, replace = TRUE, prob=c(9/19, 10/19))
  sum(X)
}
S &amp;lt;- replicate(B, roulette_winnings(n))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The Central Limit Theorem (CLT) tells us that the sum &lt;span class=&#34;math inline&#34;&gt;\(S\)&lt;/span&gt; is approximated by a normal distribution.
Using the formulas above, we know that the expected value and standard error are:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n * (20-18)/38&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 52.63158&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sqrt(n) * 2 * sqrt(90)/19&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 31.57895&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The theoretical values above match those obtained with the Monte Carlo simulation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(S)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 52.2242&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(S)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 31.65508&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using the CLT, we can skip the Monte Carlo simulation and instead compute the probability of the casino losing money using this approximation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu &amp;lt;- n * (20-18)/38
se &amp;lt;-  sqrt(n) * 2 * sqrt(90)/19
pnorm(0, mu, se)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.04779035&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which is also in very good agreement with our Monte Carlo result:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(S &amp;lt; 0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.0458&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;how-large-is-large-in-the-central-limit-theorem&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How large is large in the Central Limit Theorem?&lt;/h3&gt;
&lt;p&gt;The CLT works when the number of draws is large. But large is a relative term. In many circumstances as few as 30 draws is enough to make the CLT useful. In some specific instances, as few as 10 is enough. However, these should not be considered general rules. Note, for example, that when the probability of success is very small, we need much larger sample sizes.&lt;/p&gt;
&lt;p&gt;By way of illustration, let’s consider the lottery. In the lottery, the chances of winning are less than 1 in a million. Thousands of people play so the number of draws is very large. Yet the number of winners, the sum of the draws, range between 0 and 4. This sum is certainly not well approximated by a normal distribution, so the CLT does not apply, even with the very large sample size. This is generally true when the probability of a success is very low. In these cases, the Poisson distribution is more appropriate.&lt;/p&gt;
&lt;p&gt;You can examine the properties of the Poisson distribution using &lt;code&gt;dpois&lt;/code&gt; and &lt;code&gt;ppois&lt;/code&gt;. You can generate random variables following this distribution with &lt;code&gt;rpois&lt;/code&gt;. However, we do not cover the theory here. You can learn about the Poisson distribution in any probability textbook and even Wikipedia&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;statistical-properties-of-averages&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Statistical properties of averages&lt;/h2&gt;
&lt;p&gt;There are several useful mathematical results that we used above and often employ when working with data. We list them below.&lt;/p&gt;
&lt;p&gt;1. The expected value of the sum of random variables is the sum of each random variable’s expected value. We can write it like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}[X_1+X_2+\dots+X_n] =  \mbox{E}[X_1] + \mbox{E}[X_2]+\dots+\mbox{E}[X_n]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;If the &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; are independent draws from the urn, then they all have the same expected value. Let’s call it &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and thus:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}[X_1+X_2+\dots+X_n]=  n\mu
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which is another way of writing the result we show above for the sum of draws.&lt;/p&gt;
&lt;p&gt;2. The expected value of a non-random constant times a random variable is the non-random constant times the expected value of a random variable. This is easier to explain with symbols:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}[aX] =  a\times\mbox{E}[X]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To see why this is intuitive, consider change of units. If we change the units of a random variable, say from dollars to cents, the expectation should change in the same way. A consequence of the above two facts is that the expected value of the average of independent draws from the same urn is the expected value of the urn, call it &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; again:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{E}[(X_1+X_2+\dots+X_n) / n]=   \mbox{E}[X_1+X_2+\dots+X_n] / n = n\mu/n = \mu
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;3. The square of the standard error of the sum of &lt;strong&gt;independent&lt;/strong&gt; random variables is the sum of the square of the standard error of each random variable. This one is easier to understand in math form:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\mbox{SE}[X_1+X_2+\dots+X_n] = \sqrt{\mbox{SE}[X_1]^2 + \mbox{SE}[X_2]^2+\dots+\mbox{SE}[X_n]^2  }
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The square of the standard error is referred to as the &lt;em&gt;variance&lt;/em&gt; in statistical textbooks. Note that this particular property is not as intuitive as the previous three and more in depth explanations can be found in statistics textbooks.&lt;/p&gt;
&lt;p&gt;4. The standard error of a non-random constant times a random variable is the non-random constant times the random variable’s standard error. As with the expectation:
&lt;span class=&#34;math display&#34;&gt;\[
\mbox{SE}[aX] =  a \times \mbox{SE}[X]
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To see why this is intuitive, again think of units.&lt;/p&gt;
&lt;p&gt;A consequence of 3 and 4 is that the standard error of the average of independent draws from the same urn is the standard deviation of the urn divided by the square root of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; (the number of draws), call it &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{aligned}
\mbox{SE}[(X_1+X_2+\dots+X_n) / n] &amp;amp;=   \mbox{SE}[X_1+X_2+\dots+X_n]/n \\
&amp;amp;= \sqrt{\mbox{SE}[X_1]^2+\mbox{SE}[X_2]^2+\dots+\mbox{SE}[X_n]^2}/n \\
&amp;amp;= \sqrt{\sigma^2+\sigma^2+\dots+\sigma^2}/n\\
&amp;amp;= \sqrt{n\sigma^2}/n\\
&amp;amp;= \sigma / \sqrt{n}
\end{aligned}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;5. If &lt;span class=&#34;math inline&#34;&gt;\(X\)&lt;/span&gt; is a normally distributed random variable, then if &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt; are non-random constants, &lt;span class=&#34;math inline&#34;&gt;\(aX + b\)&lt;/span&gt; is also a normally distributed random variable. All we are doing is changing the units of the random variable by multiplying by &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;, then shifting the center by &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Note that statistical textbooks use the Greek letters &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; to denote the expected value and standard error, respectively. This is because &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the Greek letter for &lt;span class=&#34;math inline&#34;&gt;\(m\)&lt;/span&gt;, the first letter of &lt;em&gt;mean&lt;/em&gt;, which is another term used for expected value. Similarly, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is the Greek letter for &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt;, the first letter of standard error.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;law-of-large-numbers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Law of large numbers&lt;/h2&gt;
&lt;p&gt;An important implication of the final result is that the standard error of the average becomes smaller and smaller as &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; grows larger. When &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is very large, then the standard error is practically 0 and the average of the draws converges to the average of the urn. This is known in statistical textbooks as the law of large numbers or the law of averages.&lt;/p&gt;
&lt;div id=&#34;misinterpreting-law-of-averages&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Misinterpreting law of averages&lt;/h3&gt;
&lt;p&gt;The law of averages is sometimes misinterpreted. For example, if you toss a coin 5 times and see a head each time, you might hear someone argue that the next toss is probably a tail because of the law of averages: on average we should see 50% heads and 50% tails. A similar argument would be to say that red “is due” on the roulette wheel after seeing black come up five times in a row. These events are independent so the chance of a coin landing heads is 50% regardless of the previous 5. This is also the case for the roulette outcome. The law of averages applies only when the number of draws is very large and not in small samples. After a million tosses, you will definitely see about 50% heads regardless of the outcome of the first five tosses.&lt;/p&gt;
&lt;p&gt;Another funny misuse of the law of averages is in sports when TV sportscasters predict a player is about to succeed because they have failed a few times in a row.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Urn_problem&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Urn_problem&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.khanacademy.org/math/precalculus/prob-comb/dependent-events-precalc/v/monty-hall-problem&#34; class=&#34;uri&#34;&gt;https://www.khanacademy.org/math/precalculus/prob-comb/dependent-events-precalc/v/monty-hall-problem&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Monty_Hall_problem&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/wiki/Monty_Hall_problem&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Financial_crisis_of_2007%E2%80%932008&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/w/index.php?title=Financial_crisis_of_2007%E2%80%932008&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Security_(finance)&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/w/index.php?title=Security_(finance)&lt;/a&gt;&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Binomial_distribution&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/w/index.php?title=Binomial_distribution&lt;/a&gt;&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Poisson_distribution&#34; class=&#34;uri&#34;&gt;https://en.wikipedia.org/w/index.php?title=Poisson_distribution&lt;/a&gt;&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Welcome Back to R</title>
      <link>https://ssc442.netlify.app/content/01-content/</link>
      <pubDate>Wed, 30 Dec 2020 00:00:00 +0000</pubDate>
      <guid>https://ssc442.netlify.app/content/01-content/</guid>
      <description>
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;
&lt;script src=&#34;https://ssc442.netlify.app/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;https://ssc442.netlify.app/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#readings&#34;&gt;Readings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-brief-introduction-to-ssc442&#34;&gt;A Brief Introduction to SSC442&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#about-me&#34;&gt;About Me&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#about-you&#34;&gt;About You&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#this-course&#34;&gt;This Course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#more-about-this-course&#34;&gt;More About This Course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#and-finally&#34;&gt;And finally…&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#guiding-questions&#34;&gt;Guiding Questions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#what-is-data-analytics&#34;&gt;What is “Data Analytics”?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#starting-point-for-this-course&#34;&gt;Starting point for this course&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#statistical-learning&#34;&gt;Statistical Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-pros-and-cons-of-correlation&#34;&gt;The Pros and Cons of Correlation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#a-case-study-in-prediction&#34;&gt;A Case Study in Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#more-recent-examples-of-prediction&#34;&gt;More Recent Examples of Prediction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#an-aside-nomenclature&#34;&gt;An Aside: Nomenclature&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#learning-from-data&#34;&gt;Learning from Data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r-basics&#34;&gt;&lt;code&gt;R&lt;/code&gt; basics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#case-study-us-homicides-by-firearm&#34;&gt;Case study: US homicides by firearm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-very-basics&#34;&gt;The (very) basics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#objects&#34;&gt;Objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-workspace&#34;&gt;The workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#functions&#34;&gt;Functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#other-prebuilt-objects&#34;&gt;Other prebuilt objects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#variable-names&#34;&gt;Variable names&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#saving-your-workspace&#34;&gt;Saving your workspace&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#motivating-scripts&#34;&gt;Motivating scripts&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#commenting-your-code&#34;&gt;Commenting your code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-types&#34;&gt;Data types&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data-frames&#34;&gt;Data frames&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#examining-an-object&#34;&gt;Examining an object&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-accessor&#34;&gt;The accessor: &lt;code&gt;$&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vectors-numerics-characters-and-logical&#34;&gt;Vectors: numerics, characters, and logical&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#factors&#34;&gt;Factors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lists&#34;&gt;Lists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#matrices&#34;&gt;Matrices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vectors&#34;&gt;Vectors&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#creating-vectors&#34;&gt;Creating vectors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#names&#34;&gt;Names&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sequences&#34;&gt;Sequences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting&#34;&gt;Subsetting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#coercion&#34;&gt;Coercion&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#not-availables-na&#34;&gt;Not availables (NA)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sorting&#34;&gt;Sorting&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#sort&#34;&gt;&lt;code&gt;sort&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#order&#34;&gt;&lt;code&gt;order&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#max-and-which.max&#34;&gt;&lt;code&gt;max&lt;/code&gt; and &lt;code&gt;which.max&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rank&#34;&gt;&lt;code&gt;rank&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#beware-of-recycling&#34;&gt;Beware of recycling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vector-arithmetics&#34;&gt;Vector arithmetics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#rescaling-a-vector&#34;&gt;Rescaling a vector&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#two-vectors&#34;&gt;Two vectors&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#indexing&#34;&gt;Indexing&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting-with-logicals&#34;&gt;Subsetting with logicals&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#logical-operators&#34;&gt;Logical operators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#which&#34;&gt;&lt;code&gt;which&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#match&#34;&gt;&lt;code&gt;match&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#in&#34;&gt;&lt;code&gt;%in%&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#rmarkdown&#34;&gt;Rmarkdown&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;readings&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Readings&lt;/h2&gt;
&lt;p&gt;As noted in the syllabus, your readings will be assigned each week in this area. For this initial week, please read the course content. &lt;strong&gt;Read closely&lt;/strong&gt; the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;a href=&#34;https://ssc442.netlify.app/syllabus/&#34;&gt;syllabus&lt;/a&gt;, &lt;a href=&#34;https://ssc442.netlify.app/content/&#34;&gt;content&lt;/a&gt;, &lt;a href=&#34;https://ssc442.netlify.app/example/&#34;&gt;examples&lt;/a&gt;, and &lt;a href=&#34;https://ssc442.netlify.app/lab/&#34;&gt;labs&lt;/a&gt; pages for this class.&lt;/li&gt;
&lt;li&gt;This page. Yes, the whole thing.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Things to stress from syllabus:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;E-mail isn’t the ideal solution for technical problems&lt;/li&gt;
&lt;li&gt;No appointments necessary for regularly scheduled office hours; or by appointment.&lt;/li&gt;
&lt;li&gt;TA office hours are great as well. Our TA has experience in this course.&lt;/li&gt;
&lt;li&gt;Can only reschedule exams (with good reason) if you tell me &lt;strong&gt;before&lt;/strong&gt; the exam that you have a conflict.
&lt;ul&gt;
&lt;li&gt;Notify me immediately if you need accommodations because of RCPD or religious convictions; If you approach me at the last minute, I may not be able to help.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite my apparent hard-assness, I’m here to help. I am not in the business of giving bad grades for no reason, and I genuinely want you to learn a lot and enjoy the course.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;a-brief-introduction-to-ssc442&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A Brief Introduction to SSC442&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;I keep saying that the sexy job in the next 10 years will be statisticians. And I’m not kidding.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;hal-varian-chief-economist-google&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Hal Varian, Chief Economist, Google&lt;/h4&gt;
&lt;/div&gt;
&lt;div id=&#34;about-me&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;About Me&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Me:&lt;/strong&gt; My primary area of expertise is behavioral economics (also known as psychology and economics). While my research occasionally touches the topics in the course, I mostly utilize things in the course as tools. In this way, we are likely the same.&lt;/p&gt;
&lt;p&gt;This class is totally, unapologetically a work in progress. The material is a mish-mash of stuff from courses offered at Caltech, Stanford, Harvard, and Duke…so, yeah, it will be challenging. Hopefully, you’ll find it fun!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;about-you&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;About You&lt;/h3&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;em&gt;New phone who dis?&lt;/em&gt; Please email me bbushong@msu.edu your&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;name (with pronunciation guide)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;major&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;desired graduation year and semester&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;interest in this course on a 10-point scale (1: not at all interested; 10: helllllll yeah)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;p&gt;You &lt;strong&gt;must&lt;/strong&gt; spend 5 minutes emailing me a little bit about your interests before the next class.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;this-course&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;This Course&lt;/h3&gt;
&lt;p&gt;The syllabus is posted on the course website. I’ll walk through highlights now, but read it later – it’s long.
- But eventually, please read it. It is “required.”&lt;/p&gt;
&lt;p&gt;Syllabus highlights:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Grade is composed of weekly writings, labs, and projects.
&lt;ul&gt;
&lt;li&gt;Weekly writings: 22%&lt;/li&gt;
&lt;li&gt;Participation: 4%&lt;/li&gt;
&lt;li&gt;Labs: 29%&lt;/li&gt;
&lt;li&gt;Projects: 45%&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;This structure is designed to give ~55% “for free”. Success on the projects will require real work.&lt;/li&gt;
&lt;li&gt;Labs consist of a practical implementation of something we’ve covered in the course (e.g., code your own Recommender System).&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;grading&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Grading&lt;/h4&gt;
&lt;p&gt;Grading: &lt;strong&gt;come to class.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If&lt;/strong&gt; you complete all assignments and attend all class dates, I suspect you will do very well. Given the way the syllabus is structured, I conjecture that the following is a loose guide to grades:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;4.0&lt;/code&gt; Turned in all assignments with good effort, worked hard on the projects and was proud of final product.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;3.5&lt;/code&gt; Turned in all assignments with good effort, worked a bit on the projects and was indifferent to final product.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;3.0&lt;/code&gt; Turned in all assignments with some effort, worked a bit on the projects and was shy about final product.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt; 3.0&lt;/code&gt; Very little effort, or did not turn in all assignments, worked very little on the projects and was embarassed by final product.&lt;/p&gt;
&lt;p&gt;…of course, failing to turn in assignments can lead to a grade dramatically &lt;strong&gt;lower&lt;/strong&gt; than just a 3.0.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;more-about-this-course&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;More About This Course&lt;/h3&gt;
&lt;p&gt;There are sort of three texts for this course and sort of zero.&lt;/p&gt;
&lt;p&gt;The “main text” is free and available online. The secondary text is substantially more difficult, but also free online. The third text costs about $25. Assigned readings can be found on the course website under “Content”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Please please please please please:&lt;/strong&gt; Ask questions during class.
- Most ideas will be new.
- Sometimes (often?) the material itself will be confusing or interesting—or both!
- Teaching is incredibly challenging right now.
- &lt;strong&gt;Note:&lt;/strong&gt; If I find that attendance is terrible, I may have to start incorporating attendance into participation.&lt;/p&gt;
&lt;p&gt;Return of the Please: If there is some topic that you really want to learn about, ask. If you are uncomfortable asking in front of the whole group, please see me during office hours.&lt;/p&gt;
&lt;p&gt;Because this is a new course:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some of the lectures will be way too long or too short.&lt;/li&gt;
&lt;li&gt;Some (most?) of the lectures won’t make sense.&lt;/li&gt;
&lt;li&gt;Some of the time I’ll forget what I intended to say and awkwardly stare at you for a few moments (sorry).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Comment &lt;strong&gt;throughout&lt;/strong&gt; the course, not just at the end.&lt;/p&gt;
&lt;p&gt;The material will improve with time and feedback.&lt;/p&gt;
&lt;p&gt;I encourage measured feedback and thoughtful responses to questions. If I call on you and you don’t know immediately, don’t freak out. If you don’t know, it’s totally okay to say you don’t know.&lt;/p&gt;
&lt;div id=&#34;super-big-important-explanation-of-the-course&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;SUPER BIG IMPORTANT EXPLANATION OF THE COURSE&lt;/h4&gt;
&lt;p&gt;We teach using “math”. Don’t be afraid. The math won’t hurt you. I fundamentally believe that true knowledge of how we learn from data depends on a basic understanding of the underlying mathematics.&lt;/p&gt;
&lt;p&gt;-The good news is that you’ll face no black boxes. In this class you’ll &lt;strong&gt;actually learn&lt;/strong&gt; how things work. (Probably. Hopefully?)
-More good news: the level of required math is reasonably low. High-school algebra or equivalent should be fine.
-The bad news is that (at times) the course is notation-heavy. This class will require an active mind.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;and-finally&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;And finally…&lt;/h3&gt;
&lt;p&gt;I cannot address field-specific questions in areas outside economics to any satisfying degree. I’m good at knowing what I don’t know and have a very small ego, which means that I’m much less likely to blow smoke up your ass than other professors. So I won’t pretend I know everything. Of course, this implies that I can’t help with certain types of questions.&lt;/p&gt;
&lt;p&gt;This course should be applicable broadly, but many of the examples will lean on my personal expertise (sorry).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;guiding-questions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Guiding Questions&lt;/h3&gt;
&lt;p&gt;For future lectures, the guiding questions will be more pointed and at a higher level to help steer your thinking. Here, we want to ensure you remember some basics and accordingly the questions are straightforward.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do you remember anything about &lt;code&gt;R&lt;/code&gt;?&lt;/li&gt;
&lt;li&gt;What are the different data types in &lt;code&gt;R&lt;/code&gt;?&lt;/li&gt;
&lt;li&gt;How do you index specific elements of a vector? Why might you want to do that?&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;what-is-data-analytics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;What is “Data Analytics”?&lt;/h1&gt;
&lt;p&gt;How do &lt;strong&gt;you&lt;/strong&gt; define “data analytics”? (Not a rhetorical question!)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;This course will avoid this nomenclature. It is confusing and imprecise. But you signed up (suckers) and I owe an explanation of what this course will cover.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Some “data analytics” topics we will cover:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linear regression (&lt;em&gt;il classico&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;Models of classification or discrete choice.&lt;/li&gt;
&lt;li&gt;Analysis of ``wide’’ data.&lt;/li&gt;
&lt;li&gt;Decision trees and other non-linear models.&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;starting-point-for-this-course&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Starting point for this course&lt;/h2&gt;
&lt;p&gt;Better utilizing existing data can improve our predictive power whilst providing interpretable outputs for considering new policies.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;WARNING:&lt;/strong&gt; Causation is tough and we will spend the entire course warning you to avoid making causal claims!&lt;/p&gt;
&lt;div id=&#34;statistical-learning&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Statistical Learning&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;A Brief History&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Suppose you are a researcher and you want to teach a computer to recognize images of a tree.&lt;/p&gt;
&lt;p&gt;Note: this is an ``easy” problem. If you show pictures to a 3-year-old, that child will probably be able to tell you if there is a tree in the picture.&lt;/p&gt;
&lt;p&gt;Computer scientists spent about 20 years on this problem because they thought about the problem like nerds and tried to write down a series of rules.&lt;/p&gt;
&lt;p&gt;Rules are difficult to form, and simply writing rules misses the key insight: the data can tell you something.&lt;/p&gt;
&lt;div id=&#34;social-science-approaches-to-statistical-learning&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Social Science Approaches to Statistical Learning&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;A Brief History&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Suppose you are a researcher and you want to know whether prisons reduce crime.&lt;/p&gt;
&lt;p&gt;from ``A Call for a Moratorium on Prison Building’’ (1976)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Between 1955 and 1975, fifteen states increased the collective capacity of their adult prison systems by 56% (from, on average, 63,100 to 98,649).&lt;/li&gt;
&lt;li&gt;Fifteen other states increased capacity by less than 4% (from 49,575 to 51,440).&lt;/li&gt;
&lt;li&gt;In “heavy-construction” states the crime rate increased by 167%; in “low-construction” states the crime rate increased by 145%.&lt;/li&gt;
&lt;/ul&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Prison Capacity&lt;/th&gt;
&lt;th&gt;Crime Rate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;High construction&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\uparrow\)&lt;/span&gt;~56%&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\uparrow\)&lt;/span&gt;~167%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;Low construction&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\uparrow\)&lt;/span&gt;~4%&lt;/td&gt;
&lt;td&gt;&lt;span class=&#34;math inline&#34;&gt;\(\uparrow\)&lt;/span&gt;~145%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-pros-and-cons-of-correlation&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The Pros and Cons of Correlation&lt;/h3&gt;
&lt;p&gt;Pros:
- Nature gives you correlations for free.
- In principle, everyone can agree on the facts.&lt;/p&gt;
&lt;p&gt;Cons:
- Correlations are not very helpful.
- They show what has happened, but not why.
- For many things, we care about why.&lt;/p&gt;
&lt;div id=&#34;why-a-correlation-exists-between-x-and-y&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Why a Correlation Exists Between X and Y&lt;/h4&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow Y\)&lt;/span&gt;
X causes Y (causality)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X \leftarrow Y\)&lt;/span&gt;
Y causes X (reverse causality)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(Z \rightarrow X\)&lt;/span&gt;; &lt;span class=&#34;math inline&#34;&gt;\(Z \rightarrow Y\)&lt;/span&gt;
Z causes X and Y (common cause)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&#34;math inline&#34;&gt;\(X \rightarrow Y\)&lt;/span&gt;; &lt;span class=&#34;math inline&#34;&gt;\(Y \rightarrow X\)&lt;/span&gt;
X causes Y and Y causes X (simultaneous equations)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;uniting-social-science-and-computer-science&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Uniting Social Science and Computer Science&lt;/h4&gt;
&lt;p&gt;We will start in this course by examining situations where we do &lt;strong&gt;not&lt;/strong&gt; care about why something has happened, but instead we care about our ability to predict its occurrence from existing data.&lt;/p&gt;
&lt;p&gt;(But of course keep in back of mind that if you are making policy, you must care about why something happened).&lt;/p&gt;
&lt;p&gt;We will also borrow a few other ideas from CS:
- Anything is data
+ Satellite data
+ Unstructured text or audio
+ Facial expressions or vocal intonations
- Subtle improvements on existing techniques
- An eye towards practical implementability over ``cleanliness”&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;a-case-study-in-prediction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;A Case Study in Prediction&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; a firm wishes to predict user behavior based on previous purchases or interactions.&lt;/p&gt;
&lt;p&gt;Small margins &lt;span class=&#34;math inline&#34;&gt;\(\rightarrow\)&lt;/span&gt; huge payoffs. &lt;span class=&#34;math inline&#34;&gt;\(10\% \rightarrow\)&lt;/span&gt; $1 million.&lt;/p&gt;
&lt;p&gt;Not obvious to me why this was worth so much for Netflix (that’s an interesting research question). However, it’s quite obvious why this is true in financial markets.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;more-recent-examples-of-prediction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;More Recent Examples of Prediction&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Identify the risk factors for prostate cancer.&lt;/li&gt;
&lt;li&gt;Classify a tissue sample into one of several cancer classes, based on a gene expression profile.&lt;/li&gt;
&lt;li&gt;Classify a recorded phoneme based on a log-periodogram.&lt;/li&gt;
&lt;li&gt;Predict whether someone will have a heart attack on the basis of demographic, diet and clinical measurements.&lt;/li&gt;
&lt;li&gt;Customize an email spam detection system.&lt;/li&gt;
&lt;li&gt;Identify a hand-drawn object.&lt;/li&gt;
&lt;li&gt;Determine which oscillations of stellar luminosity are likely due to exoplanets.&lt;/li&gt;
&lt;li&gt;Establish the relationship between salary and demographic variables in population survey data.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;an-aside-nomenclature&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;An Aside: Nomenclature&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Machine learning&lt;/strong&gt; arose as a subfield of Artificial Intelligence.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Statistical learning&lt;/strong&gt; arose as a subfield of Statistics.&lt;/p&gt;
&lt;p&gt;There is much overlap; however, a few points of distinction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Machine learning has a greater emphasis on large scale applications and prediction accuracy.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Statistical learning emphasizes models and their interpretability, and precision and uncertainty.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;But the distinction has become more and more blurred, and there is a great deal of “cross-fertilization”.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Obviously true:&lt;/strong&gt; machine learning has the upper hand in marketing.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;learning-from-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Learning from Data&lt;/h3&gt;
&lt;p&gt;The following are the basic requirements for statistical learning:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A pattern exists.&lt;/li&gt;
&lt;li&gt;This pattern is not easily expressed in a closed mathematical form.&lt;/li&gt;
&lt;li&gt;You have data.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;ALERT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The course content below should be considered a prerequisite for success. For those concerned about basics of &lt;code&gt;R&lt;/code&gt;, you absolutely must read this content and attempt the coding exercises. If you struggle to follow the content, please contact the professor or TA.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;r-basics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;code&gt;R&lt;/code&gt; basics&lt;/h1&gt;
&lt;p&gt;In this class, we will be using &lt;code&gt;R&lt;/code&gt; software environment for all our analyses. You will learn &lt;code&gt;R&lt;/code&gt; and data analysis techniques simultaneously. To follow along you will therefore need access to &lt;code&gt;R&lt;/code&gt;. We also recommend the use of an &lt;em&gt;integrated development environment&lt;/em&gt; (IDE), such as RStudio, to save your work.
Note that it is common for a course or workshop to offer access to an &lt;code&gt;R&lt;/code&gt; environment and an IDE through your web browser, as done by RStudio cloud&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. If you have access to such a resource, you don’t need to install &lt;code&gt;R&lt;/code&gt; and RStudio. However, if you intend on becoming a practicing data analyst, we highly recommend installing these tools on your computer&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;. This is not hard.&lt;/p&gt;
&lt;p&gt;Both &lt;code&gt;R&lt;/code&gt; and RStudio are free and available online.&lt;/p&gt;
&lt;div id=&#34;case-study-us-homicides-by-firearm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Case study: US homicides by firearm&lt;/h2&gt;
&lt;p&gt;Imagine you live in Europe (if only!) and are offered a job in a US company with many locations in every state. It is a great job, but headlines such as &lt;strong&gt;US Gun Homicide Rate Higher Than Other Developed Countries&lt;/strong&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt; have you worried. Fox News runs a scary looking graphic, and charts like the one below only add to that concern:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/01-content_files/figure-html/murder-rate-example-1-1.png&#34; width=&#34;70%&#34; /&gt;&lt;/p&gt;
&lt;!--(Source:
[Ma’ayan Rosenzweigh/ABC News](https://abcnews.go.com/blogs/headlines/2012/12/us-gun-ownership-homicide-rate-higher-than-other-developed-countries/), Data from UNODC Homicide Statistics) --&gt;
&lt;p&gt;Or even worse, this version from &lt;a href=&#34;https://everytownresearch.org&#34;&gt;everytown.org&lt;/a&gt;:
&lt;img src=&#34;https://ssc442.netlify.app/content/01-content_files/figure-html/murder-rate-example-2-1.png&#34; width=&#34;70%&#34; /&gt;
&lt;!--(Source  [everytown.org](https://everytownresearch.org))--&gt;&lt;/p&gt;
&lt;p&gt;But then you remember that (1) this is a hypothetical exercise; (2) you’ll take literally any job at this point; and (3) Geographic diversity matters – the United States is a large and diverse country with 50 very different states (plus the District of Columbia and some lovely territories).&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please
## use `guide = &amp;quot;none&amp;quot;` instead.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/content/01-content_files/figure-html/us-murders-by-state-map-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;California, for example, has a larger population than Canada, and 20 US states have populations larger than that of Norway. In some respects, the variability across states in the US is akin to the variability across countries in Europe. Furthermore, although not included in the charts above, the murder rates in Lithuania, Ukraine, and Russia are higher than 4 per 100,000. So perhaps the news reports that worried you are too superficial.&lt;/p&gt;
&lt;p&gt;This is a relatively simple and straightforward problem in social science: you have options of where to live, and want to determine the safety of the various states. Your “research” is clearly policy-relevant: you will eventually have to live somewhere. We will begin to tackle the problem by examining data related to gun homicides in the US during 2010 using &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Before we get started with our example, we need to cover logistics as well as some of the very basic building blocks that are required to gain more advanced &lt;code&gt;R&lt;/code&gt; skills. Ideally, this is a refresher. However, we are aware that your preparation in previously courses varies greatly from student to student. Moreover, we want you to be aware that the usefulness of some of these early building blocks may not be immediately obvious. Later in the class you will appreciate having these skills. Mastery will be rewarded both in this class and (of course) in life.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-very-basics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The (very) basics&lt;/h2&gt;
&lt;p&gt;Before we get started with the motivating dataset, we need to cover the very basics of &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;div id=&#34;objects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Objects&lt;/h3&gt;
&lt;p&gt;Suppose a relatively math unsavvy student asks us for help solving several quadratic equations of the form &lt;span class=&#34;math inline&#34;&gt;\(ax^2+bx+c = 0\)&lt;/span&gt;. You—a savvy student—recall that the quadratic formula gives us the solutions:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{-b - \sqrt{b^2 - 4ac}}{2a}\,\, \mbox{ and } \frac{-b + \sqrt{b^2 - 4ac}}{2a}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which of course depend on the values of &lt;span class=&#34;math inline&#34;&gt;\(a\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(b\)&lt;/span&gt;, and &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt;. That is, the quadratic equation represents a &lt;em&gt;function&lt;/em&gt; with three &lt;em&gt;arguments&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;One advantage of programming languages is that we can define variables and write expressions with these variables, similar to how we do so in math, but obtain a numeric solution. We will write out general code for the quadratic equation below, but if we are asked to solve &lt;span class=&#34;math inline&#34;&gt;\(x^2 + x -1 = 0\)&lt;/span&gt;, then we define:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 1
b &amp;lt;- 1
c &amp;lt;- -1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which stores the values for later use. We use &lt;code&gt;&amp;lt;-&lt;/code&gt; to assign values to the variables.&lt;/p&gt;
&lt;p&gt;We can also assign values using &lt;code&gt;=&lt;/code&gt; instead of &lt;code&gt;&amp;lt;-&lt;/code&gt;, but we recommend against using &lt;code&gt;=&lt;/code&gt; to avoid confusion.&lt;a href=&#34;#fn5&#34; class=&#34;footnote-ref&#34; id=&#34;fnref5&#34;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Copy and paste the code above into your console to define the three variables. Note that &lt;code&gt;R&lt;/code&gt; does not print anything when we make this assignment. This means the objects were defined successfully. Had you made a mistake, you would have received an error message. Throughout these written notes, you’ll have the most success if you continue to copy code into your own console.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To see the value stored in a variable, we simply ask &lt;code&gt;R&lt;/code&gt; to evaluate &lt;code&gt;a&lt;/code&gt; and it shows the stored value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A more explicit way to ask &lt;code&gt;R&lt;/code&gt; to show us the value stored in &lt;code&gt;a&lt;/code&gt; is using &lt;code&gt;print&lt;/code&gt; like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We use the term &lt;em&gt;object&lt;/em&gt; to describe stuff that is stored in &lt;code&gt;R&lt;/code&gt;. Variables are examples, but objects can also be more complicated entities such as functions, which are described later.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-workspace&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The workspace&lt;/h3&gt;
&lt;p&gt;As we define objects in the console, we are actually changing the &lt;em&gt;workspace&lt;/em&gt;. You can see all the variables saved in your workspace by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ls()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;a&amp;quot;       &amp;quot;b&amp;quot;       &amp;quot;c&amp;quot;       &amp;quot;dat&amp;quot;     &amp;quot;filter&amp;quot;  &amp;quot;murders&amp;quot; &amp;quot;select&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(Note that one of &lt;em&gt;my&lt;/em&gt; variables listed above comes from generating the graphs above). In RStudio, the &lt;em&gt;Environment&lt;/em&gt; tab shows the values:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://ssc442.netlify.app/img/rstudio-environment.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We should see &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, and &lt;code&gt;c&lt;/code&gt;. If you try to recover the value of a variable that is not in your workspace, you receive an error. For example, if you type &lt;code&gt;x&lt;/code&gt; you will receive the following message: &lt;code&gt;Error: object &#39;x&#39; not found&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now since these values are saved in variables, to obtain a solution to our equation, we use the quadratic formula:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(-b + sqrt(b^2 - 4*a*c) ) / ( 2*a )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.618034&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;(-b - sqrt(b^2 - 4*a*c) ) / ( 2*a )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -1.618034&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;functions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Functions&lt;/h3&gt;
&lt;p&gt;Once you define variables, the data analysis process can usually be described as a series of &lt;em&gt;functions&lt;/em&gt; applied to the data. &lt;code&gt;R&lt;/code&gt; includes several zillion predefined functions and most of the analysis pipelines we construct make extensive use of the built-in functions. But &lt;code&gt;R&lt;/code&gt;’s power comes from its scalability. We have access to (nearly) infinite functions via &lt;code&gt;install.packages&lt;/code&gt; and &lt;code&gt;library&lt;/code&gt;. As we go through the course, we will carefully note new functions we bring to each problem. For now, though, we will stick to the basics.&lt;/p&gt;
&lt;p&gt;Note that you’ve used a function already: you used the function &lt;code&gt;sqrt&lt;/code&gt; to solve the quadratic equation above. These functions do not appear in the workspace because you did not define them, but they are available for immediate use.&lt;/p&gt;
&lt;p&gt;In general, we need to use parentheses to evaluate a function. If you type &lt;code&gt;ls&lt;/code&gt;, the function is not evaluated and instead &lt;code&gt;R&lt;/code&gt; shows you the code that defines the function. If you type &lt;code&gt;ls()&lt;/code&gt; the function is evaluated and, as seen above, we see objects in the workspace.&lt;/p&gt;
&lt;p&gt;Unlike &lt;code&gt;ls&lt;/code&gt;, most functions require one or more &lt;em&gt;arguments&lt;/em&gt;. Below is an example of how we assign an object to the argument of the function &lt;code&gt;log&lt;/code&gt;. Remember that we earlier defined &lt;code&gt;a&lt;/code&gt; to be 1:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.079442&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can find out what the function expects and what it does by reviewing the very useful manuals included in &lt;code&gt;R&lt;/code&gt;. You can get help by using the &lt;code&gt;help&lt;/code&gt; function like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;help(&amp;quot;log&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For most functions, we can also use this shorthand:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?log&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The help page will show you what arguments the function is expecting. For example, &lt;code&gt;log&lt;/code&gt; needs &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;base&lt;/code&gt; to run. However, some arguments are required and others are optional. You can determine which arguments are optional by noting in the help document that a default value is assigned with &lt;code&gt;=&lt;/code&gt;. Defining these is optional.&lt;a href=&#34;#fn6&#34; class=&#34;footnote-ref&#34; id=&#34;fnref6&#34;&gt;&lt;sup&gt;6&lt;/sup&gt;&lt;/a&gt; For example, the base of the function &lt;code&gt;log&lt;/code&gt; defaults to &lt;code&gt;base = exp(1)&lt;/code&gt;—that is, &lt;code&gt;log&lt;/code&gt; evaluates the natural log by default.&lt;/p&gt;
&lt;p&gt;If you want a quick look at the arguments without opening the help system, you can type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;args(log)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## function (x, base = exp(1)) 
## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can change the default values by simply assigning another object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(8, base = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we have not been specifying the argument &lt;code&gt;x&lt;/code&gt; as such:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(x = 8, base = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The above code works, but we can save ourselves some typing: if no argument name is used, &lt;code&gt;R&lt;/code&gt; assumes you are entering arguments in the order shown in the help file or by &lt;code&gt;args&lt;/code&gt;. So by not using the names, it assumes the arguments are &lt;code&gt;x&lt;/code&gt; followed by &lt;code&gt;base&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(8,2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If using the arguments’ names, then we can include them in whatever order we want:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;log(base = 2, x = 8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To specify arguments, we must use &lt;code&gt;=&lt;/code&gt;, and cannot use &lt;code&gt;&amp;lt;-&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;There are some exceptions to the rule that functions need the parentheses to be evaluated. Among these, the most commonly used are the arithmetic and relational operators. For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;2 ^ 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can see the arithmetic operators by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;help(&amp;quot;+&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?&amp;quot;+&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the relational operators by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;help(&amp;quot;&amp;gt;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?&amp;quot;&amp;gt;&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;other-prebuilt-objects&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Other prebuilt objects&lt;/h3&gt;
&lt;p&gt;There are several datasets that are included for users to practice and test out functions. You can see all the available datasets by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This shows you the object name for these datasets. These datasets are objects that can be used by simply typing the name. For example, if you type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;co2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;R&lt;/code&gt; will show you Mauna Loa atmospheric &lt;span class=&#34;math inline&#34;&gt;\(CO^2\)&lt;/span&gt; concentration data.&lt;/p&gt;
&lt;p&gt;Other prebuilt objects are mathematical quantities, such as the constant &lt;span class=&#34;math inline&#34;&gt;\(\pi\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\infty\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pi&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.141593&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;Inf+1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] Inf&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;variable-names&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Variable names&lt;/h3&gt;
&lt;p&gt;We have used the letters &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;b&lt;/code&gt;, and &lt;code&gt;c&lt;/code&gt; as variable names, but variable names can be almost anything. Some basic rules in &lt;code&gt;R&lt;/code&gt; are that variable names have to start with a letter, can’t contain spaces, and should not be variables that are predefined in &lt;code&gt;R&lt;/code&gt;. For example, don’t name one of your variables &lt;code&gt;install.packages&lt;/code&gt; by typing something like &lt;code&gt;install.packages &amp;lt;- 2&lt;/code&gt;. Usually, &lt;code&gt;R&lt;/code&gt; is smart enough to prevent you from doing such nonsense, but it’s important to develop good habits.&lt;/p&gt;
&lt;p&gt;A nice convention to follow is to use meaningful words that describe what is stored, use only lower case, and use underscores as a substitute for spaces. For the quadratic equations, we could use something like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;solution_1 &amp;lt;- (-b + sqrt(b^2 - 4*a*c)) / (2*a)
solution_2 &amp;lt;- (-b - sqrt(b^2 - 4*a*c)) / (2*a)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more advice, we highly recommend studying (Hadley Wickham’s style guide)[&lt;a href=&#34;http://adv-r.had.co.nz/Style.html&#34; class=&#34;uri&#34;&gt;http://adv-r.had.co.nz/Style.html&lt;/a&gt;].&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;saving-your-workspace&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Saving your workspace&lt;/h3&gt;
&lt;p&gt;Values remain in the workspace until you end your session or erase them with the function &lt;code&gt;rm&lt;/code&gt;. But workspaces also can be saved for later use. In fact, when you quit R, the program asks you if you want to save your workspace. If you do save it, the next time you start R, the program will restore the workspace.&lt;/p&gt;
&lt;p&gt;We actually recommend against saving the workspace this way because, as you start working on different projects, it will become harder to keep track of what is saved. Instead, we recommend you assign the workspace a specific name. You can do this by using the function &lt;code&gt;save&lt;/code&gt; or &lt;code&gt;save.image&lt;/code&gt;. To load, use the function &lt;code&gt;load&lt;/code&gt;. When saving a workspace, we recommend the suffix &lt;code&gt;rda&lt;/code&gt; or &lt;code&gt;RData&lt;/code&gt;. In RStudio, you can also do this by navigating to the &lt;em&gt;Session&lt;/em&gt; tab and choosing &lt;em&gt;Save Workspace as&lt;/em&gt;. You can later load it using the &lt;em&gt;Load Workspace&lt;/em&gt; options in the same tab.
You can read the help pages on &lt;code&gt;save&lt;/code&gt;, &lt;code&gt;save.image&lt;/code&gt;, and &lt;code&gt;load&lt;/code&gt; to learn more.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;motivating-scripts&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Motivating scripts&lt;/h3&gt;
&lt;p&gt;To solve another equation such as &lt;span class=&#34;math inline&#34;&gt;\(3x^2 + 2x -1\)&lt;/span&gt;, we can copy and paste the code above and then redefine the variables and recompute the solution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 3
b &amp;lt;- 2
c &amp;lt;- -1
(-b + sqrt(b^2 - 4*a*c)) / (2*a)
(-b - sqrt(b^2 - 4*a*c)) / (2*a)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By creating and saving a script with the code above, we would not need to retype everything each time and, instead, simply change the variable names. Try writing the script above into an editor and notice how easy it is to change the variables and receive an answer.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;commenting-your-code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Commenting your code&lt;/h3&gt;
&lt;p&gt;If a line of &lt;code&gt;R&lt;/code&gt; code starts with the symbol &lt;code&gt;#&lt;/code&gt;, it is not evaluated. We can use this to write reminders of why we wrote particular code. For example, in the script above we could add:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Code to compute solution to quadratic equation of the form ax^2 + bx + c
## define the variables
a &amp;lt;- 3
b &amp;lt;- 2
c &amp;lt;- -1

## now compute the solution
(-b + sqrt(b^2 - 4*a*c)) / (2*a)
(-b - sqrt(b^2 - 4*a*c)) / (2*a)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What is the sum of the first 100 positive integers? The formula for the sum of integers &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; through &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(n(n+1)/2\)&lt;/span&gt;. Define &lt;span class=&#34;math inline&#34;&gt;\(n=100\)&lt;/span&gt; and then use &lt;code&gt;R&lt;/code&gt; to compute the sum of &lt;span class=&#34;math inline&#34;&gt;\(1\)&lt;/span&gt; through &lt;span class=&#34;math inline&#34;&gt;\(100\)&lt;/span&gt; using the formula. What is the sum?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now use the same formula to compute the sum of the integers from 1 through 1,000.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Look at the result of typing the following code into R:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1000
x &amp;lt;- seq(1, n)
sum(x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Based on the result, what do you think the functions &lt;code&gt;seq&lt;/code&gt; and &lt;code&gt;sum&lt;/code&gt; do? You can use &lt;code&gt;help&lt;/code&gt;.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;sum&lt;/code&gt; creates a list of numbers and &lt;code&gt;seq&lt;/code&gt; adds them up.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;seq&lt;/code&gt; creates a list of numbers and &lt;code&gt;sum&lt;/code&gt; adds them up.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;seq&lt;/code&gt; creates a random list and &lt;code&gt;sum&lt;/code&gt; computes the sum of 1 through 1,000.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sum&lt;/code&gt; always returns the same number.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;In math and programming, we say that we evaluate a function when we replace the argument with a given number. So if we type &lt;code&gt;sqrt(4)&lt;/code&gt;, we evaluate the &lt;code&gt;sqrt&lt;/code&gt; function. In R, you can evaluate a function inside another function. The evaluations happen from the inside out. Use one line of code to compute the log, in base 10, of the square root of 100.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Which of the following will always return the numeric value stored in &lt;code&gt;x&lt;/code&gt;? You can try out examples and use the help system if you want.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;log(10^x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log10(x^10)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;log(exp(x))&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;exp(log(x, base = 2))&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-types&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data types&lt;/h2&gt;
&lt;p&gt;Variables in &lt;code&gt;R&lt;/code&gt; can be of different types. For example, we need to distinguish numbers from character strings and tables from simple lists of numbers. The function &lt;code&gt;class&lt;/code&gt; helps us determine what type of object we have:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 2
class(a)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To work efficiently in R, it is important to learn the different types of variables and what we can do with these.&lt;/p&gt;
&lt;div id=&#34;data-frames&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data frames&lt;/h3&gt;
&lt;p&gt;Up to now, the variables we have defined are just one number. This is not very useful for storing data. The most common way of storing a dataset in &lt;code&gt;R&lt;/code&gt; is in a &lt;em&gt;data frame&lt;/em&gt;. Conceptually, we can think of a data frame as a table with rows representing observations and the different variables reported for each observation defining the columns. Data frames are particularly useful for datasets because we can combine different data types into one object.&lt;/p&gt;
&lt;p&gt;A large proportion of data analysis challenges start with data stored in a data frame. For example, we stored the data for our motivating example in a data frame. You can access this dataset by loading the &lt;strong&gt;dslabs&lt;/strong&gt; library and loading the &lt;code&gt;murders&lt;/code&gt; dataset using the &lt;code&gt;data&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To see that this is in fact a data frame, we type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;examining-an-object&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Examining an object&lt;/h3&gt;
&lt;p&gt;The function &lt;code&gt;str&lt;/code&gt; is useful for finding out more about the structure of an object:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    51 obs. of  5 variables:
## $ state : chr &amp;quot;Alabama&amp;quot; &amp;quot;Alaska&amp;quot; &amp;quot;Arizona&amp;quot; &amp;quot;Arkansas&amp;quot; ...
## $ abb : chr &amp;quot;AL&amp;quot; &amp;quot;AK&amp;quot; &amp;quot;AZ&amp;quot; &amp;quot;AR&amp;quot; ...
## $ region : Factor w/ 4 levels &amp;quot;Northeast&amp;quot;,&amp;quot;South&amp;quot;,..: 2 4 4 2 4 4 1 2 2 2 ...
## $ population: num 4779736 710231 6392017 2915918 37253956 ...
## $ total : num 135 19 232 93 1257 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This tells us much more about the object. We see that the table has 51 rows (50 states plus DC) and five variables. We can show the first six lines using the function &lt;code&gt;head&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state abb region population total
## 1    Alabama  AL  South    4779736   135
## 2     Alaska  AK   West     710231    19
## 3    Arizona  AZ   West    6392017   232
## 4   Arkansas  AR  South    2915918    93
## 5 California  CA   West   37253956  1257
## 6   Colorado  CO   West    5029196    65&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this dataset, each state is considered an observation and five variables are reported for each state.&lt;/p&gt;
&lt;p&gt;Before we go any further in answering our original question about different states, let’s learn more about the components of this object.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-accessor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The accessor: &lt;code&gt;$&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;For our analysis, we will need to access the different variables represented by columns included in this data frame. To do this, we use the accessor operator &lt;code&gt;$&lt;/code&gt; in the following way:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders$population&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  4779736   710231  6392017  2915918 37253956  5029196  3574097   897934
##  [9]   601723 19687653  9920000  1360301  1567582 12830632  6483802  3046355
## [17]  2853118  4339367  4533372  1328361  5773552  6547629  9883640  5303925
## [25]  2967297  5988927   989415  1826341  2700551  1316470  8791894  2059179
## [33] 19378102  9535483   672591 11536504  3751351  3831074 12702379  1052567
## [41]  4625364   814180  6346105 25145561  2763885   625741  8001024  6724540
## [49]  1852994  5686986   563626&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But how did we know to use &lt;code&gt;population&lt;/code&gt;? Previously, by applying the function &lt;code&gt;str&lt;/code&gt; to the object &lt;code&gt;murders&lt;/code&gt;, we revealed the names for each of the five variables stored in this table. We can quickly access the variable names using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;state&amp;quot;      &amp;quot;abb&amp;quot;        &amp;quot;region&amp;quot;     &amp;quot;population&amp;quot; &amp;quot;total&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is important to know that the order of the entries in &lt;code&gt;murders$population&lt;/code&gt; preserves the order of the rows in our data table. This will later permit us to manipulate one variable based on the results of another. For example, we will be able to order the state names by the number of murders.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: &lt;code&gt;R&lt;/code&gt; comes with a very nice auto-complete functionality that saves us the trouble of typing out all the names. Try typing &lt;code&gt;murders$p&lt;/code&gt; then hitting the &lt;kbd&gt;tab&lt;/kbd&gt; key on your keyboard. This functionality and many other useful auto-complete features are available when working in RStudio.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vectors-numerics-characters-and-logical&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Vectors: numerics, characters, and logical&lt;/h3&gt;
&lt;p&gt;The object &lt;code&gt;murders$population&lt;/code&gt; is not one number but several. We call these types of objects &lt;em&gt;vectors&lt;/em&gt;. A single number is technically a vector of length 1, but in general we use the term vectors to refer to objects with several entries. The function &lt;code&gt;length&lt;/code&gt; tells you how many entries are in the vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pop &amp;lt;- murders$population
length(pop)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 51&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This particular vector is &lt;em&gt;numeric&lt;/em&gt; since population sizes are numbers:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(pop)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a numeric vector, every entry must be a number.&lt;/p&gt;
&lt;p&gt;To store character strings, vectors can also be of class &lt;em&gt;character&lt;/em&gt;. For example, the state names are characters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(murders$state)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with numeric vectors, all entries in a character vector need to be a character.&lt;/p&gt;
&lt;p&gt;Another important type of vectors are &lt;em&gt;logical vectors&lt;/em&gt;. These must be either &lt;code&gt;TRUE&lt;/code&gt; or &lt;code&gt;FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z &amp;lt;- 3 == 2
z&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;logical&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here the &lt;code&gt;==&lt;/code&gt; is a relational operator asking if 3 is equal to 2. In &lt;code&gt;R&lt;/code&gt;, if you just use one &lt;code&gt;=&lt;/code&gt;, you actually assign a variable, but if you use two &lt;code&gt;==&lt;/code&gt; you test for equality. Yet another reason to avoid assigning via &lt;code&gt;=&lt;/code&gt;… it can get confusing and typos can really mess things up.&lt;/p&gt;
&lt;p&gt;You can see the other &lt;em&gt;relational operators&lt;/em&gt; by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;?Comparison&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In future sections, you will see how useful relational operators can be.&lt;/p&gt;
&lt;p&gt;We discuss more important features of vectors after the next set of exercises.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: Mathematically, the values in &lt;code&gt;pop&lt;/code&gt; are integers and there is an integer class in &lt;code&gt;R&lt;/code&gt;. However, by default, numbers are assigned class numeric even when they are round integers. For example, &lt;code&gt;class(1)&lt;/code&gt; returns numeric. You can turn them into class integer with the &lt;code&gt;as.integer()&lt;/code&gt; function or by adding an &lt;code&gt;L&lt;/code&gt; like this: &lt;code&gt;1L&lt;/code&gt;. Note the class by typing: &lt;code&gt;class(1L)&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;factors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Factors&lt;/h3&gt;
&lt;p&gt;In the &lt;code&gt;murders&lt;/code&gt; dataset, we might expect the region to also be a character vector. However, it is not:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(murders$region)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;factor&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is a &lt;em&gt;factor&lt;/em&gt;. Factors are useful for storing categorical data. We can see that there are only 4 regions by using the &lt;code&gt;levels&lt;/code&gt; function:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;levels(murders$region)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Northeast&amp;quot;     &amp;quot;South&amp;quot;         &amp;quot;North Central&amp;quot; &amp;quot;West&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the background, &lt;code&gt;R&lt;/code&gt; stores these &lt;em&gt;levels&lt;/em&gt; as integers and keeps a map to keep track of the labels. This is more memory efficient than storing all the characters. It is also useful for computational reasons we’ll explore later.&lt;/p&gt;
&lt;p&gt;Note that the levels have an order that is different from the order of appearance in the factor object. The default in &lt;code&gt;R&lt;/code&gt; is for the levels to follow alphabetical order. However, often we want the levels to follow a different order. You can specify an order through the &lt;code&gt;levels&lt;/code&gt; argument when creating the factor with the &lt;code&gt;factor&lt;/code&gt; function. For example, in the murders dataset regions are ordered from east to west. The function &lt;code&gt;reorder&lt;/code&gt; lets us change the order of the levels of a factor variable based on a summary computed on a numeric vector. We will demonstrate this with a simple example, and will see more advanced ones in the Data Visualization part of the book.&lt;/p&gt;
&lt;p&gt;Suppose we want the levels of the region by the total number of murders rather than alphabetical order. If there are values associated with each level, we can use the &lt;code&gt;reorder&lt;/code&gt; and specify a data summary to determine the order. The following code takes the sum of the total murders in each region, and reorders the factor following these sums.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;region &amp;lt;- murders$region
value &amp;lt;- murders$total
region &amp;lt;- reorder(region, value, FUN = sum)
levels(region)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Northeast&amp;quot;     &amp;quot;North Central&amp;quot; &amp;quot;West&amp;quot;          &amp;quot;South&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new order is in agreement with the fact that the Northeast has the least murders and the South has the most.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Warning&lt;/strong&gt;: Factors can be a source of confusion since sometimes they behave like characters and sometimes they do not. As a result, confusing factors and characters are a common source of bugs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lists&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Lists&lt;/h3&gt;
&lt;p&gt;Data frames are a special case of &lt;em&gt;lists&lt;/em&gt;. We will cover lists in more detail later, but know that they are useful because you can store any combination of different types. Below is an example of a list we created for you:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;record&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## $name
## [1] &amp;quot;John Doe&amp;quot;
## 
## $student_id
## [1] 1234
## 
## $grades
## [1] 95 82 91 97 93
## 
## $final_grade
## [1] &amp;quot;A&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(record)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As with data frames, you can extract the components of a list with the accessor &lt;code&gt;$&lt;/code&gt;. In fact, data frames are a type of list.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;record$student_id&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1234&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also use double square brackets (&lt;code&gt;[[&lt;/code&gt;) like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;record[[&amp;quot;student_id&amp;quot;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1234&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should get used to the fact that in &lt;code&gt;R&lt;/code&gt; there are often several ways to do the same thing. such as accessing entries.&lt;a href=&#34;#fn7&#34; class=&#34;footnote-ref&#34; id=&#34;fnref7&#34;&gt;&lt;sup&gt;7&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You might also encounter lists without variable names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;record2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [[1]]
## [1] &amp;quot;John Doe&amp;quot;
## 
## [[2]]
## [1] 1234&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If a list does not have names, you cannot extract the elements with &lt;code&gt;$&lt;/code&gt;, but you can still use the brackets method and instead of providing the variable name, you provide the list index, like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;record2[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;John Doe&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We won’t be using lists until later, but you might encounter one in your own exploration of &lt;code&gt;R&lt;/code&gt;. For this reason, we show you some basics here.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;matrices&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Matrices&lt;/h3&gt;
&lt;p&gt;Matrices are another type of object that are common in &lt;code&gt;R&lt;/code&gt;. Matrices are similar to data frames in that they are two-dimensional: they have rows and columns. However, like numeric, character and logical vectors, entries in matrices have to be all the same type. For this reason data frames are much more useful for storing data, since we can have characters, factors, and numbers in them.&lt;/p&gt;
&lt;p&gt;Yet matrices have a major advantage over data frames: we can perform matrix algebra operations, a powerful type of mathematical technique. We do not describe these operations in this class, but much of what happens in the background when you perform a data analysis involves matrices. We describe them briefly here since some of the functions we will learn return matrices.&lt;/p&gt;
&lt;p&gt;We can define a matrix using the &lt;code&gt;matrix&lt;/code&gt; function. We need to specify the number of rows and columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat &amp;lt;- matrix(1:12, 4, 3)
mat&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2] [,3]
## [1,]    1    5    9
## [2,]    2    6   10
## [3,]    3    7   11
## [4,]    4    8   12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can access specific entries in a matrix using square brackets (&lt;code&gt;[&lt;/code&gt;). If you want the second row, third column, you use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[2, 3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you want the entire second row, you leave the column spot empty:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[2, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  2  6 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that this returns a vector, not a matrix.&lt;/p&gt;
&lt;p&gt;Similarly, if you want the entire third column, you leave the row spot empty:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[, 3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  9 10 11 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is also a vector, not a matrix.&lt;/p&gt;
&lt;p&gt;You can access more than one column or more than one row if you like. This will give you a new matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[, 2:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    5    9
## [2,]    6   10
## [3,]    7   11
## [4,]    8   12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can subset both rows and columns:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mat[1:2, 2:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      [,1] [,2]
## [1,]    5    9
## [2,]    6   10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can convert matrices into data frames using the function &lt;code&gt;as.data.frame&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.data.frame(mat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   V1 V2 V3
## 1  1  5  9
## 2  2  6 10
## 3  3  7 11
## 4  4  8 12&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can also use single square brackets (&lt;code&gt;[&lt;/code&gt;) to access rows and columns of a data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;murders&amp;quot;)
murders[25, 1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Mississippi&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders[2:3, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     state abb region population total
## 2  Alaska  AK   West     710231    19
## 3 Arizona  AZ   West    6392017   232&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Load the US murders dataset.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use the function &lt;code&gt;str&lt;/code&gt; to examine the structure of the &lt;code&gt;murders&lt;/code&gt; object. Which of the following best describes the variables represented in this data frame?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;The 51 states.&lt;/li&gt;
&lt;li&gt;The murder rates for all 50 states and DC.&lt;/li&gt;
&lt;li&gt;The state name, the abbreviation of the state name, the state’s region, and the state’s population and total number of murders for 2010.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;str&lt;/code&gt; shows no relevant information.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What are the column names used by the data frame for these five variables?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the accessor &lt;code&gt;$&lt;/code&gt; to extract the state abbreviations and assign them to the object &lt;code&gt;a&lt;/code&gt;. What is the class of this object?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now use the square brackets to extract the state abbreviations and assign them to the object &lt;code&gt;b&lt;/code&gt;. Use the &lt;code&gt;identical&lt;/code&gt; function to determine if &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; are the same.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We saw that the &lt;code&gt;region&lt;/code&gt; column stores a factor. You can corroborate this by typing:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(murders$region)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With one line of code, use the function &lt;code&gt;levels&lt;/code&gt; and &lt;code&gt;length&lt;/code&gt; to determine the number of regions defined by this dataset.&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The function &lt;code&gt;table&lt;/code&gt; takes a vector and returns the frequency of each element. You can quickly see how many states are in each region by applying this function. Use this function in one line of code to create a table of states per region.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;vectors&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vectors&lt;/h2&gt;
&lt;p&gt;In R, the most basic objects available to store data are &lt;em&gt;vectors&lt;/em&gt;. As we have seen, complex datasets can usually be broken down into components that are vectors. For example, in a data frame, each column is a vector. Here we learn more about this important class.&lt;/p&gt;
&lt;div id=&#34;creating-vectors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating vectors&lt;/h3&gt;
&lt;p&gt;We can create vectors using the function &lt;code&gt;c&lt;/code&gt;, which stands for &lt;em&gt;concatenate&lt;/em&gt;. We use &lt;code&gt;c&lt;/code&gt; to concatenate entries in the following way:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes &amp;lt;- c(380, 124, 818)
codes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 380 124 818&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also create character vectors. We use the quotes to denote that the entries are characters rather than variable names.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country &amp;lt;- c(&amp;quot;italy&amp;quot;, &amp;quot;canada&amp;quot;, &amp;quot;egypt&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In &lt;code&gt;R&lt;/code&gt; you can also use single quotes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country &amp;lt;- c(&amp;#39;italy&amp;#39;, &amp;#39;canada&amp;#39;, &amp;#39;egypt&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But be careful not to confuse the single quote ’ with the &lt;em&gt;back quote&lt;/em&gt;, which shares a keyboard key with &lt;kbd&gt;~&lt;/kbd&gt;.&lt;/p&gt;
&lt;p&gt;By now you should know that if you type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;country &amp;lt;- c(italy, canada, egypt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you receive an error because the variables &lt;code&gt;italy&lt;/code&gt;, &lt;code&gt;canada&lt;/code&gt;, and &lt;code&gt;egypt&lt;/code&gt; are not defined. If we do not use the quotes, &lt;code&gt;R&lt;/code&gt; looks for variables with those names and returns an error.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;names&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Names&lt;/h3&gt;
&lt;p&gt;Sometimes it is useful to name the entries of a vector. For example, when defining a vector of country codes, we can use the names to connect the two:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes &amp;lt;- c(italy = 380, canada = 124, egypt = 818)
codes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  italy canada  egypt 
##    380    124    818&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The object &lt;code&gt;codes&lt;/code&gt; continues to be a numeric vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(codes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;but with names:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(codes)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;italy&amp;quot;  &amp;quot;canada&amp;quot; &amp;quot;egypt&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the use of strings without quotes looks confusing, know that you can use the quotes as well:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes &amp;lt;- c(&amp;quot;italy&amp;quot; = 380, &amp;quot;canada&amp;quot; = 124, &amp;quot;egypt&amp;quot; = 818)
codes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  italy canada  egypt 
##    380    124    818&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There is no difference between this function call and the previous one. This is one of the many ways in which &lt;code&gt;R&lt;/code&gt; is quirky compared to other languages.&lt;/p&gt;
&lt;p&gt;We can also assign names using the &lt;code&gt;names&lt;/code&gt; functions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes &amp;lt;- c(380, 124, 818)
country &amp;lt;- c(&amp;quot;italy&amp;quot;,&amp;quot;canada&amp;quot;,&amp;quot;egypt&amp;quot;)
names(codes) &amp;lt;- country
codes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  italy canada  egypt 
##    380    124    818&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;sequences&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sequences&lt;/h3&gt;
&lt;p&gt;Another useful function for creating vectors generates sequences:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(1, 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first argument defines the start, and the second defines the end which is included. The default is to go up in increments of 1, but a third argument lets us tell it how much to jump by:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seq(1, 10, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 3 5 7 9&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want consecutive integers, we can use the following shorthand:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1:10&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  1  2  3  4  5  6  7  8  9 10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When we use these functions, &lt;code&gt;R&lt;/code&gt; produces integers, not numerics, because they are typically used to index something:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;integer&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, if we create a sequence including non-integers, the class changes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(seq(1, 10, 0.5))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;subsetting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Subsetting&lt;/h3&gt;
&lt;p&gt;We use square brackets to access specific elements of a vector. For the vector &lt;code&gt;codes&lt;/code&gt; we defined above, we can access the second element using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## canada 
##    124&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can get more than one entry by using a multi-entry vector as an index:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes[c(1,3)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## italy egypt 
##   380   818&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sequences defined above are particularly useful if we want to access, say, the first two elements:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes[1:2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  italy canada 
##    380    124&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If the elements have names, we can also access the entries using these names. Below are two examples.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes[&amp;quot;canada&amp;quot;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## canada 
##    124&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;codes[c(&amp;quot;egypt&amp;quot;,&amp;quot;italy&amp;quot;)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## egypt italy 
##   818   380&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;coercion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Coercion&lt;/h2&gt;
&lt;p&gt;In general, &lt;em&gt;coercion&lt;/em&gt; is an attempt by &lt;code&gt;R&lt;/code&gt; to be flexible with data types. When an entry does not match the expected, some of the prebuilt &lt;code&gt;R&lt;/code&gt; functions try to guess what was meant before throwing an error. This can also lead to confusion. Failing to understand &lt;em&gt;coercion&lt;/em&gt; can drive programmers crazy when attempting to code in &lt;code&gt;R&lt;/code&gt; since it behaves quite differently from most other languages in this regard. Let’s learn about it with some examples.&lt;/p&gt;
&lt;p&gt;We said that vectors must be all of the same type. So if we try to combine, say, numbers and characters, you might expect an error:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(1, &amp;quot;canada&amp;quot;, 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But we don’t get one, not even a warning! What happened? Look at &lt;code&gt;x&lt;/code&gt; and its class:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1&amp;quot;      &amp;quot;canada&amp;quot; &amp;quot;3&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;character&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R &lt;em&gt;coerced&lt;/em&gt; the data into characters. It guessed that because you put a character string in the vector, you meant the 1 and 3 to actually be character strings &lt;code&gt;&#34;1&#34;&lt;/code&gt; and “&lt;code&gt;3&lt;/code&gt;”. The fact that not even a warning is issued is an example of how coercion can cause many unnoticed errors in &lt;code&gt;R&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;R also offers functions to change from one type to another. For example, you can turn numbers into characters with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1:5
y &amp;lt;- as.character(x)
y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;1&amp;quot; &amp;quot;2&amp;quot; &amp;quot;3&amp;quot; &amp;quot;4&amp;quot; &amp;quot;5&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can turn it back with &lt;code&gt;as.numeric&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;as.numeric(y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2 3 4 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function is actually quite useful since datasets that include numbers as character strings are common.&lt;/p&gt;
&lt;div id=&#34;not-availables-na&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Not availables (NA)&lt;/h3&gt;
&lt;p&gt;This “topic” seems to be wholly unappreciated and it has been our experience that students often panic when encountering an &lt;code&gt;NA&lt;/code&gt;. This often happens when a function tries to coerce one type to another and encounters an impossible case. In such circumstances, &lt;code&gt;R&lt;/code&gt; usually gives us a warning and turns the entry into a special value called an &lt;code&gt;NA&lt;/code&gt; (for “not available”). For example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(&amp;quot;1&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;3&amp;quot;)
as.numeric(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: NAs introduced by coercion&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  1 NA  3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;R does not have any guesses for what number you want when you type &lt;code&gt;b&lt;/code&gt;, so it does not try.&lt;/p&gt;
&lt;p&gt;While coercion is a common case leading to &lt;code&gt;NA&lt;/code&gt;s, you’ll see them in nearly every real-world dataset. Most often, you will encounter the &lt;code&gt;NA&lt;/code&gt;s as a stand-in for missing data. Again, this a common problem in real-world datasets and you need to be aware that it will come up.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;sorting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Sorting&lt;/h2&gt;
&lt;p&gt;Now that we have mastered some basic &lt;code&gt;R&lt;/code&gt; knowledge (ha!), let’s try to gain some insights into the safety of different states in the context of gun murders.&lt;/p&gt;
&lt;div id=&#34;sort&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;sort&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Say we want to rank the states from least to most gun murders. The function &lt;code&gt;sort&lt;/code&gt; sorts a vector in increasing order. We can therefore see the largest number of gun murders by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)
sort(murders$total)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]    2    4    5    5    7    8   11   12   12   16   19   21   22   27   32
## [16]   36   38   53   63   65   67   84   93   93   97   97   99  111  116  118
## [31]  120  135  142  207  219  232  246  250  286  293  310  321  351  364  376
## [46]  413  457  517  669  805 1257&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, this does not give us information about which states have which murder totals. For example, we don’t know which state had 1257.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;order&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;order&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The function &lt;code&gt;order&lt;/code&gt; is closer to what we want. It takes a vector as input and returns the vector of indexes that sorts the input vector. This may sound confusing so let’s look at a simple example. We can create a vector and sort it:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(31, 4, 15, 92, 65)
sort(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  4 15 31 65 92&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rather than sort the input vector, the function &lt;code&gt;order&lt;/code&gt; returns the index that sorts input vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;index &amp;lt;- order(x)
x[index]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1]  4 15 31 65 92&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is the same output as that returned by &lt;code&gt;sort(x)&lt;/code&gt;. If we look at this index, we see why it works:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 31  4 15 92 65&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;order(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2 3 1 5 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second entry of &lt;code&gt;x&lt;/code&gt; is the smallest, so &lt;code&gt;order(x)&lt;/code&gt; starts with &lt;code&gt;2&lt;/code&gt;. The next smallest is the third entry, so the second entry is &lt;code&gt;3&lt;/code&gt; and so on.&lt;/p&gt;
&lt;p&gt;How does this help us order the states by murders? First, remember that the entries of vectors you access with &lt;code&gt;$&lt;/code&gt; follow the same order as the rows in the table. For example, these two vectors containing state names and abbreviations, respectively, are matched by their order:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders$state[1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Alabama&amp;quot;    &amp;quot;Alaska&amp;quot;     &amp;quot;Arizona&amp;quot;    &amp;quot;Arkansas&amp;quot;   &amp;quot;California&amp;quot;
## [6] &amp;quot;Colorado&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders$abb[1:6]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;AL&amp;quot; &amp;quot;AK&amp;quot; &amp;quot;AZ&amp;quot; &amp;quot;AR&amp;quot; &amp;quot;CA&amp;quot; &amp;quot;CO&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means we can order the state names by their total murders. We first obtain the index that orders the vectors according to murder totals and then index the state names vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- order(murders$total)
murders$abb[ind]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;VT&amp;quot; &amp;quot;ND&amp;quot; &amp;quot;NH&amp;quot; &amp;quot;WY&amp;quot; &amp;quot;HI&amp;quot; &amp;quot;SD&amp;quot; &amp;quot;ME&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;MT&amp;quot; &amp;quot;RI&amp;quot; &amp;quot;AK&amp;quot; &amp;quot;IA&amp;quot; &amp;quot;UT&amp;quot; &amp;quot;WV&amp;quot; &amp;quot;NE&amp;quot;
## [16] &amp;quot;OR&amp;quot; &amp;quot;DE&amp;quot; &amp;quot;MN&amp;quot; &amp;quot;KS&amp;quot; &amp;quot;CO&amp;quot; &amp;quot;NM&amp;quot; &amp;quot;NV&amp;quot; &amp;quot;AR&amp;quot; &amp;quot;WA&amp;quot; &amp;quot;CT&amp;quot; &amp;quot;WI&amp;quot; &amp;quot;DC&amp;quot; &amp;quot;OK&amp;quot; &amp;quot;KY&amp;quot; &amp;quot;MA&amp;quot;
## [31] &amp;quot;MS&amp;quot; &amp;quot;AL&amp;quot; &amp;quot;IN&amp;quot; &amp;quot;SC&amp;quot; &amp;quot;TN&amp;quot; &amp;quot;AZ&amp;quot; &amp;quot;NJ&amp;quot; &amp;quot;VA&amp;quot; &amp;quot;NC&amp;quot; &amp;quot;MD&amp;quot; &amp;quot;OH&amp;quot; &amp;quot;MO&amp;quot; &amp;quot;LA&amp;quot; &amp;quot;IL&amp;quot; &amp;quot;GA&amp;quot;
## [46] &amp;quot;MI&amp;quot; &amp;quot;PA&amp;quot; &amp;quot;NY&amp;quot; &amp;quot;FL&amp;quot; &amp;quot;TX&amp;quot; &amp;quot;CA&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;According to the above, California had the most murders.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;max-and-which.max&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;max&lt;/code&gt; and &lt;code&gt;which.max&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;If we are only interested in the entry with the largest value, we can use &lt;code&gt;max&lt;/code&gt; for the value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;max(murders$total)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1257&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and &lt;code&gt;which.max&lt;/code&gt; for the index of the largest value:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;i_max &amp;lt;- which.max(murders$total)
murders$state[i_max]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;California&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the minimum, we can use &lt;code&gt;min&lt;/code&gt; and &lt;code&gt;which.min&lt;/code&gt; in the same way.&lt;/p&gt;
&lt;p&gt;Does this mean California is the most dangerous state? In an upcoming section, we argue that we should be considering rates instead of totals. Before doing that, we introduce one last order-related function: &lt;code&gt;rank&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rank&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;rank&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Although not as frequently used as &lt;code&gt;order&lt;/code&gt; and &lt;code&gt;sort&lt;/code&gt;, the function &lt;code&gt;rank&lt;/code&gt; is also related to order and can be useful.
For any given vector it returns a vector with the rank of the first entry, second entry, etc., of the input vector. Here is a simple example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(31, 4, 15, 92, 65)
rank(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3 1 2 5 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To summarize, let’s look at the results of the three functions we have introduced:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
original
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
sort
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
order
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
rank
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
15
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
31
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
65
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
92
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;beware-of-recycling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Beware of recycling&lt;/h3&gt;
&lt;p&gt;Another common source of unnoticed errors in &lt;code&gt;R&lt;/code&gt; is the use of &lt;em&gt;recycling&lt;/em&gt;. We saw that vectors are added elementwise. So if the vectors don’t match in length, it is natural to assume that we should get an error. But we don’t. Notice what happens:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(1,2,3)
y &amp;lt;- c(10, 20, 30, 40, 50, 60, 70)
x+y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning in x + y: longer object length is not a multiple of shorter object
## length&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11 22 33 41 52 63 71&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We do get a warning, but no error. For the output, &lt;code&gt;R&lt;/code&gt; has recycled the numbers in &lt;code&gt;x&lt;/code&gt;. Notice the last digit of numbers in the output.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For these exercises we will use the US murders dataset. Make sure you load it prior to starting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(&amp;quot;murders&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Use the &lt;code&gt;$&lt;/code&gt; operator to access the population size data and store it as the object &lt;code&gt;pop&lt;/code&gt;. Then use the &lt;code&gt;sort&lt;/code&gt; function to redefine &lt;code&gt;pop&lt;/code&gt; so that it is sorted. Finally, use the &lt;code&gt;[&lt;/code&gt; operator to report the smallest population size.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now instead of the smallest population size, find the index of the entry with the smallest population size. Hint: use &lt;code&gt;order&lt;/code&gt; instead of &lt;code&gt;sort&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We can actually perform the same operation as in the previous exercise using the function &lt;code&gt;which.min&lt;/code&gt;. Write one line of code that does this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now we know how small the smallest state is and we know which row represents it. Which state is it? Define a variable &lt;code&gt;states&lt;/code&gt; to be the state names from the &lt;code&gt;murders&lt;/code&gt; data frame. Report the name of the state with the smallest population.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You can create a data frame using the &lt;code&gt;data.frame&lt;/code&gt; function. Here is a quick example:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp &amp;lt;- c(35, 88, 42, 84, 81, 30)
city &amp;lt;- c(&amp;quot;Beijing&amp;quot;, &amp;quot;Lagos&amp;quot;, &amp;quot;Paris&amp;quot;, &amp;quot;Rio de Janeiro&amp;quot;,
          &amp;quot;San Juan&amp;quot;, &amp;quot;Toronto&amp;quot;)
city_temps &amp;lt;- data.frame(name = city, temperature = temp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Use the &lt;code&gt;rank&lt;/code&gt; function to determine the population rank of each state from smallest population size to biggest. Save these ranks in an object called &lt;code&gt;ranks&lt;/code&gt;, then create a data frame with the state name and its rank. Call the data frame &lt;code&gt;my_df&lt;/code&gt;.&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Repeat the previous exercise, but this time order &lt;code&gt;my_df&lt;/code&gt; so that the states are ordered from least populous to most populous. Hint: create an object &lt;code&gt;ind&lt;/code&gt; that stores the indexes needed to order the population values. Then use the bracket operator &lt;code&gt;[&lt;/code&gt; to re-order each column in the data frame.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The &lt;code&gt;na_example&lt;/code&gt; vector represents a series of counts. You can quickly examine the object using:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(&amp;quot;na_example&amp;quot;)
str(na_example)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  int [1:1000] 2 1 3 2 1 3 1 4 3 2 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, when we compute the average with the function &lt;code&gt;mean&lt;/code&gt;, we obtain an &lt;code&gt;NA&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mean(na_example)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;is.na&lt;/code&gt; function returns a logical vector that tells us which entries are &lt;code&gt;NA&lt;/code&gt;. Assign this logical vector to an object called &lt;code&gt;ind&lt;/code&gt; and determine how many &lt;code&gt;NA&lt;/code&gt;s does &lt;code&gt;na_example&lt;/code&gt; have.&lt;/p&gt;
&lt;ol start=&#34;8&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Now compute the average again, but only for the entries that are not &lt;code&gt;NA&lt;/code&gt;. Hint: remember the &lt;code&gt;!&lt;/code&gt; operator.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;vector-arithmetics&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vector arithmetics&lt;/h2&gt;
&lt;p&gt;California had the most murders, but does this mean it is the most dangerous state? What if it just has many more people than any other state? We can quickly confirm that California indeed has the largest population:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(&amp;quot;murders&amp;quot;)
murders$state[which.max(murders$population)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;California&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;with over 37 million inhabitants. It is therefore unfair to compare the totals if we are interested in learning how safe the state is. What we really should be computing is the murders per capita. The reports we describe in the motivating section used murders per 100,000 as the unit. To compute this quantity, the powerful vector arithmetic capabilities of &lt;code&gt;R&lt;/code&gt; come in handy.&lt;/p&gt;
&lt;div id=&#34;rescaling-a-vector&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Rescaling a vector&lt;/h3&gt;
&lt;p&gt;In R, arithmetic operations on vectors occur &lt;em&gt;element-wise&lt;/em&gt;. For a quick example, suppose we have height in inches:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inches &amp;lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and want to convert to centimeters. Notice what happens when we multiply &lt;code&gt;inches&lt;/code&gt; by 2.54:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inches * 2.54&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 175.26 157.48 167.64 177.80 177.80 185.42 170.18 185.42 170.18 177.80&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the line above, we multiplied each element by 2.54. Similarly, if for each entry we want to compute how many inches taller or shorter than 69 inches, the average height for males, we can subtract it from every entry like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;inches - 69&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]  0 -7 -3  1  1  4 -2  4 -2  1&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;two-vectors&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Two vectors&lt;/h3&gt;
&lt;p&gt;If we have two vectors of the same length, and we sum them in R, they will be added entry by entry as follows:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{pmatrix}
a\\
b\\
c\\
d
\end{pmatrix}
+
\begin{pmatrix}
e\\
f\\
g\\
h
\end{pmatrix}
=
\begin{pmatrix}
a +e\\
b + f\\
c + g\\
d + h
\end{pmatrix}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The same holds for other mathematical operations, such as &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;*&lt;/code&gt; and &lt;code&gt;/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This implies that to compute the murder rates we can simply type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murder_rate &amp;lt;- murders$total / murders$population * 100000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we do this, we notice that California is no longer near the top of the list. In fact, we can use what we have learned to order the states by murder rate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders$abb[order(murder_rate)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;VT&amp;quot; &amp;quot;NH&amp;quot; &amp;quot;HI&amp;quot; &amp;quot;ND&amp;quot; &amp;quot;IA&amp;quot; &amp;quot;ID&amp;quot; &amp;quot;UT&amp;quot; &amp;quot;ME&amp;quot; &amp;quot;WY&amp;quot; &amp;quot;OR&amp;quot; &amp;quot;SD&amp;quot; &amp;quot;MN&amp;quot; &amp;quot;MT&amp;quot; &amp;quot;CO&amp;quot; &amp;quot;WA&amp;quot;
## [16] &amp;quot;WV&amp;quot; &amp;quot;RI&amp;quot; &amp;quot;WI&amp;quot; &amp;quot;NE&amp;quot; &amp;quot;MA&amp;quot; &amp;quot;IN&amp;quot; &amp;quot;KS&amp;quot; &amp;quot;NY&amp;quot; &amp;quot;KY&amp;quot; &amp;quot;AK&amp;quot; &amp;quot;OH&amp;quot; &amp;quot;CT&amp;quot; &amp;quot;NJ&amp;quot; &amp;quot;AL&amp;quot; &amp;quot;IL&amp;quot;
## [31] &amp;quot;OK&amp;quot; &amp;quot;NC&amp;quot; &amp;quot;NV&amp;quot; &amp;quot;VA&amp;quot; &amp;quot;AR&amp;quot; &amp;quot;TX&amp;quot; &amp;quot;NM&amp;quot; &amp;quot;CA&amp;quot; &amp;quot;FL&amp;quot; &amp;quot;TN&amp;quot; &amp;quot;PA&amp;quot; &amp;quot;AZ&amp;quot; &amp;quot;GA&amp;quot; &amp;quot;MS&amp;quot; &amp;quot;MI&amp;quot;
## [46] &amp;quot;DE&amp;quot; &amp;quot;SC&amp;quot; &amp;quot;MD&amp;quot; &amp;quot;MO&amp;quot; &amp;quot;LA&amp;quot; &amp;quot;DC&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;TRY IT&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Previously we created this data frame:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;temp &amp;lt;- c(35, 88, 42, 84, 81, 30)
city &amp;lt;- c(&amp;quot;Beijing&amp;quot;, &amp;quot;Lagos&amp;quot;, &amp;quot;Paris&amp;quot;, &amp;quot;Rio de Janeiro&amp;quot;,
          &amp;quot;San Juan&amp;quot;, &amp;quot;Toronto&amp;quot;)
city_temps &amp;lt;- data.frame(name = city, temperature = temp)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remake the data frame using the code above, but add a line that converts the temperature from Fahrenheit to Celsius. The conversion is &lt;span class=&#34;math inline&#34;&gt;\(C = \frac{5}{9} \times (F - 32)\)&lt;/span&gt;.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Write code to compute the following sum &lt;span class=&#34;math inline&#34;&gt;\(1+1/2^2 + 1/3^2 + \dots 1/100^2\)&lt;/span&gt;? &lt;em&gt;Hint:&lt;/em&gt; thanks to Euler, we know it should be close to &lt;span class=&#34;math inline&#34;&gt;\(\pi^2/6\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compute the per 100,000 murder rate for each state and store it in the object &lt;code&gt;murder_rate&lt;/code&gt;. Then compute the average murder rate for the US using the function &lt;code&gt;mean&lt;/code&gt;. What is the average?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;indexing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Indexing&lt;/h2&gt;
&lt;p&gt;Indexing is a boring name for an important tool. &lt;code&gt;R&lt;/code&gt; provides a powerful and convenient way of referencing specific elements of vectors. We can, for example, subset a vector based on properties of another vector. In this section, we continue working with our US murders example, which we can load like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(&amp;quot;murders&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;subsetting-with-logicals&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Subsetting with logicals&lt;/h3&gt;
&lt;p&gt;We have now calculated the murder rate using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murder_rate &amp;lt;- murders$total / murders$population * 100000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Imagine you are moving from Italy where, according to an ABC news report, the murder rate is only 0.71 per 100,000. You would prefer to move to a state with a similar murder rate. Another powerful feature of &lt;code&gt;R&lt;/code&gt; is that we can use logicals to index vectors. If we compare a vector to a single number, it actually performs the test for each entry. The following is an example related to the question above:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- murder_rate &amp;lt; 0.71&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we instead want to know if a value is less or equal, we can use:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- murder_rate &amp;lt;= 0.71&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we get back a logical vector with &lt;code&gt;TRUE&lt;/code&gt; for each entry smaller than or equal to 0.71. To see which states these are, we can leverage the fact that vectors can be indexed with logicals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murders$state[ind]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Hawaii&amp;quot;        &amp;quot;Iowa&amp;quot;          &amp;quot;New Hampshire&amp;quot; &amp;quot;North Dakota&amp;quot; 
## [5] &amp;quot;Vermont&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In order to count how many are TRUE, the function &lt;code&gt;sum&lt;/code&gt; returns the sum of the entries of a vector and logical vectors get &lt;em&gt;coerced&lt;/em&gt; to numeric with &lt;code&gt;TRUE&lt;/code&gt; coded as 1 and &lt;code&gt;FALSE&lt;/code&gt; as 0. Thus we can count the states using:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(ind)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;logical-operators&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Logical operators&lt;/h3&gt;
&lt;p&gt;Suppose we like the mountains and we want to move to a safe state in the western region of the country. We want the murder rate to be at most 1. In this case, we want two different things to be true. Here we can use the logical operator &lt;em&gt;and&lt;/em&gt;, which in &lt;code&gt;R&lt;/code&gt; is represented with &lt;code&gt;&amp;amp;&lt;/code&gt;. This operation results in &lt;code&gt;TRUE&lt;/code&gt; only when both logicals are &lt;code&gt;TRUE&lt;/code&gt;. To see this, consider this example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TRUE &amp;amp; TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;TRUE &amp;amp; FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;FALSE &amp;amp; FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For our example, we can form two logicals:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;west &amp;lt;- murders$region == &amp;quot;West&amp;quot;
safe &amp;lt;- murder_rate &amp;lt;= 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and we can use the &lt;code&gt;&amp;amp;&lt;/code&gt; to get a vector of logicals that tells us which states satisfy both conditions:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- safe &amp;amp; west
murders$state[ind]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Hawaii&amp;quot;  &amp;quot;Idaho&amp;quot;   &amp;quot;Oregon&amp;quot;  &amp;quot;Utah&amp;quot;    &amp;quot;Wyoming&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;which&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;which&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Suppose we want to look up California’s murder rate. For this type of operation, it is convenient to convert vectors of logicals into indexes instead of keeping long vectors of logicals. The function &lt;code&gt;which&lt;/code&gt; tells us which entries of a logical vector are TRUE. So we can type:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- which(murders$state == &amp;quot;California&amp;quot;)
murder_rate[ind]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3.374138&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;match&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;match&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;If instead of just one state we want to find out the murder rates for several states, say New York, Florida, and Texas, we can use the function &lt;code&gt;match&lt;/code&gt;. This function tells us which indexes of a second vector match each of the entries of a first vector:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- match(c(&amp;quot;New York&amp;quot;, &amp;quot;Florida&amp;quot;, &amp;quot;Texas&amp;quot;), murders$state)
ind&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 33 10 44&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can look at the murder rates:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;murder_rate[ind]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 2.667960 3.398069 3.201360&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;in&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;code&gt;%in%&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;If rather than an index we want a logical that tells us whether or not each element of a first vector is in a second, we can use the function &lt;code&gt;%in%&lt;/code&gt;. Let’s imagine you are not sure if Boston, Dakota, and Washington are states. You can find out like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;c(&amp;quot;Boston&amp;quot;, &amp;quot;Dakota&amp;quot;, &amp;quot;Washington&amp;quot;) %in% murders$state&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE FALSE  TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that we will be using &lt;code&gt;%in%&lt;/code&gt; often throughout the book.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advanced&lt;/strong&gt;: There is a connection between &lt;code&gt;match&lt;/code&gt; and &lt;code&gt;%in%&lt;/code&gt; through &lt;code&gt;which&lt;/code&gt;. To see this, notice that the following two lines produce the same index (although in different order):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;match(c(&amp;quot;New York&amp;quot;, &amp;quot;Florida&amp;quot;, &amp;quot;Texas&amp;quot;), murders$state)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 33 10 44&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;which(murders$state%in%c(&amp;quot;New York&amp;quot;, &amp;quot;Florida&amp;quot;, &amp;quot;Texas&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 10 33 44&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;rmarkdown&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rmarkdown&lt;/h2&gt;
&lt;p&gt;If you’re new to Rmarkdown, a previous instructor (Prof. Kirkpatrick) has provided &lt;a href=&#34;https://mediaspace.msu.edu/media/Spring2021_R_Part3/1_yigvqy1i&#34;&gt;a short video on how to use it &lt;i class=&#34;fas fa-film&#34;&gt;&lt;/i&gt;&lt;/a&gt;. This video is for his EC420 course, but the principles are universal.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;EXERCISES&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Start by loading the library and data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)&lt;/code&gt;&lt;/pre&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Compute the per 100,000 murder rate for each state and store it in an object called &lt;code&gt;murder_rate&lt;/code&gt;. Then use logical operators to create a logical vector named &lt;code&gt;low&lt;/code&gt; that tells us which entries of &lt;code&gt;murder_rate&lt;/code&gt; are lower than 1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now use the results from the previous exercise and the function &lt;code&gt;which&lt;/code&gt; to determine the indices of &lt;code&gt;murder_rate&lt;/code&gt; associated with values lower than 1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the results from the previous exercise to report the names of the states with murder rates lower than 1.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now extend the code from exercises 2 and 3 to report the states in the Northeast with murder rates lower than 1. Hint: use the previously defined logical vector &lt;code&gt;low&lt;/code&gt; and the logical operator &lt;code&gt;&amp;amp;&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In a previous exercise we computed the murder rate for each state and the average of these numbers. How many states are below the average?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the match function to identify the states with abbreviations AK, MI, and IA. Hint: start by defining an index of the entries of &lt;code&gt;murders$abb&lt;/code&gt; that match the three abbreviations, then use the &lt;code&gt;[&lt;/code&gt; operator to extract the states.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Use the &lt;code&gt;%in%&lt;/code&gt; operator to create a logical vector that answers the question: which of the following are actual abbreviations: MA, ME, MI, MO, MU?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Extend the code you used in exercise 7 to report the one entry that is &lt;strong&gt;not&lt;/strong&gt; an actual abbreviation. Hint: use the &lt;code&gt;!&lt;/code&gt; operator, which turns &lt;code&gt;FALSE&lt;/code&gt; into &lt;code&gt;TRUE&lt;/code&gt; and vice versa, then &lt;code&gt;which&lt;/code&gt; to obtain an index.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://rstudio.cloud&#34; class=&#34;uri&#34;&gt;https://rstudio.cloud&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://rafalab.github.io/dsbook/installing-r-rstudio.html&#34; class=&#34;uri&#34;&gt;https://rafalab.github.io/dsbook/installing-r-rstudio.html&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://abcnews.go.com/blogs/headlines/2012/12/us-gun-ownership-homicide-rate-higher-than-other-developed-countries/&#34; class=&#34;uri&#34;&gt;http://abcnews.go.com/blogs/headlines/2012/12/us-gun-ownership-homicide-rate-higher-than-other-developed-countries/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;I’m especially partial to Puerto Rico.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn5&#34;&gt;&lt;p&gt;This is, without a doubt, my least favorite aspect of &lt;code&gt;R&lt;/code&gt;. I’d even venture to call it stupid. The logic behind this pesky &lt;code&gt;&amp;lt;-&lt;/code&gt; is a total mystery to me, but there &lt;em&gt;is&lt;/em&gt; logic to avoiding &lt;code&gt;=&lt;/code&gt;. But, you do you.&lt;a href=&#34;#fnref5&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn6&#34;&gt;&lt;p&gt;This equals sign is the reasons we assign values with &lt;code&gt;&amp;lt;-&lt;/code&gt;; then when arguments of a function are assigned values, we don’t end up with multiple equals signs. But… who cares.&lt;a href=&#34;#fnref6&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn7&#34;&gt;&lt;p&gt;Whether you view this as a feature or a bug is a good indicator whether you’ll enjoy working with &lt;code&gt;R&lt;/code&gt;.&lt;a href=&#34;#fnref7&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
