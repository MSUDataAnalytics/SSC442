<!DOCTYPE html>
<html lang="en-us" 
      xmlns:og="http://ogp.me/ns#" 
      xmlns:fb="https://www.facebook.com/2008/fbml">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Ben Bushong">

  
  
  
    
  
  <meta name="description" content="Part 1: Statistical Inference and Polls  Polls  The sampling model for polls  Populations, samples, parameters, and estimates  The sample average Parameters Polling versus forecasting Properties of our estimate: expected value and standard error  Central Limit Theorem  A Monte Carlo simulation The spread Bias: why not run a very large poll?   Part 2: (Supplemental) Additional Visualization Techniques  Code  Load and clean data Histograms Density plots Box, violin, and rain cloud plots     Probabilistic thinking is central in the human experience.">

  
  <link rel="alternate" hreflang="en-us" href="https://ssc442.netlify.app/example/05-example/">

  


  
  
  
  <meta name="theme-color" content="#18453B">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Sans+Condensed:400,400i,700,700i%7COverpass:400,400i,700,700i&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu5cb5fae69b6b75ece00896ca20e5499a_29457_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu5cb5fae69b6b75ece00896ca20e5499a_29457_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://ssc442.netlify.app/example/05-example/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Data Analytics">
  <meta property="og:url" content="https://ssc442.netlify.app/example/05-example/">
  <meta property="og:title" content="Visualizing Uncertainty | Data Analytics">
  <meta property="og:description" content="Part 1: Statistical Inference and Polls  Polls  The sampling model for polls  Populations, samples, parameters, and estimates  The sample average Parameters Polling versus forecasting Properties of our estimate: expected value and standard error  Central Limit Theorem  A Monte Carlo simulation The spread Bias: why not run a very large poll?   Part 2: (Supplemental) Additional Visualization Techniques  Code  Load and clean data Histograms Density plots Box, violin, and rain cloud plots     Probabilistic thinking is central in the human experience."><meta property="og:image" content="https://ssc442.netlify.app/img/social-image.png">
  <meta property="twitter:image" content="https://ssc442.netlify.app/img/social-image.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2021-09-30T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2021-10-19T10:55:53-04:00">
  

  



  


  


  <link rel="shortcut icon" href="https://ssc442.netlify.app/favicon.ico" />
  <link rel="apple-touch-icon-precomposed" sizes="57x57" href="https://ssc442.netlify.app/img/apple-touch-icon-57x57.png" />
  <link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://ssc442.netlify.app/img/apple-touch-icon-114x114.png" />
  <link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://ssc442.netlify.app/img/apple-touch-icon-72x72.png" />
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://ssc442.netlify.app/img/apple-touch-icon-144x144.png" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="https://ssc442.netlify.app/img/apple-touch-icon-120x120.png" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="https://ssc442.netlify.app/img/apple-touch-icon-152x152.png" />
  <link rel="icon" type="image/png" href="https://ssc442.netlify.app/img/favicon-32x32.png" sizes="32x32" />
  <link rel="icon" type="image/png" href="https://ssc442.netlify.app/img/favicon-16x16.png" sizes="16x16" />
  <meta name="application-name" content="SSC 442: Data Analytics" />
  <meta name="msapplication-TileColor" content="#FFFFFF" />
  <meta name="msapplication-TileImage" content="https://ssc442.netlify.app/img/mstile-144x144.png" />


  <title>Visualizing Uncertainty | Data Analytics</title>

</head>


<body id="top" data-spy="scroll" data-offset="70"
    data-target="#TableOfContents"
    >

    <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


    







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Data Analytics</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Data Analytics</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/syllabus/"><span>Syllabus</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/schedule/"><span>Schedule</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/content/"><span>Content</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/example/"><span>Examples</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="/assignment/"><span>Assignments</span></a>
        </li>

        
        

        

        
        
        
          
            
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link " href="https://join.slack.com/t/ssc442/shared_invite/zt-v3n7r8hh-TjwMzpDLBSywvVYwzftqXA" target="_blank" rel="noopener"><span><i class="fab fa-slack"></i></span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      

      

    </ul>

  </div>
</nav>


    

<div class="container-fluid docs">
    <div class="row flex-xl-nowrap">
        <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
            





  
    
  




<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
</form>

<nav class="collapse docs-links" id="docs-nav">
  

  
  
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/example/">Practical Content in This Class</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/example/01-example/">Examples</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/example/01-example/">1: Introduction to R</a>
      </li>
      
      <li >
        <a href="/example/02-example/">2: Visualization I</a>
      </li>
      
      <li >
        <a href="/example/03-example/">3: Visualization II</a>
      </li>
      
      <li >
        <a href="/example/04-example/">4: Visualization III</a>
      </li>
      
      <li class="active">
        <a href="/example/05-example/">5: Uncertainty</a>
      </li>
      
      <li >
        <a href="/example/06-example/">6: Linear Regression I</a>
      </li>
      
      <li >
        <a href="/example/07-example/">7: Linear Regression II</a>
      </li>
      
      <li >
        <a href="/example/08-example/">8: Linear Regression III</a>
      </li>
      
      <li >
        <a href="/example/09-example/">9: Bias vs. Variance</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

        </div>

        

        <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

            <article class="article">

                <div class="docs-article-container">
                    <h1>Visualizing Uncertainty</h1>

                    

                    
                    <div class="due-date p-2 mb-3 bg-content text-white">
                        Content for Thursday, September 30, 2021
                    </div>
                    

                    

                    <div class="article-style">
                        
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>
<link href="/rmarkdown-libs/lightable/lightable.css" rel="stylesheet" />

<div id="TOC">
<ul>
<li><a href="#part-1-statistical-inference-and-polls">Part 1: Statistical Inference and Polls</a>
<ul>
<li><a href="#polls">Polls</a>
<ul>
<li><a href="#the-sampling-model-for-polls">The sampling model for polls</a></li>
</ul></li>
<li><a href="#populations-samples-parameters-and-estimates">Populations, samples, parameters, and estimates</a>
<ul>
<li><a href="#the-sample-average">The sample average</a></li>
<li><a href="#parameters">Parameters</a></li>
<li><a href="#polling-versus-forecasting">Polling versus forecasting</a></li>
<li><a href="#properties-of-our-estimate-expected-value-and-standard-error">Properties of our estimate: expected value and standard error</a></li>
</ul></li>
<li><a href="#clt">Central Limit Theorem</a>
<ul>
<li><a href="#a-monte-carlo-simulation">A Monte Carlo simulation</a></li>
<li><a href="#the-spread">The spread</a></li>
<li><a href="#bias-why-not-run-a-very-large-poll">Bias: why not run a very large poll?</a></li>
</ul></li>
</ul></li>
<li><a href="#part-2-supplemental-additional-visualization-techniques">Part 2: (Supplemental) Additional Visualization Techniques</a>
<ul>
<li><a href="#code">Code</a>
<ul>
<li><a href="#load-and-clean-data">Load and clean data</a></li>
<li><a href="#histograms">Histograms</a></li>
<li><a href="#density-plots">Density plots</a></li>
<li><a href="#box-violin-and-rain-cloud-plots">Box, violin, and rain cloud plots</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<p>Probabilistic thinking is central in the human experience. How we describe that thinking is mixed, but most of the time we use (rather imprecise) language. With only a few moments of searching, one can find thousands of articles that use probabilistic words to describe events. Here are some examples:</p>
<blockquote>
<p>“‘Highly unlikely’ State of the Union will happen amid shutdown” – The Hill</p>
</blockquote>
<blockquote>
<p>“Tiger Woods makes Masters 15th and most improbable major” – Fox</p>
</blockquote>
<blockquote>
<p>“Trump predicts ‘very good chance’ of China trade deal” – CNN</p>
</blockquote>
<p>Yet people don’t have a good sense of what these things mean. Uncertainty is key to data analytics: if we were certain of things, A study in the 1960s explored the perception of probabilistic words like these among NATO officers. A more modern replication of this found the following basic pattern:</p>
<p><img src="/content/05-content_files/words.png" /></p>
<p>A deep, basic fact about humans is that we struggle to understand probabilities. But visualizing things can help. The graphic above shows the uncertainty about uncertainty (very meta). We can convey all manner of uncertainty with clever graphics. Today’s practical example works through some of the myriad of ways to visualize variable data. We’ll cover some territory that we’ve already hit, in hopes of locking in some key concepts.</p>
<div id="part-1-statistical-inference-and-polls" class="section level1">
<h1>Part 1: Statistical Inference and Polls</h1>
<p>In this Example we will describe, in some detail, how poll aggregators such as FiveThirtyEight use data to predict election outcomes. To understand how they do this, we first need to learn the basics of <em>Statistical Inference</em>, the part of statistics that helps distinguish patterns arising from signal from those arising from chance. Statistical inference is a broad topic and here we go over the very basics using polls as a motivating example. To describe the concepts, we complement the mathematical formulas with Monte Carlo simulations and <code>R</code> code.</p>
<div id="polls" class="section level2">
<h2>Polls</h2>
<p>Opinion polling has been conducted since the 19th century. The general goal is to describe the opinions held by a specific population on a given set of topics. In recent times, these polls have been pervasive during presidential elections. Polls are useful when interviewing every member of a particular population is logistically impossible. The general strategy is to interview a smaller group, chosen at random, and then infer the opinions of the entire population from the opinions of the smaller group. Statistical theory is used to justify the process. This theory is referred to as <em>inference</em> and it is the main topic of this chapter.</p>
<p>Perhaps the best known opinion polls are those conducted to determine which candidate is preferred by voters in a given election. Political strategists make extensive use of polls to decide, among other things, how to invest resources. For example, they may want to know in which geographical locations to focus their “get out the vote” efforts.</p>
<p>Elections are a particularly interesting case of opinion polls because the actual opinion of the entire population is revealed on election day. Of course, it costs millions of dollars to run an actual election which makes polling a cost effective strategy for those that want to forecast the results.</p>
<p>Although typically the results of these polls are kept private, similar polls are conducted by news organizations because results tend to be of interest to the general public and made public. We will eventually be looking at such data.</p>
<p>Real Clear Politics<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> is an example of a news aggregator that organizes and publishes poll results. For example, they present the following poll results reporting estimates of the popular vote for the 2016 presidential election<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>:</p>
<table class="table table-striped" style="width: auto !important; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
Poll
</th>
<th style="text-align:left;">
Date
</th>
<th style="text-align:left;">
Sample
</th>
<th style="text-align:left;">
MoE
</th>
<th style="text-align:right;">
Clinton
</th>
<th style="text-align:right;">
Trump
</th>
<th style="text-align:left;">
Spread
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Final Results
</td>
<td style="text-align:left;">
–
</td>
<td style="text-align:left;">
–
</td>
<td style="text-align:left;">
–
</td>
<td style="text-align:right;">
48.2
</td>
<td style="text-align:right;">
46.1
</td>
<td style="text-align:left;">
Clinton +2.1
</td>
</tr>
<tr>
<td style="text-align:left;">
RCP Average
</td>
<td style="text-align:left;">
11/1 - 11/7
</td>
<td style="text-align:left;">
–
</td>
<td style="text-align:left;">
–
</td>
<td style="text-align:right;">
46.8
</td>
<td style="text-align:right;">
43.6
</td>
<td style="text-align:left;">
Clinton +3.2
</td>
</tr>
<tr>
<td style="text-align:left;">
Bloomberg
</td>
<td style="text-align:left;">
11/4 - 11/6
</td>
<td style="text-align:left;">
799 LV
</td>
<td style="text-align:left;">
3.5
</td>
<td style="text-align:right;">
46.0
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:left;">
Clinton +3
</td>
</tr>
<tr>
<td style="text-align:left;">
IBD
</td>
<td style="text-align:left;">
11/4 - 11/7
</td>
<td style="text-align:left;">
1107 LV
</td>
<td style="text-align:left;">
3.1
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
42.0
</td>
<td style="text-align:left;">
Clinton +1
</td>
</tr>
<tr>
<td style="text-align:left;">
Economist
</td>
<td style="text-align:left;">
11/4 - 11/7
</td>
<td style="text-align:left;">
3669 LV
</td>
<td style="text-align:left;">
–
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
45.0
</td>
<td style="text-align:left;">
Clinton +4
</td>
</tr>
<tr>
<td style="text-align:left;">
LA Times
</td>
<td style="text-align:left;">
11/1 - 11/7
</td>
<td style="text-align:left;">
2935 LV
</td>
<td style="text-align:left;">
4.5
</td>
<td style="text-align:right;">
44.0
</td>
<td style="text-align:right;">
47.0
</td>
<td style="text-align:left;">
Trump +3
</td>
</tr>
<tr>
<td style="text-align:left;">
ABC
</td>
<td style="text-align:left;">
11/3 - 11/6
</td>
<td style="text-align:left;">
2220 LV
</td>
<td style="text-align:left;">
2.5
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
46.0
</td>
<td style="text-align:left;">
Clinton +3
</td>
</tr>
<tr>
<td style="text-align:left;">
FOX News
</td>
<td style="text-align:left;">
11/3 - 11/6
</td>
<td style="text-align:left;">
1295 LV
</td>
<td style="text-align:left;">
2.5
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
44.0
</td>
<td style="text-align:left;">
Clinton +4
</td>
</tr>
<tr>
<td style="text-align:left;">
Monmouth
</td>
<td style="text-align:left;">
11/3 - 11/6
</td>
<td style="text-align:left;">
748 LV
</td>
<td style="text-align:left;">
3.6
</td>
<td style="text-align:right;">
50.0
</td>
<td style="text-align:right;">
44.0
</td>
<td style="text-align:left;">
Clinton +6
</td>
</tr>
<tr>
<td style="text-align:left;">
NBC News
</td>
<td style="text-align:left;">
11/3 - 11/5
</td>
<td style="text-align:left;">
1282 LV
</td>
<td style="text-align:left;">
2.7
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:left;">
Clinton +5
</td>
</tr>
<tr>
<td style="text-align:left;">
CBS News
</td>
<td style="text-align:left;">
11/2 - 11/6
</td>
<td style="text-align:left;">
1426 LV
</td>
<td style="text-align:left;">
3.0
</td>
<td style="text-align:right;">
47.0
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:left;">
Clinton +4
</td>
</tr>
<tr>
<td style="text-align:left;">
Reuters
</td>
<td style="text-align:left;">
11/2 - 11/6
</td>
<td style="text-align:left;">
2196 LV
</td>
<td style="text-align:left;">
2.3
</td>
<td style="text-align:right;">
44.0
</td>
<td style="text-align:right;">
39.0
</td>
<td style="text-align:left;">
Clinton +5
</td>
</tr>
</tbody>
</table>
<!-- (Source: [Real Clear Politics](https://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html)) -->
<p>Although in the United States the popular vote does not determine the result of the presidential election, we will use it as an illustrative and simple example of how well polls work. Forecasting the election is a more complex process since it involves combining results from 50 states and DC and we will go into some detail on this later.</p>
<p>Let’s make some observations about the table above. First, note that different polls, all taken days before the election, report a different <em>spread</em>: the estimated difference between support for the two candidates. Notice also that the reported spreads hover around what ended up being the actual result: Clinton won the popular vote by 2.1%. We also see a column titled <strong>MoE</strong> which stands for <em>margin of error</em>.</p>
<p>In this example, we will show how the probability concepts we learned in the previous content can be applied to develop the statistical approaches that make polls an effective tool. We will learn the statistical concepts necessary to define <em>estimates</em> and <em>margins of errors</em>, and show how we can use these to forecast final results relatively well and also provide an estimate of the precision of our forecast. Once we learn this, we will be able to understand two concepts that are ubiquitous in data science: <em>confidence intervals</em> and <em>p-values</em>. Finally, to understand probabilistic statements about the probability of a candidate winning, we will have to learn about Bayesian modeling. In the final sections, we put it all together to recreate the simplified version of the FiveThirtyEight model and apply it to the 2016 election.</p>
<p>We start by connecting probability theory to the task of using polls to learn about a population.</p>
<div id="the-sampling-model-for-polls" class="section level3">
<h3>The sampling model for polls</h3>
<p>To help us understand the connection between polls and what we have learned, let’s construct a similar situation to the one pollsters face. To mimic the challenge real pollsters face in terms of competing with other pollsters for media attention, we will use an urn full of beads to represent voters and pretend we are competing for a $25 dollar prize. The challenge is to guess the spread between the proportion of blue and red beads in this hypothetical urn.</p>
<p>Before making a prediction, you can take a sample (with replacement) from the urn. To mimic the fact that running polls is expensive, it costs you 10 cents per each bead you sample. Therefore, if your sample size is 250, and you win, you will break even since you will pay \$25 to collect your \$25 prize. Your entry into the competition can be an interval. If the interval you submit contains the true proportion, you get half what you paid and pass to the second phase of the competition. In the second phase, the entry with the smallest interval is selected as the winner.</p>
<p>The <strong>dslabs</strong> package includes a function that shows a random draw from this urn:</p>
<pre class="r"><code>library(tidyverse)
library(dslabs)
take_poll(25)</code></pre>
<p><img src="/example/05-example_files/figure-html/first-simulated-poll-1.png" width="672" /></p>
<p>Think about how you would construct your interval based on the data shown above.</p>
<p>We have just described a simple sampling model for opinion polls. The beads inside the urn represent the individuals that will vote on election day. Those that will vote for the Republican candidate are represented with red beads and the Democrats with the blue beads. For simplicity, assume there are no other colors. That is, that there are just two parties: Republican and Democratic.</p>
</div>
</div>
<div id="populations-samples-parameters-and-estimates" class="section level2">
<h2>Populations, samples, parameters, and estimates</h2>
<p>We want to predict the proportion of blue beads in the urn. Let’s call this quantity <span class="math inline">\(p\)</span>, which then tells us the proportion of red beads <span class="math inline">\(1-p\)</span>, and the spread <span class="math inline">\(p - (1-p)\)</span>, which simplifies to <span class="math inline">\(2p - 1\)</span>.</p>
<p>In statistical textbooks, the beads in the urn are called the <em>population</em>. The proportion of blue beads in the population <span class="math inline">\(p\)</span> is called a <em>parameter</em>. The 25 beads we see in the previous plot are called a <em>sample</em>. The task of statistical inference is to predict the parameter <span class="math inline">\(p\)</span> using the observed data in the sample.</p>
<p>Can we do this with the 25 observations above? It is certainly informative. For example, given that we see 13 red and 12 blue beads, it is unlikely that <span class="math inline">\(p\)</span> &gt; .9 or <span class="math inline">\(p\)</span> &lt; .1. But are we ready to predict with certainty that there are more red beads than blue in the jar?</p>
<p>We want to construct an estimate of <span class="math inline">\(p\)</span> using only the information we observe. An estimate should be thought of as a summary of the observed data that we think is informative about the parameter of interest. It seems intuitive to think that the proportion of blue beads in the sample <span class="math inline">\(0.48\)</span> must be at least related to the actual proportion <span class="math inline">\(p\)</span>. But do we simply predict <span class="math inline">\(p\)</span> to be 0.48? First, remember that the sample proportion is a random variable. If we run the command <code>take_poll(25)</code> four times, we get a different answer each time, since the sample proportion is a random variable.</p>
<p><img src="/example/05-example_files/figure-html/four-simulated-polls-1.png" width="672" /></p>
<p>Note that in the four random samples shown above, the sample proportions range from 0.44 to 0.60. By describing the distribution of this random variable, we will be able to gain insights into how good this estimate is and how we can make it better.</p>
<div id="the-sample-average" class="section level3">
<h3>The sample average</h3>
<p>Conducting an opinion poll is being modeled as taking a random sample from an urn. We are proposing the use of the proportion of blue beads in our sample as an <em>estimate</em> of the parameter <span class="math inline">\(p\)</span>. Once we have this estimate, we can easily report an estimate for the spread <span class="math inline">\(2p-1\)</span>, but for simplicity we will illustrate the concepts for estimating <span class="math inline">\(p\)</span>. We will use our knowledge of probability to defend our use of the sample proportion and quantify how close we think it is from the population proportion <span class="math inline">\(p\)</span>.</p>
<p>We start by defining the random variable <span class="math inline">\(X\)</span> as: <span class="math inline">\(X=1\)</span> if we pick a blue bead at random and <span class="math inline">\(X=0\)</span> if it is red. This implies that the population is a list of 0s and 1s. If we sample <span class="math inline">\(N\)</span> beads, then the average of the draws <span class="math inline">\(X_1, \dots, X_N\)</span> is equivalent to the proportion of blue beads in our sample. This is because adding the <span class="math inline">\(X\)</span>s is equivalent to counting the blue beads and dividing this count by the total <span class="math inline">\(N\)</span> is equivalent to computing a proportion. We use the symbol <span class="math inline">\(\bar{X}\)</span> to represent this average. In general, in statistics textbooks a bar on top of a symbol means the average. The theory we just learned about the sum of draws becomes useful because the average is a sum of draws multiplied by the constant <span class="math inline">\(1/N\)</span>:</p>
<p><span class="math display">\[\bar{X} = 1/N \times \sum_{i=1}^N X_i\]</span></p>
<p>For simplicity, let’s assume that the draws are independent: after we see each sampled bead, we return it to the urn. In this case, what do we know about the distribution of the sum of draws? First, we know that the expected value of the sum of draws is <span class="math inline">\(N\)</span> times the average of the values in the urn. We know that the average of the 0s and 1s in the urn must be <span class="math inline">\(p\)</span>, the proportion of blue beads.</p>
<p>Here we encounter an important difference with what we did in the Probability chapter: we don’t know what is in the urn. We know there are blue and red beads, but we don’t know how many of each. This is what we want to find out: we are trying to <strong>estimate</strong> <span class="math inline">\(p\)</span>.</p>
</div>
<div id="parameters" class="section level3">
<h3>Parameters</h3>
<p>Just like we use variables to define unknowns in systems of equations, in statistical inference we define <em>parameters</em> to define unknown parts of our models. In the urn model which we are using to mimic an opinion poll, we do not know the proportion of blue beads in the urn. We define the parameters <span class="math inline">\(p\)</span> to represent this quantity. <span class="math inline">\(p\)</span> is the average of the urn because if we take the average of the 1s (blue) and 0s (red), we get the proportion of blue beads. Since our main goal is figuring out what is <span class="math inline">\(p\)</span>, we are going to <em>estimate this parameter</em>.</p>
<p>The ideas presented here on how we estimate parameters, and provide insights into how good these estimates are, extrapolate to many data science tasks. For example, we may want to determine the difference in health improvement between patients receiving treatment and a control group. We may ask, what are the health effects of smoking on a population? What are the differences in racial groups of fatal shootings by police? What is the rate of change in life expectancy in the US during the last 10 years? All these questions can be framed as a task of estimating a parameter from a sample.</p>
</div>
<div id="polling-versus-forecasting" class="section level3">
<h3>Polling versus forecasting</h3>
<p>Before we continue, let’s make an important clarification related to the practical problem of forecasting the election. If a poll is conducted four months before the election, it is estimating the <span class="math inline">\(p\)</span> for that moment and not for election day. The <span class="math inline">\(p\)</span> for election night might be different since people’s opinions fluctuate through time. The polls provided the night before the election tend to be the most accurate since opinions don’t change that much in a day. However, forecasters try to build tools that model how opinions vary across time and try to predict the election night results taking into consideration the fact that opinions fluctuate. We will describe some approaches for doing this in a later section.</p>
</div>
<div id="properties-of-our-estimate-expected-value-and-standard-error" class="section level3">
<h3>Properties of our estimate: expected value and standard error</h3>
<p>To understand how good our estimate is, we will describe the statistical properties of the random variable defined above: the sample proportion <span class="math inline">\(\bar{X}\)</span>. Remember that <span class="math inline">\(\bar{X}\)</span> is the sum of independent draws so the rules we covered in the probability chapter apply.</p>
<p>Using what we have learned, the expected value of the sum <span class="math inline">\(N\bar{X}\)</span> is <span class="math inline">\(N \times\)</span> the average of the urn, <span class="math inline">\(p\)</span>. So dividing by the non-random constant <span class="math inline">\(N\)</span> gives us that the expected value of the average <span class="math inline">\(\bar{X}\)</span> is <span class="math inline">\(p\)</span>. We can write it using our mathematical notation:</p>
<p><span class="math display">\[
\mbox{E}(\bar{X}) = p
\]</span></p>
<p>We can also use what we learned to figure out the standard error: the standard error of the sum is <span class="math inline">\(\sqrt{N} \times\)</span> the standard deviation of the urn. Can we compute the standard error of the urn? We learned a formula that tells us that it is <span class="math inline">\((1-0) \sqrt{p (1-p)}\)</span> = <span class="math inline">\(\sqrt{p (1-p)}\)</span>. Because we are dividing the sum by <span class="math inline">\(N\)</span>, we arrive at the following formula for the standard error of the average:</p>
<p><span class="math display">\[
\mbox{SE}(\bar{X}) = \sqrt{p(1-p)/N}
\]</span></p>
<p>This result reveals the power of polls. The expected value of the sample proportion <span class="math inline">\(\bar{X}\)</span> is the parameter of interest <span class="math inline">\(p\)</span> and we can make the standard error as small as we want by increasing <span class="math inline">\(N\)</span>. The law of large numbers tells us that with a large enough poll, our estimate converges to <span class="math inline">\(p\)</span>.</p>
<p>If we take a large enough poll to make our standard error about 1%, we will be quite certain about who will win. But how large does the poll have to be for the standard error to be this small?</p>
<p>One problem is that we do not know <span class="math inline">\(p\)</span>, so we can’t compute the standard error. However, for illustrative purposes, let’s assume that <span class="math inline">\(p=0.51\)</span> and make a plot of the standard error versus the sample size <span class="math inline">\(N\)</span>:</p>
<p><img src="/example/05-example_files/figure-html/standard-error-versus-sample-size-1.png" width="672" /></p>
<p>From the plot we see that we would need a poll of over 10,000 people to get the standard error that low. We rarely see polls of this size due in part to costs. From the Real Clear Politics table, we learn that the sample sizes in opinion polls range from 500-3,500 people. For a sample size of 1,000 and <span class="math inline">\(p=0.51\)</span>, the standard error is:</p>
<pre class="r"><code>sqrt(p*(1-p))/sqrt(1000)</code></pre>
<pre><code>## [1] 0.01580823</code></pre>
<p>or 1.5 percentage points. So even with large polls, for close elections, <span class="math inline">\(\bar{X}\)</span> can lead us astray if we don’t realize it is a random variable. Nonetheless, we can actually say more about how close we get the <span class="math inline">\(p\)</span>.</p>
</div>
</div>
<div id="clt" class="section level2">
<h2>Central Limit Theorem</h2>
<p>The Central Limit Theorem (CLT) tells us that the distribution function for a sum of draws is approximately normal. You also may recall that dividing a normally distributed random variable by a constant is also a normally distributed variable. This implies that the distribution of <span class="math inline">\(\bar{X}\)</span> is approximately normal.</p>
<p>In summary, we have that <span class="math inline">\(\bar{X}\)</span> has an approximately normal distribution with expected value <span class="math inline">\(p\)</span> and standard error <span class="math inline">\(\sqrt{p(1-p)/N}\)</span>.</p>
<p>Now how does this help us? Suppose we want to know what is the probability that we are within 1% from <span class="math inline">\(p\)</span>. We are basically asking what is</p>
<p><span class="math display">\[
\mbox{Pr}(| \bar{X} - p| \leq .01)
\]</span>
which is the same as:</p>
<p><span class="math display">\[
\mbox{Pr}(\bar{X}\leq p + .01) - \mbox{Pr}(\bar{X} \leq p - .01)
\]</span></p>
<p>Can we answer this question? We can use the mathematical trick we learned in the previous chapter. Subtract the expected value and divide by the standard error to get a standard normal random variable, call it <span class="math inline">\(Z\)</span>, on the left. Since <span class="math inline">\(p\)</span> is the expected value and <span class="math inline">\(\mbox{SE}(\bar{X}) = \sqrt{p(1-p)/N}\)</span> is the standard error we get:</p>
<p><span class="math display">\[
\mbox{Pr}\left(Z \leq \frac{ \,.01} {\mbox{SE}(\bar{X})} \right) -
\mbox{Pr}\left(Z \leq - \frac{ \,.01} {\mbox{SE}(\bar{X})} \right)
\]</span></p>
<p>One problem we have is that since we don’t know <span class="math inline">\(p\)</span>, we don’t know <span class="math inline">\(\mbox{SE}(\bar{X})\)</span>. But it turns out that the CLT still works if we estimate the standard error by using <span class="math inline">\(\bar{X}\)</span> in place of <span class="math inline">\(p\)</span>. We say that we <em>plug-in</em> the estimate. Our estimate of the standard error is therefore:</p>
<p><span class="math display">\[
\hat{\mbox{SE}}(\bar{X})=\sqrt{\bar{X}(1-\bar{X})/N}
\]</span>
In statistics textbooks, we use a little hat to denote estimates. The estimate can be constructed using the observed data and <span class="math inline">\(N\)</span>.</p>
<p>Now we continue with our calculation, but dividing by <span class="math inline">\(\hat{\mbox{SE}}(\bar{X})=\sqrt{\bar{X}(1-\bar{X})/N})\)</span> instead. In our first sample we had 12 blue and 13 red so <span class="math inline">\(\bar{X} = 0.48\)</span> and our estimate of standard error is:</p>
<pre class="r"><code>x_hat &lt;- 0.48
se &lt;- sqrt(x_hat*(1-x_hat)/25)
se</code></pre>
<pre><code>## [1] 0.09991997</code></pre>
<p>And now we can answer the question of the probability of being close to <span class="math inline">\(p\)</span>. The answer is:</p>
<pre class="r"><code>pnorm(0.01/se) - pnorm(-0.01/se)</code></pre>
<pre><code>## [1] 0.07971926</code></pre>
<p>Therefore, there is a small chance that we will be close. A poll of only <span class="math inline">\(N=25\)</span> people is not really very useful, at least not for a close election.</p>
<p>Earlier we mentioned the <em>margin of error</em>. Now we can define it because it is simply two times the standard error, which we can now estimate. In our case it is:</p>
<pre class="r"><code>1.96*se</code></pre>
<pre><code>## [1] 0.1958431</code></pre>
<p>Why do we multiply by 1.96? Because if you ask what is the probability that we are within 1.96 standard errors from <span class="math inline">\(p\)</span>, we get:</p>
<p><span class="math display">\[
\mbox{Pr}\left(Z \leq \, 1.96\,\mbox{SE}(\bar{X})  / \mbox{SE}(\bar{X}) \right) -
\mbox{Pr}\left(Z \leq - 1.96\, \mbox{SE}(\bar{X}) / \mbox{SE}(\bar{X}) \right)
\]</span>
which is:</p>
<p><span class="math display">\[
\mbox{Pr}\left(Z \leq 1.96 \right) -
\mbox{Pr}\left(Z \leq - 1.96\right)
\]</span></p>
<p>which we know is about 95%:</p>
<pre class="r"><code>pnorm(1.96)-pnorm(-1.96)</code></pre>
<pre><code>## [1] 0.9500042</code></pre>
<p>Hence, there is a 95% probability that <span class="math inline">\(\bar{X}\)</span> will be within <span class="math inline">\(1.96\times \hat{SE}(\bar{X})\)</span>, in our case within about 0.2, of <span class="math inline">\(p\)</span>. Note that 95% is somewhat of an arbitrary choice and sometimes other percentages are used, but it is the most commonly used value to define margin of error. We often round 1.96 up to 2 for simplicity of presentation.</p>
<p>In summary, the CLT tells us that our poll based on a sample size of <span class="math inline">\(25\)</span> is not very useful. We don’t really learn much when the margin of error is this large. All we can really say is that the popular vote will not be won by a large margin. This is why pollsters tend to use larger sample sizes.</p>
<p>From the table above, we see that typical sample sizes range from 700 to 3500. To see how this gives us a much more practical result, notice that if we had obtained a <span class="math inline">\(\bar{X}\)</span>=0.48 with a sample size of 2,000, our standard error <span class="math inline">\(\hat{\mbox{SE}}(\bar{X})\)</span> would have been 0.0111714. So our result is an estimate of <code>48</code>% with a margin of error of 2%. In this case, the result is much more informative and would make us think that there are more red balls than blue. Keep in mind, however, that this is hypothetical. We did not take a poll of 2,000 since we don’t want to ruin the competition.</p>
<div id="a-monte-carlo-simulation" class="section level3">
<h3>A Monte Carlo simulation</h3>
<p>Suppose we want to use a Monte Carlo simulation to corroborate the tools we have built using probability theory. To create the simulation, we would write code like this:</p>
<pre class="r"><code>B &lt;- 10000
N &lt;- 1000
x_hat &lt;- replicate(B, {
  x &lt;- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
  mean(x)
})</code></pre>
<p>The problem is, of course, we don’t know <code>p</code>. We could construct an urn like the one pictured above and run an analog (without a computer) simulation. It would take a long time, but you could take 10,000 samples, count the beads and keep track of the proportions of blue. We can use the function <code>take_poll(n=1000)</code> instead of drawing from an actual urn, but it would still take time to count the beads and enter the results.</p>
<p>One thing we therefore do to corroborate theoretical results is to pick one or several values of <code>p</code> and run the simulations. Let’s set <code>p=0.45</code>. We can then simulate a poll:</p>
<pre class="r"><code>p &lt;- 0.45
N &lt;- 1000

x &lt;- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
x_hat &lt;- mean(x)</code></pre>
<p>In this particular sample, our estimate is <code>x_hat</code>. We can use that code to do a Monte Carlo simulation:</p>
<pre class="r"><code>B &lt;- 10000
x_hat &lt;- replicate(B, {
  x &lt;- sample(c(0,1), size = N, replace = TRUE, prob = c(1-p, p))
  mean(x)
})</code></pre>
<p>To review, the theory tells us that <span class="math inline">\(\bar{X}\)</span> is approximately normally distributed, has expected value <span class="math inline">\(p=\)</span> 0.45 and standard error <span class="math inline">\(\sqrt{p(1-p)/N}\)</span> = 0.0157321. The simulation confirms this:</p>
<pre class="r"><code>mean(x_hat)</code></pre>
<pre><code>## [1] 0.4500761</code></pre>
<pre class="r"><code>sd(x_hat)</code></pre>
<pre><code>## [1] 0.01579523</code></pre>
<p>A histogram and qq-plot confirm that the normal approximation is accurate as well:</p>
<p><img src="/example/05-example_files/figure-html/normal-approximation-for-polls-1.png" width="100%" /></p>
<p>Of course, in real life we would never be able to run such an experiment because we don’t know <span class="math inline">\(p\)</span>. But we could run it for various values of <span class="math inline">\(p\)</span> and <span class="math inline">\(N\)</span> and see that the theory does indeed work well for most values. You can easily do this by re-running the code above after changing <code>p</code> and <code>N</code>.</p>
</div>
<div id="the-spread" class="section level3">
<h3>The spread</h3>
<p>The competition is to predict the spread, not the proportion <span class="math inline">\(p\)</span>. However, because we are assuming there are only two parties, we know that the spread is <span class="math inline">\(p - (1-p) = 2p - 1\)</span>. As a result, everything we have done can easily be adapted to an estimate of <span class="math inline">\(2p - 1\)</span>. Once we have our estimate <span class="math inline">\(\bar{X}\)</span> and <span class="math inline">\(\hat{\mbox{SE}}(\bar{X})\)</span>, we estimate the spread with <span class="math inline">\(2\bar{X} - 1\)</span> and, since we are multiplying by 2, the standard error is <span class="math inline">\(2\hat{\mbox{SE}}(\bar{X})\)</span>. Note that subtracting 1 does not add any variability so it does not affect the standard error.</p>
<p>For our 25 item sample above, our estimate <span class="math inline">\(p\)</span> is <code>.48</code> with margin of error <code>.20</code> and our estimate of the spread is <code>0.04</code> with margin of error <code>.40</code>. Again, not a very useful sample size. However, the point is that once we have an estimate and standard error for <span class="math inline">\(p\)</span>, we have it for the spread <span class="math inline">\(2p-1\)</span>.</p>
</div>
<div id="bias-why-not-run-a-very-large-poll" class="section level3">
<h3>Bias: why not run a very large poll?</h3>
<p>For realistic values of <span class="math inline">\(p\)</span>, say from 0.35 to 0.65, if we run a very large poll with 100,000 people, theory tells us that we would predict the election perfectly since the largest possible margin of error is around 0.3%:</p>
<p><img src="/example/05-example_files/figure-html/standard-error-versus-p-1.png" width="672" /></p>
<p>One reason is that running such a poll is very expensive. Another possibly more important reason is that theory has its limitations. Polling is much more complicated than picking beads from an urn. Some people might lie to pollsters and others might not have phones. But perhaps the most important way an actual poll differs from an urn model is that we actually don’t know for sure who is in our population and who is not. How do we know who is going to vote? Are we reaching all possible voters? Hence, even if our margin of error is very small, it might not be exactly right that our expected value is <span class="math inline">\(p\)</span>. We call this bias. Historically, we observe that polls are indeed biased, although not by that much. The typical bias appears to be about 1-2%. This makes election forecasting a bit more interesting and we will talk about how to model this shortly.</p>
</div>
</div>
</div>
<div id="part-2-supplemental-additional-visualization-techniques" class="section level1">
<h1>Part 2: (Supplemental) Additional Visualization Techniques</h1>
<p>For this second part of the example, we’re going to use historical weather data from <a href="https://darksky.net/forecast/33.7546,-84.39/us12/en">Dark Sky</a> about wind speed and temperature trends for downtown Atlanta (<a href="https://www.google.com/maps/place/33°45&#39;16.4%22N+84°23&#39;24.0%22W/@33.754557,-84.3921977,17z/">specifically <code>33.754557, -84.390009</code></a>) in 2019. We downloaded this data using Dark Sky’s (about-to-be-retired-because-they-were-bought-by-Apple) API using the <a href="https://github.com/hrbrmstr/darksky"><strong>darksky</strong> package</a>.</p>
<p>If you want to follow along with this example, you can download the data below (you’ll likely need to right click and choose “Save Link As…”):</p>
<ul>
<li><a href="/data/atl-weather-2019.csv"><i class="fas fa-file-csv"></i> <code>atl-weather-2019.csv</code></a></li>
</ul>
<div id="code" class="section level2">
<h2>Code</h2>
<div id="load-and-clean-data" class="section level3">
<h3>Load and clean data</h3>
<p>First, we load the libraries we’ll be using:</p>
<pre class="r"><code>library(tidyverse)
library(lubridate)
library(ggridges)
library(gghalves)</code></pre>
<p>Then we load the data with <code>read_csv()</code>. Here we assume that the CSV file lives in a subfolder in my project named <code>data</code>. Naturally, you’ll need to point this to wherever you stashed the data.</p>
<pre class="r"><code>weather_atl_raw &lt;- read_csv(&quot;data/atl-weather-2019.csv&quot;)</code></pre>
<p>We’ll add a couple columns that we can use for faceting and filling using the <code>month()</code> and <code>wday()</code> functions from <strong>lubridate</strong> for extracting parts of the date:</p>
<pre class="r"><code>weather_atl &lt;- weather_atl_raw %&gt;%
  mutate(Month = month(time, label = TRUE, abbr = FALSE),
         Day = wday(time, label = TRUE, abbr = FALSE))</code></pre>
<p>Now we’re ready to go!</p>
</div>
<div id="histograms" class="section level3">
<h3>Histograms</h3>
<p>We can first make a histogram of wind speed. We’ll use a bin width of 1 and color the edges of the bars white:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed)) +
  geom_histogram(binwidth = 1, color = &quot;white&quot;)</code></pre>
<p><img src="/example/05-example_files/figure-html/basic-histogram-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>This is fine enough, but we can improve it by forcing the buckets/bins to start at whole numbers instead of containing ranges like 2.5–3.5. We’ll use the <code>boundary</code> argument for that. We also add <code>scale_x_continuous()</code> to add our own x-axis breaks instead of having things like 2.5, 5, and 7.5:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed)) +
  geom_histogram(binwidth = 1, color = &quot;white&quot;, boundary = 1) +
  scale_x_continuous(breaks = seq(0, 12, by = 1))</code></pre>
<p><img src="/example/05-example_files/figure-html/basic-histogram-better-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can show the distribution of wind speed by month if we map the <code>Month</code> column we made onto the fill aesthetic:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
  geom_histogram(binwidth = 1, color = &quot;white&quot;, boundary = 1) +
  scale_x_continuous(breaks = seq(0, 12, by = 1))</code></pre>
<p><img src="/example/05-example_files/figure-html/histogram-by-month-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>This is colorful, but it’s impossible to actually interpret. Instead of only filling, we’ll also facet by month to see separate graphs for each month. We can turn off the fill legend because it’s now redundant.</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
  geom_histogram(binwidth = 1, color = &quot;white&quot;, boundary = 1) +
  scale_x_continuous(breaks = seq(0, 12, by = 1)) +
  guides(fill = FALSE) +
  facet_wrap(vars(Month))</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/histogram-by-month-facet-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Neat! January, March, and April appear to have the most variation in windy days, with a few wind-less days and a few very-windy days, while August was very wind-less.</p>
</div>
<div id="density-plots" class="section level3">
<h3>Density plots</h3>
<p>The code to create a density plot is nearly identical to what we used for the histogram—the only thing we change is the <code>geom</code> layer:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed)) +
  geom_density(color = &quot;grey20&quot;, fill = &quot;grey50&quot;)</code></pre>
<p><img src="/example/05-example_files/figure-html/basic-density-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>If we want, we can mess with some of the calculus options like the kernel and bandwidth:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed)) +
  geom_density(color = &quot;grey20&quot;, fill = &quot;grey50&quot;,
               bw = 0.1, kernel = &quot;epanechnikov&quot;)</code></pre>
<p><img src="/example/05-example_files/figure-html/density-kernel-bw-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can also fill by month. We’ll make the different layers 50% transparent so we can kind of see through the whole stack:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
  geom_density(alpha = 0.5)</code></pre>
<p><img src="/example/05-example_files/figure-html/density-fill-by-month-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Even with the transparency, this is really hard to interpret. We can fix this by faceting, like we did with the histograms:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
  geom_density(alpha = 0.5) +
  guides(fill = FALSE) +
  facet_wrap(vars(Month))</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/density-facet-by-month-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Or we can stack the density plots behind each other with <a href="https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html"><strong>ggridges</strong></a>. For that to work, we also need to map <code>Month</code> to the y-axis. We can reverse the y-axis so that January is at the top if we use the <code>fct_rev()</code> function:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed, y = fct_rev(Month), fill = Month)) +
  geom_density_ridges() +
  guides(fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/ggridges-basic-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can add some extra information to <code>geom_density_ridges()</code> with some other arguments like <code>quantile_lines</code>. We can use the <code>quantiles</code> argument to tell the plow how many parts to be cut into. Since we just want to show the median, we’ll set that to 2 so each density plot is divided in half:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = windSpeed, y = fct_rev(Month), fill = Month)) +
  geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +
  guides(fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/ggridges-quantile-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Now that we have good working code, we can easily substitute in other variables by changing the x mapping:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = temperatureHigh, y = fct_rev(Month), fill = Month)) +
  geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +
  guides(fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/ggridges-quantile-temp-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can get extra fancy if we fill by temperature instead of filling by month. To get this to work, we need to use <code>geom_density_ridges_gradient()</code>, and we need to change the <code>fill</code> mapping to the strange looking <code>..x..</code>, which is a weird ggplot trick that tells it to use the variable we mapped to the x-axis. For whatever reason, <code>fill = temperatureHigh</code> doesn’t work 🤷:</p>
<pre class="r"><code>ggplot(weather_atl, aes(x = temperatureHigh, y = fct_rev(Month), fill = ..x..)) +
  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +
  scale_fill_viridis_c(option = &quot;plasma&quot;) +
  labs(x = &quot;High temperature&quot;, y = NULL, color = &quot;Temp&quot;)</code></pre>
<p><img src="/example/05-example_files/figure-html/ggridges-gradient-temp-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>And finally, we can get <em>extra</em> fancy and show the distributions for both the high and low temperatures each month. To make this work, we need to manipulate the data a little. Right now there are two columns for high and low temperature: <code>temperatureLow</code> and <code>temperatureHigh</code>. To be able to map temperature to the x-axis and high vs. low to another aesthetic (like <code>linetype</code>), we need a column with the temperature and a column with an indicator variable for whether it is high or low. This data needs to be tidied (since right now we have a variable (high/low) encoded in the column name). We can tidy this data using <code>pivot_longer()</code> from <strong>tidyr</strong>, which was already loaded with <code>library(tidyverse)</code>. In the RStudio primers, you did this same thing with <code>gather()</code>—<code>pivot_longer()</code> is the newer version of <code>gather()</code>:</p>
<pre class="r"><code>weather_atl_long &lt;- weather_atl %&gt;%
  pivot_longer(cols = c(temperatureLow, temperatureHigh),
               names_to = &quot;temp_type&quot;,
               values_to = &quot;temp&quot;) %&gt;%
  # Clean up the new temp_type column so that &quot;temperatureHigh&quot; becomes &quot;High&quot;, etc.
  mutate(temp_type = recode(temp_type,
                            temperatureHigh = &quot;High&quot;,
                            temperatureLow = &quot;Low&quot;)) %&gt;%
  # This is optional—just select a handful of columns
  select(time, temp_type, temp, Month)

# Show the first few rows
head(weather_atl_long)</code></pre>
<pre><code>## # A tibble: 6 × 4
##   time                temp_type  temp Month  
##   &lt;dttm&gt;              &lt;chr&gt;     &lt;dbl&gt; &lt;ord&gt;  
## 1 2019-01-01 05:00:00 Low        50.6 January
## 2 2019-01-01 05:00:00 High       63.9 January
## 3 2019-01-02 05:00:00 Low        49.0 January
## 4 2019-01-02 05:00:00 High       57.4 January
## 5 2019-01-03 05:00:00 Low        53.1 January
## 6 2019-01-03 05:00:00 High       55.3 January</code></pre>
<p>Now we have a column for the temperature (<code>temp</code>) and a column indicating if it is high or low (<code>temp_type</code>). The dataset is also twice as long (730 rows) because each day has two rows (high and low). Let’s plot it and map high/low to the <code>linetype</code> aesthetic to show high/low in the border of the plots:</p>
<pre class="r"><code>ggplot(weather_atl_long, aes(x = temp, y = fct_rev(Month),
                             fill = ..x.., linetype = temp_type)) +
  geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +
  scale_fill_viridis_c(option = &quot;plasma&quot;) +
  labs(x = &quot;High temperature&quot;, y = NULL, color = &quot;Temp&quot;)</code></pre>
<p><img src="/example/05-example_files/figure-html/ggridges-gradient-temp-high-low-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can see much wider temperature disparities during the summer, with large gaps between high and low, and relatively equal high/low temperatures during the winter.</p>
</div>
<div id="box-violin-and-rain-cloud-plots" class="section level3">
<h3>Box, violin, and rain cloud plots</h3>
<p>Finally, we can look at the distribution of variables with box plots, violin plots, and other similar graphs. First, we’ll make a box plot of windspeed, filled by the <code>Day</code> variable we made indicating weekday:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(y = windSpeed, fill = Day)) +
  geom_boxplot()</code></pre>
<p><img src="/example/05-example_files/figure-html/basic-boxplot-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can switch this to a violin plot by just changing the <code>geom</code> layer and mapping <code>Day</code> to the x-axis:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(y = windSpeed, x = Day, fill = Day)) +
  geom_violin()</code></pre>
<p><img src="/example/05-example_files/figure-html/basic-violin-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>With violin plots it’s typically good to overlay other geoms. We can add some jittered points for a strip plot:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(y = windSpeed, x = Day, fill = Day)) +
  geom_violin() +
  geom_point(size = 0.5, position = position_jitter(width = 0.1)) +
  guides(fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/violin-strip-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can also add larger points for the daily averages. We’ll use a special layer for this: <code>stat_summary()</code>. It has a slightly different syntax, since we’re not actually mapping a column from the dataset. Instead, we’re feeding a column from a dataset into a function (here <code>"mean"</code>) and then plotting that result:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(y = windSpeed, x = Day, fill = Day)) +
  geom_violin() +
  stat_summary(geom = &quot;point&quot;, fun = &quot;mean&quot;, size = 5, color = &quot;white&quot;) +
  geom_point(size = 0.5, position = position_jitter(width = 0.1)) +
  guides(fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/violin-strip-mean-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>We can also show the mean and confidence interval at the same time by changing the summary function:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(y = windSpeed, x = Day, fill = Day)) +
  geom_violin() +
  stat_summary(geom = &quot;pointrange&quot;, fun.data = &quot;mean_se&quot;, size = 1, color = &quot;white&quot;) +
  geom_point(size = 0.5, position = position_jitter(width = 0.1)) +
  guides(fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/violin-strip-mean-ci-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Overlaying the points directly on top of the violins shows extra information, but it’s also really crowded and hard to read. If we use <a href="https://github.com/erocoar/gghalves">the <strong>gghalves</strong> package</a>, we can use special halved versions of some of these geoms like so:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(x = fct_rev(Day), y = temperatureHigh)) +
  geom_half_point(aes(color = Day), side = &quot;l&quot;, size = 0.5) +
  geom_half_boxplot(aes(fill = Day), side = &quot;r&quot;) +
  guides(color = FALSE, fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/gghalves-point-boxplot-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Note the <code>side</code> argument for specifying which half of the column the geom goes. We can also use <code>geom_half_violin()</code>:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(x = fct_rev(Day), y = temperatureHigh)) +
  geom_half_point(aes(color = Day), side = &quot;l&quot;, size = 0.5) +
  geom_half_violin(aes(fill = Day), side = &quot;r&quot;) +
  guides(color = FALSE, fill = FALSE)</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/gghalves-point-violon-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>If we flip the plot, we can make a <a href="https://micahallen.org/2018/03/15/introducing-raincloud-plots/">rain cloud plot</a>:</p>
<pre class="r"><code>ggplot(weather_atl,
       aes(x = fct_rev(Day), y = temperatureHigh)) +
  geom_half_boxplot(aes(fill = Day), side = &quot;l&quot;, width = 0.5, nudge = 0.1) +
  geom_half_point(aes(color = Day), side = &quot;l&quot;, size = 0.5) +
  geom_half_violin(aes(fill = Day), side = &quot;r&quot;) +
  guides(color = FALSE, fill = FALSE) +
  coord_flip()</code></pre>
<pre><code>## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; =
## &quot;none&quot;)` instead.</code></pre>
<p><img src="/example/05-example_files/figure-html/gghalves-rain-cloud-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="http://www.realclearpolitics.com" class="uri">http://www.realclearpolitics.com</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="http://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html" class="uri">http://www.realclearpolitics.com/epolls/2016/president/us/general_election_trump_vs_clinton-5491.html</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

                    </div>

                    



                    
                </div>

                <div class="body-footer">
                    <p>Last updated on October 19, 2021</p>

                    


                    

                </div>

            </article>

            <footer>
    <hr>

    <div class="row course-info">
        <div class="col-md-7">
            <p>
                <strong>SSC 442: Data Analytics (Fall Semester 2021)</strong><br>

                <a href="https://www.msu.edu" target="_blank" rel="noopener">Michigan State University</a> &emsp;&emsp;
                <a href="https://socialscience.msu.edu/" target="_blank" rel="noopener">College of Social Science</a>
            </p>

            <p>
                <a href="https://www.benbushong.com" target="_blank" rel="noopener"><i class="fas fa-user"></i>
                    Prof. Ben Bushong</a> &emsp;&emsp;
                <a href="mailto:bbushong@msu.edu"><i class="fas fa-envelope"></i>
                    bbushong@msu.edu</a>
            </p>

            <p>
                <i class="far fa-calendar-alt"></i> Tuesday and Thursday &emsp;&emsp;
                <i class="far fa-clock"></i> 12:40pm - 2:00pm 
                
            </p>
        </div>

        <div class="col-md-5 credits">
            <p>All content licensed under a <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank" rel="noopener">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>.</p>
            
            <p>Content <i class="fab fa-creative-commons"></i> 2021 <a href="https://www.benbushong.com" target="_blank" rel="noopener"></a></p>
        
            <p>This site created with the <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> in <a href="https://bookdown.org/yihui/blogdown/" target="_blank" rel="noopener">blogdown</a> and <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>. </p>
            
            <p><a href="https://github.com/" target="_blank" rel="noopener"><i class="fab fa-github"></i> View the source at GitHub.</a></p>
        </div>
    </div>
</footer>


        </main>
    </div>
</div>

        

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    

    
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.6f7ce8be710290b8c431bbc97f405d15.js"></script>

    



    
    

    
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>

</html>
