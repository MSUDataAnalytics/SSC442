<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Assignments and Evaluations | Data Analytics</title>
    <link>/assignment/</link>
      <atom:link href="/assignment/index.xml" rel="self" type="application/rss+xml" />
    <description>Assignments and Evaluations</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <image>
      <url>/img/social-image.png</url>
      <title>Assignments and Evaluations</title>
      <link>/assignment/</link>
    </image>
    
    <item>
      <title>Programming Basics in R</title>
      <link>/assignment/00-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/assignment/00-assignment/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#programming-basics&#34;&gt;Programming basics&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#conditionals&#34;&gt;Conditional expressions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#defining-functions&#34;&gt;Defining functions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#namespaces&#34;&gt;Namespaces&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#for-loops&#34;&gt;For-loops&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#vectorization&#34;&gt;Vectorization and functionals&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This lab is not due for credit. Nevertheless, if you do not have a &lt;em&gt;firm&lt;/em&gt; grasp of &lt;code&gt;R&lt;/code&gt;, you should work through both the entirety of this section and the exercises at the end. There are a number of tricks that will come up over and over.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;programming-basics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Programming basics&lt;/h1&gt;
&lt;p&gt;We teach &lt;code&gt;R&lt;/code&gt; because it greatly facilitates data analysis, the main topic of this book. By coding in R, we can efficiently perform exploratory data analysis, build data analysis pipelines, and prepare data visualization to communicate results. However, &lt;code&gt;R&lt;/code&gt; is not just a data analysis environment but a programming language. Advanced &lt;code&gt;R&lt;/code&gt; programmers can develop complex packages and even improve &lt;code&gt;R&lt;/code&gt; itself, but we do not cover advanced programming in this book. Nonetheless, in this section, we introduce three key programming concepts: conditional expressions, for-loops, and functions. These are not just key building blocks for advanced programming, but are sometimes useful during data analysis. We also note that there are several functions that are widely used to program in &lt;code&gt;R&lt;/code&gt; but that we will not cover in this book. These include &lt;code&gt;split&lt;/code&gt;, &lt;code&gt;cut&lt;/code&gt;, &lt;code&gt;do.call&lt;/code&gt;, and &lt;code&gt;Reduce&lt;/code&gt;, as well as the &lt;strong&gt;data.table&lt;/strong&gt; package. These are worth learning if you plan to become an expert &lt;code&gt;R&lt;/code&gt; programmer.&lt;/p&gt;
&lt;div id=&#34;conditionals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conditional expressions&lt;/h2&gt;
&lt;p&gt;Conditional expressions are one of the basic features of programming. They are used for what is called &lt;em&gt;flow control&lt;/em&gt;. The most common conditional expression is the if-else statement. In R, we can actually perform quite a bit of data analysis without conditionals. However, they do come up occasionally, and you will need them once you start writing your own functions and packages.&lt;/p&gt;
&lt;p&gt;Here is a very simple example showing the general structure of an if-else statement. The basic idea is to print the reciprocal of &lt;code&gt;a&lt;/code&gt; unless &lt;code&gt;a&lt;/code&gt; is 0:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 0

if(a!=0){
  print(1/a)
} else{
  print(&amp;quot;No reciprocal for 0.&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;No reciprocal for 0.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s look at one more example using the US murders data frame:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dslabs)
data(murders)
murder_rate &amp;lt;- murders$total / murders$population*100000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a very simple example that tells us which states, if any, have a murder rate lower than 0.5 per 100,000. The &lt;code&gt;if&lt;/code&gt; statement protects us from the case in which no state satisfies the condition.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ind &amp;lt;- which.min(murder_rate)

if(murder_rate[ind] &amp;lt; 0.5){
  print(murders$state[ind])
} else{
  print(&amp;quot;No state has murder rate that low&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;Vermont&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we try it again with a rate of 0.25, we get a different answer:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;if(murder_rate[ind] &amp;lt; 0.25){
  print(murders$state[ind])
} else{
  print(&amp;quot;No state has a murder rate that low.&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;No state has a murder rate that low.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A related function that is very useful is &lt;code&gt;ifelse&lt;/code&gt;. This function takes three arguments: a logical and two possible answers. If the logical is &lt;code&gt;TRUE&lt;/code&gt;, the value in the second argument is returned and if &lt;code&gt;FALSE&lt;/code&gt;, the value in the third argument is returned. Here is an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- 0
ifelse(a &amp;gt; 0, 1/a, NA)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The function is particularly useful because it works on vectors. It examines each entry of the logical vector and returns elements from the vector provided in the second argument, if the entry is &lt;code&gt;TRUE&lt;/code&gt;, or elements from the vector provided in the third argument, if the entry is &lt;code&gt;FALSE&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;a &amp;lt;- c(0, 1, 2, -4, 5)
result &amp;lt;- ifelse(a &amp;gt; 0, 1/a, NA)&lt;/code&gt;&lt;/pre&gt;
This table helps us see what happened:
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
a
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
is_a_positive
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
answer1
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
answer2
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
result
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
Inf
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.00
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1.0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.50
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
FALSE
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
-0.25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
TRUE
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.20
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
0.2
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Here is an example of how this function can be readily used to replace all the missing values in a vector with zeros:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(na_example)
no_nas &amp;lt;- ifelse(is.na(na_example), 0, na_example)
sum(is.na(no_nas))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Two other useful functions are &lt;code&gt;any&lt;/code&gt; and &lt;code&gt;all&lt;/code&gt;. The &lt;code&gt;any&lt;/code&gt; function takes a vector of logicals and returns &lt;code&gt;TRUE&lt;/code&gt; if any of the entries is &lt;code&gt;TRUE&lt;/code&gt;. The &lt;code&gt;all&lt;/code&gt; function takes a vector of logicals and returns &lt;code&gt;TRUE&lt;/code&gt; if all of the entries are &lt;code&gt;TRUE&lt;/code&gt;. Here is an example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;z &amp;lt;- c(TRUE, TRUE, FALSE)
any(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;all(z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] FALSE&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;defining-functions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Defining functions&lt;/h2&gt;
&lt;p&gt;As you become more experienced, you will find yourself needing to perform the same operations over and over. A simple example is computing averages. We can compute the average of a vector &lt;code&gt;x&lt;/code&gt; using the &lt;code&gt;sum&lt;/code&gt; and &lt;code&gt;length&lt;/code&gt; functions: &lt;code&gt;sum(x)/length(x)&lt;/code&gt;. Because we do this repeatedly, it is much more efficient to write a function that performs this operation. This particular operation is so common that someone already wrote the &lt;code&gt;mean&lt;/code&gt; function and it is included in base R. However, you will encounter situations in which the function does not already exist, so &lt;code&gt;R&lt;/code&gt; permits you to write your own. A simple version of a function that computes the average can be defined like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avg &amp;lt;- function(x){
  s &amp;lt;- sum(x)
  n &amp;lt;- length(x)
  s/n
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now &lt;code&gt;avg&lt;/code&gt; is a function that computes the mean:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1:100
identical(mean(x), avg(x))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] TRUE&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that variables defined inside a function are not saved in the workspace. So while we use &lt;code&gt;s&lt;/code&gt; and &lt;code&gt;n&lt;/code&gt; when we call &lt;code&gt;avg&lt;/code&gt;, the values are created and changed only during the call. Here is an illustrative example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- 3
avg(1:10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 3&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how &lt;code&gt;s&lt;/code&gt; is still 3 after we call &lt;code&gt;avg&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;In general, functions are objects, so we assign them to variable names with &lt;code&gt;&amp;lt;-&lt;/code&gt;. The function &lt;code&gt;function&lt;/code&gt; tells &lt;code&gt;R&lt;/code&gt; you are about to define a function. The general form of a function definition looks like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;my_function &amp;lt;- function(VARIABLE_NAME){
  perform operations on VARIABLE_NAME and calculate VALUE
  VALUE
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The functions you define can have multiple arguments as well as default values. For example, we can define a function that computes either the arithmetic or geometric average depending on a user defined variable like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avg &amp;lt;- function(x, arithmetic = TRUE){
  n &amp;lt;- length(x)
  ifelse(arithmetic, sum(x)/n, prod(x)^(1/n))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We will learn more about how to create functions through experience as we face more complex tasks.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;namespaces&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Namespaces&lt;/h2&gt;
&lt;p&gt;Once you start becoming more of an &lt;code&gt;R&lt;/code&gt; expert user, you will likely need to load several add-on packages for some of your analysis. Once you start doing this, it is likely that two packages use the same name for two different functions. And often these functions do completely different things. In fact, you have already encountered this because both &lt;strong&gt;dplyr&lt;/strong&gt; and the R-base &lt;strong&gt;stats&lt;/strong&gt; package define a &lt;code&gt;filter&lt;/code&gt; function. There are five other examples in &lt;strong&gt;dplyr&lt;/strong&gt;. We know this because when we first load &lt;strong&gt;dplyr&lt;/strong&gt; we see the following message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So what does &lt;code&gt;R&lt;/code&gt; do when we type &lt;code&gt;filter&lt;/code&gt;? Does it use the &lt;strong&gt;dplyr&lt;/strong&gt; function or the &lt;strong&gt;stats&lt;/strong&gt; function? From our previous work we know it uses the &lt;strong&gt;dplyr&lt;/strong&gt; one. But what if we want to use the &lt;strong&gt;stats&lt;/strong&gt; version?&lt;/p&gt;
&lt;p&gt;These functions live in different &lt;em&gt;namespaces&lt;/em&gt;. &lt;code&gt;R&lt;/code&gt; will follow a certain order when searching for a function in these &lt;em&gt;namespaces&lt;/em&gt;. You can see the order by typing:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;search()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first entry in this list is the global environment which includes all the objects you define.&lt;/p&gt;
&lt;p&gt;So what if we want to use the &lt;strong&gt;stats&lt;/strong&gt; &lt;code&gt;filter&lt;/code&gt; instead of the &lt;strong&gt;dplyr&lt;/strong&gt; filter but &lt;strong&gt;dplyr&lt;/strong&gt; appears first in the search list? You can force the use of a specific namespace by using double colons (&lt;code&gt;::&lt;/code&gt;) like this:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;stats::filter&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to be absolutely sure that we use the &lt;strong&gt;dplyr&lt;/strong&gt; &lt;code&gt;filter&lt;/code&gt;, we can use&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dplyr::filter&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also note that if we want to use a function in a package without loading the entire package, we can use the double colon as well.&lt;/p&gt;
&lt;p&gt;For more on this more advanced topic we recommend the &lt;code&gt;R&lt;/code&gt; packages book&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;for-loops&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;For-loops&lt;/h2&gt;
&lt;p&gt;If we had to write this section in a single sentence, it would be: Don’t use for-loops. Looping is intuitive, but &lt;code&gt;R&lt;/code&gt; is designed to provide more computationally efficient solutions. For-loops should be considered a quick-and-dirty way to get an answer. But, hey, you live your own life. Below we provide a brief overview to for-looping.&lt;/p&gt;
&lt;p&gt;The formula for the sum of the series &lt;span class=&#34;math inline&#34;&gt;\(1+2+\dots+n\)&lt;/span&gt; is &lt;span class=&#34;math inline&#34;&gt;\(n(n+1)/2\)&lt;/span&gt;. What if we weren’t sure that was the right function? How could we check? Using what we learned about functions we can create one that computes the &lt;span class=&#34;math inline&#34;&gt;\(S_n\)&lt;/span&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;compute_s_n &amp;lt;- function(n){
  x &amp;lt;- 1:n
  sum(x)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;How can we compute &lt;span class=&#34;math inline&#34;&gt;\(S_n\)&lt;/span&gt; for various values of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, say &lt;span class=&#34;math inline&#34;&gt;\(n=1,\dots,25\)&lt;/span&gt;? Do we write 25 lines of code calling &lt;code&gt;compute_s_n&lt;/code&gt;? No, that is what for-loops are for in programming. In this case, we are performing exactly the same task over and over, and the only thing that is changing is the value of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. For-loops let us define the range that our variable takes (in our example &lt;span class=&#34;math inline&#34;&gt;\(n=1,\dots,10\)&lt;/span&gt;), then change the value and evaluate expression as you &lt;em&gt;loop&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Perhaps the simplest example of a for-loop is this useless piece of code:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;for(i in 1:5){
  print(i)
}&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1
## [1] 2
## [1] 3
## [1] 4
## [1] 5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the for-loop we would write for our &lt;span class=&#34;math inline&#34;&gt;\(S_n\)&lt;/span&gt; example:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- 25
s_n &amp;lt;- vector(length = m) # create an empty vector
for(n in 1:m){
  s_n[n] &amp;lt;- compute_s_n(n)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In each iteration &lt;span class=&#34;math inline&#34;&gt;\(n=1\)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(n=2\)&lt;/span&gt;, etc…, we compute &lt;span class=&#34;math inline&#34;&gt;\(S_n\)&lt;/span&gt; and store it in the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;th entry of &lt;code&gt;s_n&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now we can create a plot to search for a pattern:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1:m
plot(n, s_n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/00-assignment_files/figure-html/sum-of-consecutive-squares-1.png&#34; width=&#34;50%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If you noticed that it appears to be a quadratic, you are on the right track because the formula is &lt;span class=&#34;math inline&#34;&gt;\(n(n+1)/2\)&lt;/span&gt;.
&lt;!--
which we can confirm with a table:


```r
head(data.frame(s_n = s_n, formula = n*(n+1)/2))
```

```
##   s_n formula
## 1   1       1
## 2   3       3
## 3   6       6
## 4  10      10
## 5  15      15
## 6  21      21
```

We can also overlay the two results by using the function `lines` to draw a line over the previously plotted points:


```r
plot(n, s_n)
lines(n, n*(n+1)/2)
```

&lt;img src=&#34;/assignment/00-assignment_files/figure-html/s_n-v-n-1.png&#34; width=&#34;672&#34; /&gt;

--&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vectorization&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vectorization and functionals&lt;/h2&gt;
&lt;p&gt;Although for-loops are an important concept to understand, in &lt;code&gt;R&lt;/code&gt; we rarely use them. As you learn more &lt;code&gt;R&lt;/code&gt;, you will realize that &lt;em&gt;vectorization&lt;/em&gt; is preferred over for-loops since it results in shorter and clearer code. (It’s also vastly more efficient computationally, which can matter as your data grows.) A &lt;em&gt;vectorized&lt;/em&gt; function is a function that will apply the same operation on each of the vectors.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1:10
sqrt(x)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427
##  [9] 3.000000 3.162278&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y &amp;lt;- 1:10
x*y&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1]   1   4   9  16  25  36  49  64  81 100&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make this calculation, there is no need for for-loops. However, not all functions work this way. For instance, the function we just wrote, &lt;code&gt;compute_s_n&lt;/code&gt;, does not work element-wise since it is expecting a scalar. This piece of code does not run the function on each entry of &lt;code&gt;n&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1:25
compute_s_n(n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Functionals&lt;/em&gt; are functions that help us apply the same function to each entry in a vector, matrix, data frame, or list. Here we cover the functional that operates on numeric, logical, and character vectors: &lt;code&gt;sapply&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The function &lt;code&gt;sapply&lt;/code&gt; permits us to perform element-wise operations on any function. Here is how it works:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1:10
sapply(x, sqrt)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427
##  [9] 3.000000 3.162278&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each element of &lt;code&gt;x&lt;/code&gt; is passed on to the function &lt;code&gt;sqrt&lt;/code&gt; and the result is returned. These results are concatenated. In this case, the result is a vector of the same length as the original &lt;code&gt;x&lt;/code&gt;. This implies that the for-loop above can be written as follows:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 1:25
s_n &amp;lt;- sapply(n, compute_s_n)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Other functionals are &lt;code&gt;apply&lt;/code&gt;, &lt;code&gt;lapply&lt;/code&gt;, &lt;code&gt;tapply&lt;/code&gt;, &lt;code&gt;mapply&lt;/code&gt;, &lt;code&gt;vapply&lt;/code&gt;, and &lt;code&gt;replicate&lt;/code&gt;. We mostly use &lt;code&gt;sapply&lt;/code&gt;, &lt;code&gt;apply&lt;/code&gt;, and &lt;code&gt;replicate&lt;/code&gt; in this book, but we recommend familiarizing yourselves with the others as they can be very useful.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;EXERCISES&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;What will this conditional expression return?&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- c(1,2,-3,4)

if(all(x&amp;gt;0)){
  print(&amp;quot;All Postives&amp;quot;)
} else{
  print(&amp;quot;Not all positives&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Which of the following expressions is always &lt;code&gt;FALSE&lt;/code&gt; when at least one entry of a logical vector &lt;code&gt;x&lt;/code&gt; is TRUE?&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;&lt;code&gt;all(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;any(x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;any(!x)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;all(!x)&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;The function &lt;code&gt;nchar&lt;/code&gt; tells you how many characters long a character vector is. Write a line of code that assigns to the object &lt;code&gt;new_names&lt;/code&gt; the state abbreviation when the state name is longer than 8 characters.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a function &lt;code&gt;sum_n&lt;/code&gt; that for any given value, say &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;, computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5,000.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Create a function &lt;code&gt;altman_plot&lt;/code&gt; that takes two arguments, &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, and plots the difference against the sum.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;After running the code below, what is the value of &lt;code&gt;x&lt;/code&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 3
my_func &amp;lt;- function(y){
  x &amp;lt;- 5
  y+5
}&lt;/code&gt;&lt;/pre&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Write a function &lt;code&gt;compute_s_n&lt;/code&gt; that for any given &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; computes the sum &lt;span class=&#34;math inline&#34;&gt;\(S_n = 1^2 + 2^2 + 3^2 + \dots n^2\)&lt;/span&gt;. Report the value of the sum when &lt;span class=&#34;math inline&#34;&gt;\(n=10\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Define an empty numerical vector &lt;code&gt;s_n&lt;/code&gt; of size 25 using &lt;code&gt;s_n &amp;lt;- vector(&#34;numeric&#34;, 25)&lt;/code&gt; and store in the results of &lt;span class=&#34;math inline&#34;&gt;\(S_1, S_2, \dots S_{25}\)&lt;/span&gt; using a for-loop.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Repeat exercise 8, but this time use &lt;code&gt;sapply&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Repeat exercise 8, but this time use &lt;code&gt;map_dbl&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Plot &lt;span class=&#34;math inline&#34;&gt;\(S_n\)&lt;/span&gt; versus &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. Use points defined by &lt;span class=&#34;math inline&#34;&gt;\(n=1,\dots,25\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Confirm that the formula for this sum is &lt;span class=&#34;math inline&#34;&gt;\(S_n= n(n+1)(2n+1)/6\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;http://r-pkgs.had.co.nz/namespace.html&#34; class=&#34;uri&#34;&gt;http://r-pkgs.had.co.nz/namespace.html&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Basics of ggplot</title>
      <link>/assignment/01-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/assignment/01-assignment/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#using-ggplot2&#34;&gt;Using ggplot2&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-use-ggplot2-the-too-fast-and-wholly-unclear-recipe&#34;&gt;How to use &lt;code&gt;ggplot2&lt;/code&gt; – the too-fast and wholly unclear recipe&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mappings-link-data-to-things-you-see&#34;&gt;Mappings Link Data to Things You See&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-recipe&#34;&gt;The Recipe&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#mapping-aesthetics-vs-setting-them&#34;&gt;Mapping Aesthetics vs Setting them&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You must turn in a PDF document of your &lt;code&gt;R markdown&lt;/code&gt; code. Submit this to D2L by 11:59 PM on Monday.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Our primary tool for data visualization in the course will be &lt;code&gt;ggplot&lt;/code&gt;. Technically, we’re using &lt;code&gt;ggplot2&lt;/code&gt;; the o.g. version lacked some of the modern features of its big brother. &lt;code&gt;ggplot2&lt;/code&gt; implements the grammar of graphics, a coherent and relatively straightforward system for describing and building graphs. With &lt;code&gt;ggplot2&lt;/code&gt;, you can do more faster by learning one system and applying it in many places. Other languages provide more specific tools, but require you to learn a different tool for each application. In this class, we’ll dig into a single package for our visuals.&lt;/p&gt;
&lt;div id=&#34;using-ggplot2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using ggplot2&lt;/h2&gt;
&lt;p&gt;In order to get our hands dirty, we will first have to load &lt;code&gt;ggplot2&lt;/code&gt;. To do this, and to access the datasets, help pages, and functions that we will use in this assignment, we will load the so-called tidyverse by running this code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you run this code and get an error message “there is no package called ‘tidyverse’”, you’ll need to first install it, then run library() once again. To install packages in &lt;code&gt;R&lt;/code&gt;, we utilize the simple function install.packages(). In this case, we would write:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;install.packages(&amp;quot;tidyverse&amp;quot;)
library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we’re up and running, we’re ready to dive into some basic exercises. &lt;code&gt;ggplot2&lt;/code&gt; works by specifying the connections between the variables in the data and the colors, points, and shapes you see on the screen. These logical connections are called &lt;em&gt;aesthetic mappings&lt;/em&gt; or simply &lt;em&gt;aesthetics&lt;/em&gt;.&lt;/p&gt;
&lt;div id=&#34;how-to-use-ggplot2-the-too-fast-and-wholly-unclear-recipe&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How to use &lt;code&gt;ggplot2&lt;/code&gt; – the too-fast and wholly unclear recipe&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;data =&lt;/code&gt;: Define what your data is. For instance, below we’ll use the mpg data frame found in ggplot2 (by using &lt;code&gt;ggplot2::mpg&lt;/code&gt;). As a reminder, a data frame is a rectangular collection of variables (in the columns) and observations (in the rows). This structure of data is often called a “table” but we’ll try to use terms slightly more precisely. The &lt;code&gt;mpg&lt;/code&gt; data frame contains observations collected by the US Environmental Protection Agency on 38 different models of car.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mapping = aes(...)&lt;/code&gt;: How to map the variables in the data to aesthetics&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Axes, size of points, intensities of colors, which colors, shape of points, lines/points&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Then say what type of plot you want:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;boxplot, scatterplot, histogram, …&lt;/li&gt;
&lt;li&gt;these are called ‘geoms’ in ggplot’s grammar, such as &lt;code&gt;geom_point()&lt;/code&gt; giving scatter plots&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code&gt;library(ggplot2)
... + geom_point() # Produces scatterplots
... + geom_bar() # Bar plots
.... + geom_boxplot() # boxplots
... #&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You link these steps by &lt;em&gt;literally&lt;/em&gt; adding them together with &lt;code&gt;+&lt;/code&gt; as we’ll see.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; What other types of plots are there? Try to find several more &lt;code&gt;geom_&lt;/code&gt; functions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mappings-link-data-to-things-you-see&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mappings Link Data to Things You See&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(gapminder)
library(ggplot2)
gapminder&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1,704 x 6
##    country     continent  year lifeExp      pop gdpPercap
##    &amp;lt;fct&amp;gt;       &amp;lt;fct&amp;gt;     &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;int&amp;gt;     &amp;lt;dbl&amp;gt;
##  1 Afghanistan Asia       1952    28.8  8425333      779.
##  2 Afghanistan Asia       1957    30.3  9240934      821.
##  3 Afghanistan Asia       1962    32.0 10267083      853.
##  4 Afghanistan Asia       1967    34.0 11537966      836.
##  5 Afghanistan Asia       1972    36.1 13079460      740.
##  6 Afghanistan Asia       1977    38.4 14880372      786.
##  7 Afghanistan Asia       1982    39.9 12881816      978.
##  8 Afghanistan Asia       1987    40.8 13867957      852.
##  9 Afghanistan Asia       1992    41.7 16317921      649.
## 10 Afghanistan Asia       1997    41.8 22227415      635.
## # … with 1,694 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/01-assignment_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Above we’ve loaded a different dataset and have started to explore a particular relationship. Before putting in this code yourself, try to intuit what &lt;em&gt;might&lt;/em&gt; be going on.&lt;/p&gt;
&lt;p&gt;Any ideas?&lt;/p&gt;
&lt;p&gt;Here’s a breakdown of everything that happens after the &lt;code&gt;p&amp;lt;- ggplot()&lt;/code&gt; call:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data = gapminder&lt;/code&gt; tells ggplot to use gapminder dataset, so if variable names are mentioned, they should be looked up in gapminder&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mapping = aes(...)&lt;/code&gt; shows that the mapping is a function call. There is a deeper logic to this that I will disucss below, but it’s easiest to simply accept that this is how you write it. Put another way, the &lt;code&gt;mapping = aes(...)&lt;/code&gt; argument &lt;em&gt;links variables&lt;/em&gt; to &lt;em&gt;things you will see&lt;/em&gt; on the plot.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aes(x = gdpPercap, y = lifeExp)&lt;/code&gt; maps the GDP data onto &lt;code&gt;x&lt;/code&gt;, which is a known aesthetic (the x-coordinate) and life expectancy data onto &lt;code&gt;x&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are predefined names that are used by &lt;code&gt;ggplot&lt;/code&gt; and friends&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let’s return to the &lt;code&gt;mpg&lt;/code&gt; data. Among the variables in &lt;code&gt;mpg&lt;/code&gt; are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;displ&lt;/code&gt;, a car’s engine size, in litres.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;hwy&lt;/code&gt;, a car’s fuel efficiency on the highway, in miles per gallon (mpg). A car with a low fuel efficiency consumes more fuel than a car with a high fuel efficiency when they travel the same distance.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generate a scatterplot between these two variables. Does it capture the intuitive relationship you expected? What happens if you make a scatterplot of &lt;code&gt;class&lt;/code&gt; vs &lt;code&gt;drv&lt;/code&gt;? Why is the plot not useful?&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;It turns out there’s a reason for doing all of this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“The greatest value of a picture is when it forces us to notice what we never expected to see.”&#34; — John Tukey&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In the plot you made above, one group of points seems to fall outside of the linear trend. These cars have a higher mileage than you might expect. How can you explain these cars?&lt;/p&gt;
&lt;p&gt;Let’s hypothesize that the cars are hybrids. One way to test this hypothesis is to look at the class value for each car. The &lt;code&gt;class&lt;/code&gt; variable of the &lt;code&gt;mpg&lt;/code&gt; dataset classifies cars into groups such as compact, midsize, and SUV. If the outlying points are hybrids, they should be classified as compact cars or, perhaps, subcompact cars (keep in mind that this data was collected before hybrid trucks and SUVs became popular).&lt;/p&gt;
&lt;p&gt;You can add a third variable, like &lt;code&gt;class&lt;/code&gt;, to a two dimensional scatterplot by mapping it to an aesthetic. An aesthetic is a visual property of the objects in your plot. Aesthetics include things like the size, the shape, or the color of your points. You can display a point (like the one below) in different ways by changing the values of its aesthetic properties. Since we already use the word “&lt;strong&gt;value&lt;/strong&gt;” to describe data, let’s use the word “&lt;strong&gt;level&lt;/strong&gt;” to describe aesthetic properties. Thus, we are interested in exploring &lt;code&gt;class&lt;/code&gt; as a level.&lt;/p&gt;
&lt;p&gt;You can convey information about your data by mapping the aesthetics in your plot to the variables in your dataset. For example, you can map the colors of your points to the class variable to reveal the class of each car. To map an aesthetic to a variable, associate the name of the aesthetic to the name of the variable inside &lt;code&gt;aes()&lt;/code&gt;. &lt;code&gt;ggplot2&lt;/code&gt; will automatically assign a unique level of the aesthetic (here a unique color) to each unique value of the variable, a process known as scaling. &lt;code&gt;ggplot2&lt;/code&gt; will also add a legend that explains which levels correspond to which values.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise 2:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using your previous scatterplot of &lt;code&gt;displ&lt;/code&gt; and &lt;code&gt;hwy&lt;/code&gt;, map the colors of your points to the class variable to reveal the class of each car. What conclusions can we make?&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let’s explore our previously saved &lt;code&gt;p&lt;/code&gt; in greater detail. As with Exercise 1, we’ll add a &lt;em&gt;layer&lt;/em&gt;. This says how some data gets turned into concrete visual aspects.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p + geom_point()
p + geom_smooth()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Both of the above geom’s use the same mapping, where the x-axis represents &lt;code&gt;gdpPercap&lt;/code&gt; and the y-axis represents &lt;code&gt;lifeExp&lt;/code&gt;. You can find this yourself with some ease. But the first one maps the data to individual points, the other one maps it to a smooth line with error ranges.&lt;/p&gt;
&lt;p&gt;We get a message that tells us that &lt;code&gt;geom_smooth()&lt;/code&gt; is using the method = ‘gam’, so presumably we can use other methods. Let’s see if we can figure out which other methods there are.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;?geom_smooth
p + geom_point() + geom_smooth() + geom_smooth(method = ...) + geom_smooth(method = ...)
p + geom_point() + geom_smooth() + geom_smooth(method = ...) + geom_smooth(method = ..., color = &amp;quot;red&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may start to see why &lt;code&gt;ggplot2&lt;/code&gt;’s way of breaking up tasks is quite powerful: the geometric objects can all reuse the &lt;em&gt;same&lt;/em&gt; mapping of data to aesthetics, yet the results are quite different. And if we want later geoms to use different mappings, then we can override them – but it isn’t necessary.&lt;/p&gt;
&lt;p&gt;Consider the output we’ve explored thus far. One potential issue lurking in the data is that most of it is bunched to the left. If we instead used a logarithmic scale, we should be able to spread the data out better.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p + geom_point() + geom_smooth(method = &amp;quot;lm&amp;quot;) + scale_x_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Describe what the &lt;code&gt;scale_x_log10()&lt;/code&gt; does. Why is it a more evenly distributed cloud of points now? (2-3 sentences.)&lt;/p&gt;
&lt;p&gt;Nice. We’re starting to get somewhere. But, you might notice that the x-axis now has scientific notation. Let’s change that.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(scales)
p + geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  scale_x_log10(labels = scales::dollar)
p + geom_point() +
  geom_smooth(method = &amp;quot;lm&amp;quot;) +
  scale_x_log10(labels = scales::...)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; What does the &lt;code&gt;dollar()&lt;/code&gt; call do? How can you find other ways of relabeling the scales when using &lt;code&gt;scale_x_log10()&lt;/code&gt;?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;?dollar()&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-recipe&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Recipe&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Tell the &lt;code&gt;ggplot()&lt;/code&gt; function what our data is.&lt;/li&gt;
&lt;li&gt;Tell &lt;code&gt;ggplot()&lt;/code&gt; &lt;em&gt;what&lt;/em&gt; relationships we want to see. For convenience we will put the results of the first two steps in an object called &lt;code&gt;p&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Tell &lt;code&gt;ggplot&lt;/code&gt; &lt;em&gt;how&lt;/em&gt; we want to see the relationships in our data.&lt;/li&gt;
&lt;li&gt;Layer on geoms as needed, by adding them on the &lt;code&gt;p&lt;/code&gt; object one at a time.&lt;/li&gt;
&lt;li&gt;Use some additional functions to adjust scales, labels, tickmarks, titles.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;e.g. &lt;code&gt;scale_&lt;/code&gt;, &lt;code&gt;labs()&lt;/code&gt;, and &lt;code&gt;guides()&lt;/code&gt; functions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As you start to run more &lt;code&gt;R&lt;/code&gt; code, you’re likely to run into problems. Don’t worry — it happens to everyone. I have been writing code in numerous languages for years, and every day I still write code that doesn’t work. Sadly, &lt;code&gt;R&lt;/code&gt; is particularly persnickity, and its error messages are often opaque.&lt;/p&gt;
&lt;p&gt;Start by carefully comparing the code that you’re running to the code in these notes. &lt;code&gt;R&lt;/code&gt; is extremely picky, and a misplaced character can make all the difference. Make sure that every ( is matched with a ) and every &#34; is paired with another &#34;. Sometimes you’ll run the code and nothing happens. Check the left-hand of your console: if it’s a +, it means that R doesn’t think you’ve typed a complete expression and it’s waiting for you to finish it. In this case, it’s usually easy to start from scratch again by pressing ESCAPE to abort processing the current command.&lt;/p&gt;
&lt;p&gt;One common problem when creating ggplot2 graphics is to put the + in the wrong place: it has to come at the end of the line, not the start.&lt;/p&gt;
&lt;div id=&#34;mapping-aesthetics-vs-setting-them&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Mapping Aesthetics vs Setting them&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp, color = &amp;#39;yellow&amp;#39;))
p + geom_point() + scale_x_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is interesting (or annoying): the points are not yellow. How can we tell ggplot to draw yellow points?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp, ...))
p + geom_point(...) + scale_x_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; describe in your words what is going on.
One way to avoid such mistakes is to read arguments inside &lt;code&gt;aes(&amp;lt;property&amp;gt; = &amp;lt;variable&amp;gt;)&lt;/code&gt;as &lt;em&gt;the property &lt;property&gt; in the graph is determined by the data in &lt;variable&gt;&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Write the above sentence for the original call &lt;code&gt;aes(x = gdpPercap, y = lifeExp, color = &#39;yellow&#39;)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Aesthetics convey information about a variable in the dataset, whereas setting the color of all points to yellow conveys no information about the dataset - it changes the appearance of the plot in a way that is independent of the underlying data.&lt;/p&gt;
&lt;p&gt;Remember: &lt;code&gt;color = &#39;yellow&#39;&lt;/code&gt; and &lt;code&gt;aes(color = &#39;yellow&#39;)&lt;/code&gt; are very different, and the second makes usually no sense, as &lt;code&gt;&#39;yellow&#39;&lt;/code&gt; is treated as &lt;em&gt;data&lt;/em&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point() + geom_smooth(color = &amp;quot;orange&amp;quot;, se = FALSE, size = 8, method = &amp;quot;lm&amp;quot;) + scale_x_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Write down what all those arguments in &lt;code&gt;geom_smooth(...)&lt;/code&gt; do.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p + geom_point(alpha = 0.3) +
  geom_smooth(method = &amp;quot;gam&amp;quot;) +
  scale_x_log10(labels = scales::dollar) +
  labs(x = &amp;quot;GDP Per Capita&amp;quot;, y = &amp;quot;Life Expectancy in Years&amp;quot;,
       title = &amp;quot;Economic Growth and Life Expectancy&amp;quot;,
       subtitle = &amp;quot;Data Points are country-years&amp;quot;,
       caption = &amp;quot;Source: Gapminder&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Coloring by continent:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(scales)
p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp, color = continent, fill = continent))
p + geom_point()
p + geom_point() + scale_x_log10(labels = dollar)
p + geom_point() + scale_x_log10(labels = dollar) + geom_smooth()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; What does &lt;code&gt;fill = continent&lt;/code&gt; do? What do you think about the match of colors between lines and error bands?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = continent)) + geom_smooth() + scale_x_log10()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Notice how the above code leads to a single smooth line, not one per continent. Why?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; What is bad about the following example, assuming the graph is the one we want? Think about why you should set aesthetics at the top level rather than at the individual geometry level if that’s your intent.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;p &amp;lt;- ggplot(data = gapminder,
            mapping = aes(x = gdpPercap, y = lifeExp))
p + geom_point(mapping = aes(color = continent)) +
  geom_smooth(mapping = aes(color = continent, fill = continent)) +
  scale_x_log10() +
  geom_smooth(mapping = aes(color = continent), method = &amp;quot;gam&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise 3:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Generate two new plots with &lt;code&gt;data = gapminder&lt;/code&gt; (note: you’ll need to install the package by the same name if you have not already). Label the axes and the header with clear, easy to understand language. In a few sentences, describe what you’ve visualized and why.&lt;/p&gt;
&lt;p&gt;Note that this is your first foray into &lt;code&gt;ggplot2&lt;/code&gt;; accordingly, you should ry to make sure that you do not bite off more than you can chew. We will improve and refine our abilities as we progress through the semester.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Applying ggplot2 to Real Data</title>
      <link>/assignment/02-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/assignment/02-assignment/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#preliminaries&#34;&gt;Preliminaries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#background&#34;&gt;Background&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#r-markdown&#34;&gt;R Markdown&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#turning-everything-in&#34;&gt;Turning everything in&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You must turn in a PDF document of your &lt;code&gt;R Markdown&lt;/code&gt; code. Submit this to D2L by 11:59 PM Eastern Time on Monday, September 21.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;preliminaries&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;As always, we will first have to load &lt;code&gt;ggplot2&lt;/code&gt;. To do this, we will load the tidyverse by running this code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;library(tidyverse)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;background&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt;The New York City Department of Buildings (DOB) maintains a list of construction sites that have been categorized as “essential” during the city’s shelter-in-place pandemic order. They’ve provided &lt;a href=&#34;https://www1.nyc.gov/assets/buildings/html/essential-active-construction.html&#34;&gt;an interactive map here&lt;/a&gt; where you can see the different projects. There’s also a link there to download the complete dataset.&lt;/p&gt;
&lt;p&gt;For this exercise, you’re going to use this data to visualize the amounts or proportions of different types of essential projects in the five boroughs of New York City (Brooklyn, Manhattan, the Bronx, Queens, and Staten Island).&lt;/p&gt;
&lt;p&gt;As you hopefully figured out by now, you’ll be doing all your &lt;code&gt;R&lt;/code&gt; work in &lt;code&gt;R Markdown&lt;/code&gt;. You can use an RStudio Project to keep your files well organized (either on your computer or on RStudio.cloud), but this is optional. If you decide to do so, either create a new project for this exercise only, or make a project for all your work in this class.&lt;/p&gt;
&lt;p&gt;You’ll need to download one CSV file and put it somewhere on your computer or upload it to RStudio.cloud—preferably in a folder named &lt;code&gt;data&lt;/code&gt; in your project folder. You can download the data from &lt;a href=&#34;https://www1.nyc.gov/assets/buildings/html/essential-active-construction.html&#34;&gt;the DOB’s map&lt;/a&gt;, or use this link to get it directly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/projects/02-lab/data/EssentialConstruction.csv&#34;&gt;&lt;i class=&#34;fas fa-file-csv&#34;&gt;&lt;/i&gt; &lt;code&gt;EssentialConstruction.csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To help you, I’ve created a skeleton &lt;code&gt;R Markdown&lt;/code&gt; file with a template for this exercise, along with some code to help you clean and summarize the data. Download that here and use it to begin your lab this week. Note: skip this step at your own peril.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/projects/02-lab/02-lab.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; &lt;code&gt;02-lab.Rmd&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;r-markdown&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R Markdown&lt;/h3&gt;
&lt;p&gt;(We learned after the first assignment the following.) Many of you have not worked with &lt;code&gt;R Markdown&lt;/code&gt; before. That’s okay—we’ll teach you. Importantly, there are resources &lt;a href=&#34;/resource/&#34;&gt;here&lt;/a&gt; to help.&lt;/p&gt;
&lt;p&gt;Writing regular text with &lt;code&gt;R Markdown&lt;/code&gt; follows the rules of Markdown. You can make lists; different-size headers, etc. This should be relatively straightfoward; consult the resouces for more information.&lt;/p&gt;
&lt;p&gt;You’ll also need to insert your own code chunks where needed. Rather than typing them by hand (that’s tedious and you might miscount the number of backticks!), use the “Insert” button at the top of the editing window, or type &lt;kbd&gt;ctrl&lt;/kbd&gt; + &lt;kbd&gt;alt&lt;/kbd&gt; + &lt;kbd&gt;i&lt;/kbd&gt; on Windows, or &lt;kbd&gt;⌘&lt;/kbd&gt; + &lt;kbd&gt;⌥&lt;/kbd&gt; + &lt;kbd&gt;i&lt;/kbd&gt; on macOS.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/img/assignments/insert-chunk-button.png&#34; width=&#34;19%&#34; /&gt;&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;Exercise 1: Essential pandemic construction&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Make the following plots and briefly explain what they show. Note that the included .Rmd file above provides some intial guidance.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Show the count or proportion of approved projects by borough using a bar chart.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Show the count or proportion of approved projects by category using a lollipop chart&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Show the proportion of approved projects by borough and category simultaneously using a heatmap&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You don’t need to make these super fancy, but if you’re feeling brave, experiment with adding a &lt;code&gt;labs()&lt;/code&gt; layer or changing fill colors with &lt;code&gt;scale_fill_manual()&lt;/code&gt; or with palettes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bonus&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Overlay the data from Part 1 above onto a map of NYC. For double bonus, color the boroughs.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;turning-everything-in&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Turning everything in&lt;/h2&gt;
&lt;p&gt;When you’re all done, click on the “Knit” button at the top of the editing window and create a PDF. If you haven’t already &lt;a href=&#34;/resource/install/#install-tinytex&#34;&gt;install &lt;strong&gt;tinytex&lt;/strong&gt;&lt;/a&gt;) to ensure that works. Upload the PDF file to D2L.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Visualizing Large(ish) Data</title>
      <link>/assignment/03-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/assignment/03-assignment/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#getting-started&#34;&gt;Getting started&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#bonus-exercise&#34;&gt;Bonus Exercise&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#turning-everything-in&#34;&gt;Turning everything in&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#postscript-how-we-got-this-unemployment-data&#34;&gt;Postscript: how we got this unemployment data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You must turn in a PDF document of your &lt;code&gt;R Markdown&lt;/code&gt; code. Submit this to D2L by 11:59 PM Eastern Time on Monday, September 28.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-started&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting started&lt;/h1&gt;
&lt;p&gt;For this exercise you’ll use state-level unemployment data from 2006 to 2016 that comes from the US Bureau of Labor Statistics (if you’re curious, &lt;a href=&#34;#postscript-how-we-got-this-unemployment-data&#34;&gt;we describe how we built this dataset down below&lt;/a&gt;).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/projects/03-lab/data/unemployment.csv&#34;&gt;&lt;i class=&#34;fas fa-file-csv&#34;&gt;&lt;/i&gt; &lt;code&gt;unemployment.csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;To help you&lt;/strong&gt;, I’ve created a skeleton R Markdown file with a template for this exercise, along with some code to help you clean and summarize the data. Download that here and include it in your project:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/projects/03-lab/03-lab.Rmd&#34;&gt;&lt;i class=&#34;fab fa-r-project&#34;&gt;&lt;/i&gt; &lt;code&gt;03-lab.Rmd&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the end, to help you master file organization, we suggest that the structure of your project directory should look something like this:&lt;/p&gt;
&lt;pre class=&#34;text&#34;&gt;&lt;code&gt;your-project-name\
  03-lab.Rmd
  your-project-name.Rproj
  data\
    unemployment.csv&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;/example/03-example/&#34;&gt;The example for today’s session&lt;/a&gt; will be &lt;strong&gt;&lt;em&gt;incredibly&lt;/em&gt;&lt;/strong&gt; helpful for this exercise. Reference it.&lt;/p&gt;
&lt;p&gt;For this week, you need to start making your plots look nice. Label axes. Label the plot. Experiment with themes. Experiment with adding a &lt;code&gt;labs()&lt;/code&gt; layer or changing colors. Or, if you’re super brave, try modifying a theme and its elements.&lt;/p&gt;
&lt;p&gt;You’ll need to insert your own code chunks where needed. Rather than typing them by hand (that’s tedious and you might miscount the number of backticks!), use the “Insert” button at the top of the editing window, or type &lt;kbd&gt;ctrl&lt;/kbd&gt; + &lt;kbd&gt;alt&lt;/kbd&gt; + &lt;kbd&gt;i&lt;/kbd&gt; on Windows, or &lt;kbd&gt;⌘&lt;/kbd&gt; + &lt;kbd&gt;⌥&lt;/kbd&gt; + &lt;kbd&gt;i&lt;/kbd&gt; on macOS.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;EXERCISE 1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Use data from the US Bureau of Labor Statistics (BLS) to show the trends in employment rate for all 50 states between 2006 and 2016. What stories does this plot tell? Which states struggled to recover from the 2008–09 recession?&lt;/p&gt;
&lt;p&gt;Some hints/tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You won’t need to filter out any missing rows because the data here is complete—there are no state-year combinations with missing unemployment data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You’ll be plotting 51 facets. You can filter out DC if you want to have a better grid (like 5 × 10), or you can try using &lt;code&gt;facet_geo()&lt;/code&gt; from the &lt;strong&gt;geofacet&lt;/strong&gt; package to lay out the plots like a map of the US (try this!).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Plot the &lt;code&gt;date&lt;/code&gt; column along the x-axis, &lt;em&gt;not&lt;/em&gt; the &lt;code&gt;year&lt;/code&gt; column. If you plot by year, you’ll get weird looking lines (try it for fun?), since these observations are monthly. If you really want to plot by year only, you’ll need to create a different data frame where you group by year and state and calculate the average unemployment rate for each year/state combination (i.e. &lt;code&gt;group_by(year, state) %&amp;gt;% summarize(avg_unemployment = mean(unemployment))&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Try mapping other aesthetics onto the graph too. You’ll notice there are columns for region and division—play with those as colors, for instance.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;This plot might be big, so make sure you adjust &lt;code&gt;fig.width&lt;/code&gt; and &lt;code&gt;fig.height&lt;/code&gt; in the chunk options so that it’s visible when you knit it. You might also want to used &lt;code&gt;ggsave()&lt;/code&gt; to save it with extra large dimensions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;EXERCISE 2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Use data from the BLS to create a slopegraph that compares the unemployment rate in January 2006 with the unemployment rate in January 2009, either for all 50 states at once (good luck with that!) or for a specific region or division. Make sure the plot doesn’t look too busy or crowded in the end.&lt;/p&gt;
&lt;p&gt;What story does this plot tell? Which states in the US (or in the specific region you selected) were the most/least affected the Great Recession?&lt;/p&gt;
&lt;p&gt;Some hints/tips:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;You should use &lt;code&gt;filter()&lt;/code&gt; to only select rows where the year is 2006 or 2009 (i.e. &lt;code&gt;filter(year %in% c(2006, 2009)&lt;/code&gt;) and to select rows where the month is January (&lt;code&gt;filter(month == 1)&lt;/code&gt; or &lt;code&gt;filter(month_name == &#34;January&#34;)&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In order for the year to be plotted as separate categories on the x-axis, it needs to be a factor, so use &lt;code&gt;mutate(year = factor(year))&lt;/code&gt; to convert it.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To make ggplot draw lines between the 2006 and 2009 categories, you need to include &lt;code&gt;group = state&lt;/code&gt; in the aesthetics.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;bonus-exercise&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bonus Exercise&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;This is entirely optional but might be fun.&lt;/strong&gt; Then again, it might not be fun. I don’t know.&lt;/p&gt;
&lt;p&gt;For extra fun times, if you feel like it, create a bump chart showing something from the unemployment data (perhaps the top 10 states or bottom 10 states in unemployment?) Adapt the code in the &lt;a href=&#34;/example/03-example/&#34;&gt;example for today’s session&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you do this, plotting 51 lines is going to be a huge mess. But filtering the data is also a bad idea, because states could drop in and out of the top/bottom 10 over time, and we don’t want to get rid of them. Instead, you can zoom in on a specific range of data in your plot with &lt;code&gt;coord_cartesian(ylim = c(1, 10))&lt;/code&gt;, for instance.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;turning-everything-in&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Turning everything in&lt;/h2&gt;
&lt;p&gt;When you’re all done, click on the “Knit” button at the top of the editing window and create a PDF. If you haven’t already &lt;a href=&#34;/resource/install/#install-tinytex&#34;&gt;install &lt;strong&gt;tinytex&lt;/strong&gt;&lt;/a&gt;) to ensure that works. Upload the PDF file to D2L.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;postscript-how-we-got-this-unemployment-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Postscript: how we got this unemployment data&lt;/h2&gt;
&lt;p&gt;For the curious, &lt;a href=&#34;/projects/get_bls_data.R&#34;&gt;here’s the code we used&lt;/a&gt; to download the unemployment data from the BLS.&lt;/p&gt;
&lt;p&gt;And to pull the curtain back and show how much googling is involved in data visualization (and data analysis and programming in general), here was my process for getting this data:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;We thought “We want to have students show variation in something domestic over time” and then we googled “us data by state”. Nothing really came up (since it was an exceedingly vague search in the first place), but some results mentioned unemployment rates, so we figured that could be cool.&lt;/li&gt;
&lt;li&gt;We googled “unemployment statistics by state over time” and found that the BLS keeps statistics on this. We clicked on the &lt;a href=&#34;https://www.bls.gov/data/&#34;&gt;“Data Tools” link in their main navigation bar&lt;/a&gt;, clicked on “Unemployment”, and then clicked on the “Multi-screen data search” button for the Local Area Unemployment Statistics (LAUS).&lt;/li&gt;
&lt;li&gt;We walked through the multiple screens and got excited that we’d be able to download all unemployment stats for all states for a ton of years, &lt;em&gt;but then&lt;/em&gt; the final page had links to 51 individual Excel files, which was dumb.&lt;/li&gt;
&lt;li&gt;So we went back to Google and searched for “download bls data r” and found a few different packages people have written to do this. The first one we clicked on was &lt;a href=&#34;https://github.com/keberwein/blscrapeR&#34;&gt;&lt;code&gt;blscrapeR&lt;/code&gt; at GitHub&lt;/a&gt;, and it looked like it had been updated recently, so we went with it.&lt;/li&gt;
&lt;li&gt;We followed the examples in the &lt;code&gt;blscrapeR&lt;/code&gt; package and downloaded data for every state.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another day in the life of doing modern data science. This is an example of something you will be able to do by the end of this class. we had no idea people had written &lt;code&gt;R&lt;/code&gt; packages to access BLS data, but there are (at least) 3 packages out there. After a few minutes of tinkering, we got it working and it is relatively straightforward.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Statistical Models</title>
      <link>/assignment/04-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/assignment/04-assignment/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/kePrint/kePrint.js&#34;&gt;&lt;/script&gt;
&lt;link href=&#34;/rmarkdown-libs/lightable/lightable.css&#34; rel=&#34;stylesheet&#34; /&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#models&#34;&gt;Statistical models&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#poll-aggregators&#34;&gt;Poll aggregators&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#poll-data&#34;&gt;Poll data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#pollster-bias&#34;&gt;Pollster bias&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-driven-model&#34;&gt;Data-driven models&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You must turn in a PDF document of your &lt;code&gt;R Markdown&lt;/code&gt; code. Submit this to D2L by 11:59 PM Eastern Time on Monday, October 5.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;For this exercise you will need to ensure that you’ve carefully read this week’s content and example. We will build on both. The exercises (which you will turn in as this week’s lab) are at the bottom. Note that this week’s lab is much more theoretical than any other week in this class. This is to ensure that you have the foundations necessary to build rich statistical models and apply them to real-world data.&lt;/p&gt;
&lt;div id=&#34;models&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Statistical models&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;“All models are wrong, but some are useful.” –George E. P. Box&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The day before the 2008 presidential election, Nate Silver’s FiveThirtyEight stated that “Barack Obama appears poised for a decisive electoral victory”. They went further and predicted that Obama would win the election with 349 electoral votes to 189, and the popular vote by a margin of 6.1%. FiveThirtyEight also attached a probabilistic statement to their prediction claiming that Obama had a 91% chance of winning the election. The predictions were quite accurate since, in the final results, Obama won the electoral college 365 to 173 and the popular vote by a 7.2% difference. Their performance in the 2008 election brought FiveThirtyEight to the attention of political pundits and TV personalities. Four years later, the week before the 2012 presidential election, FiveThirtyEight’s Nate Silver was giving Obama a 90% chance of winning despite many of the experts thinking the final results would be closer. Political commentator Joe Scarborough said during his show&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Anybody that thinks that this race is anything but a toss-up right now is such an ideologue … they’re jokes.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To which Nate Silver responded via Twitter:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you think it’s a toss-up, let’s bet. If Obama wins, you donate $1,000 to the American Red Cross. If Romney wins, I do. Deal?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In 2016, Silver was not as certain and gave Hillary Clinton only a 71% of winning. In contrast, most other forecasters were almost certain she would win. She lost. But 71% is still more than 50%, so was Mr. Silver wrong? And what does probability mean in this context anyway? Are dice being tossed somewhere?&lt;/p&gt;
&lt;p&gt;In this lab we will demonstrate how &lt;em&gt;poll aggregators&lt;/em&gt;, such as FiveThirtyEight, collected and combined data reported by different experts to produce improved predictions. We will introduce ideas behind the &lt;em&gt;statistical models&lt;/em&gt;, also known as &lt;em&gt;probability models&lt;/em&gt;, that were used by poll aggregators to improve election forecasts beyond the power of individual polls. First, we’ll motivate the models, building on the statistical inference concepts we learned in this week’s content and example. We start with relatively simple models, realizing that the actual data science exercise of forecasting elections involves rather complex ones. We will introduce such modeks towards the end of this section of the course.&lt;/p&gt;
&lt;div id=&#34;poll-aggregators&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Poll aggregators&lt;/h2&gt;
&lt;p&gt;A few weeks before the 2012 election Nate Silver was giving Obama a 90% chance of winning. How was Mr. Silver so confident? We will use a Monte Carlo simulation to illustrate the insight Mr. Silver had and others missed. To do this, we generate results for 12 polls taken the week before the election. We mimic sample sizes from actual polls and construct and report 95% confidence intervals for each of the 12 polls. We save the results from this simulation in a data frame and add a poll ID column.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(dslabs)
d &amp;lt;- 0.039
Ns &amp;lt;- c(1298, 533, 1342, 897, 774, 254, 812, 324, 1291, 1056, 2172, 516)
p &amp;lt;- (d + 1) / 2

polls &amp;lt;- map_df(Ns, function(N) {
  x &amp;lt;- sample(c(0,1), size=N, replace=TRUE, prob=c(1-p, p))
  x_hat &amp;lt;- mean(x)
  se_hat &amp;lt;- sqrt(x_hat * (1 - x_hat) / N)
  list(estimate = 2 * x_hat - 1,
    low = 2*(x_hat - 1.96*se_hat) - 1,
    high = 2*(x_hat + 1.96*se_hat) - 1,
    sample_size = N)
}) %&amp;gt;% mutate(poll = seq_along(Ns))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a visualization showing the intervals the pollsters would have reported for the difference between Obama and Romney:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/04-assignment_files/figure-html/simulated-polls-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Not surprisingly, all 12 polls report confidence intervals that include the election night result (dashed line). However, all 12 polls also include 0 (solid black line) as well. Therefore, if asked individually for a prediction, the pollsters would have to say: it’s a toss-up. Below we describe a key insight they are missing.&lt;/p&gt;
&lt;p&gt;Poll aggregators, such as Nate Silver, realized that by combining the results of different polls you could greatly improve precision. By doing this, we are effectively conducting a poll with a huge sample size. We can therefore report a smaller 95% confidence interval and a more precise prediction.&lt;/p&gt;
&lt;p&gt;Although as aggregators we do not have access to the raw poll data, we can use mathematics to reconstruct what we would have obtained had we made one large poll with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(polls$sample_size)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 11269&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;participants. Basically, we construct an estimate of the spread, let’s call it &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, with a weighted average in the following way:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_hat &amp;lt;- polls %&amp;gt;%
  summarize(avg = sum(estimate*sample_size) / sum(sample_size)) %&amp;gt;%
  pull(avg)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once we have an estimate of &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, we can construct an estimate for the proportion voting for Obama, which we can then use to estimate the standard error. Once we do this, we see that our margin of error is 0.0184545.&lt;/p&gt;
&lt;p&gt;Thus, we can predict that the spread will be 3.1 plus or minus 1.8, which not only includes the actual result we eventually observed on election night, but is quite far from including 0. Once we combine the 12 polls, we become quite certain that Obama will win the popular vote.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/04-assignment_files/figure-html/confidence-coverage-2008-election-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Of course, this was just a simulation to illustrate the idea. The actual data science exercise of forecasting elections is much more complicated and it involves modeling. Below we explain how pollsters fit multilevel models to the data and use this to forecast election results. In the 2008 and 2012 US presidential elections, Nate Silver used this approach to make an almost perfect prediction and silence the pundits.&lt;/p&gt;
&lt;p&gt;Since the 2008 elections, other organizations have started their own election forecasting group that, like Nate Silver’s, aggregates polling data and uses statistical models to make predictions. In 2016, forecasters underestimated Trump’s chances of winning greatly. The day before the election the &lt;em&gt;New York Times&lt;/em&gt; reported&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; the following probabilities for Hillary Clinton winning the presidency:&lt;/p&gt;
&lt;table class=&#34;table table-striped&#34; style=&#34;width: auto !important; margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
NYT
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
538
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
HuffPost
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
PW
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
PEC
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
DK
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Cook
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Roth
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Win Prob
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
85%
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
71%
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
98%
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
89%
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
&amp;gt;99%
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
92%
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lean Dem
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Lean Dem
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--(Source: [New York Times](https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html))--&gt;
&lt;p&gt;For example, the Princeton Election Consortium (PEC) gave Trump less than 1% chance of winning, while the Huffington Post gave him a 2% chance. In contrast, FiveThirtyEight had Trump’s probability of winning at 29%, higher than tossing two coins and getting two heads. In fact, four days before the election FiveThirtyEight published an article titled &lt;em&gt;Trump Is Just A Normal Polling Error Behind Clinton&lt;/em&gt;&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.
By understanding statistical models and how these forecasters use them, we will start to understand how this happened.&lt;/p&gt;
&lt;p&gt;Although not nearly as interesting as predicting the electoral college, for illustrative purposes we will start by looking at predictions for the popular vote. FiveThirtyEight predicted a 3.6% advantage for Clinton&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;, included the actual result of 2.1% (48.2% to 46.1%) in their interval, and was much more confident about Clinton winning the election, giving her an 81.4% chance. Their prediction was summarized with a chart like this:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/04-assignment_files/figure-html/fivethirtyeight-densities-1.png&#34; width=&#34;80%&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The colored areas represent values with an 80% chance of including the actual result, according to the FiveThirtyEight model.
&lt;!--(Source: [FiveThirtyEight](https://projects.fivethirtyeight.com/2016-election-forecast/))--&gt;&lt;/p&gt;
&lt;p&gt;We introduce actual data from the 2016 US presidential election to show how models are motivated and built to produce these predictions. To understand the “81.4% chance” statement we need to describe Bayesian statistics, which we do in Sections &lt;a href=&#34;#bayesian-statistics&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt; and &lt;a href=&#34;#bayesian-approach&#34;&gt;&lt;strong&gt;??&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;poll-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Poll data&lt;/h3&gt;
&lt;p&gt;We use public polling data organized by FiveThirtyEight for the 2016 presidential election. The data is included as part of the &lt;strong&gt;dslabs&lt;/strong&gt; package:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(polls_us_election_2016)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The table includes results for national polls, as well as state polls, taken during the year prior to the election. For this first example, we will filter the data to include national polls conducted during the week before the election. We also remove polls that FiveThirtyEight has determined not to be reliable and graded with a “B” or less. Some polls have not been graded and we include those:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls &amp;lt;- polls_us_election_2016 %&amp;gt;%
  filter(state == &amp;quot;U.S.&amp;quot; &amp;amp; enddate &amp;gt;= &amp;quot;2016-10-31&amp;quot; &amp;amp;
           (grade %in% c(&amp;quot;A+&amp;quot;,&amp;quot;A&amp;quot;,&amp;quot;A-&amp;quot;,&amp;quot;B+&amp;quot;) | is.na(grade)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We add a spread estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls &amp;lt;- polls %&amp;gt;%
  mutate(spread = rawpoll_clinton/100 - rawpoll_trump/100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this example, we will assume that there are only two parties and call &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; the proportion voting for Clinton and &lt;span class=&#34;math inline&#34;&gt;\(1-p\)&lt;/span&gt; the proportion voting for Trump. We are interested in the spread &lt;span class=&#34;math inline&#34;&gt;\(2p-1\)&lt;/span&gt;. Let’s call the spread &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; (for difference).&lt;/p&gt;
&lt;p&gt;We have 49 estimates of the spread. The theory we learned tells us that these estimates are a random variable with a probability distribution that is approximately normal. The expected value is the election night spread &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and the standard error is &lt;span class=&#34;math inline&#34;&gt;\(2\sqrt{p (1 - p) / N}\)&lt;/span&gt;. Assuming the urn model we described earlier is a good one, we can use this information to construct a confidence interval based on the aggregated data. The estimated spread is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d_hat &amp;lt;- polls %&amp;gt;%
  summarize(d_hat = sum(spread * samplesize) / sum(samplesize)) %&amp;gt;%
  pull(d_hat)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the standard error is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p_hat &amp;lt;- (d_hat+1)/2
moe &amp;lt;- 1.96 * 2 * sqrt(p_hat * (1 - p_hat) / sum(polls$samplesize))
moe&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.006623178&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So we report a spread of 1.43% with a margin of error of 0.66%. On election night, we discover that the actual percentage was 2.1%, which is outside a 95% confidence interval. What happened?&lt;/p&gt;
&lt;p&gt;A histogram of the reported spreads shows a problem:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls %&amp;gt;%
  ggplot(aes(spread)) +
  geom_histogram(color=&amp;quot;black&amp;quot;, binwidth = .01)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/04-assignment_files/figure-html/polls-2016-spread-histogram-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The data does not appear to be normally distributed and the standard error appears to be larger than 0.0066232. The theory is not quite working here.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pollster-bias&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Pollster bias&lt;/h3&gt;
&lt;p&gt;Notice that various pollsters are involved and some are taking several polls a week:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls %&amp;gt;% group_by(pollster) %&amp;gt;% summarize(n())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` ungrouping output (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 15 x 2
##    pollster                                                   `n()`
##    &amp;lt;fct&amp;gt;                                                      &amp;lt;int&amp;gt;
##  1 ABC News/Washington Post                                       7
##  2 Angus Reid Global                                              1
##  3 CBS News/New York Times                                        2
##  4 Fox News/Anderson Robbins Research/Shaw &amp;amp; Company Research     2
##  5 IBD/TIPP                                                       8
##  6 Insights West                                                  1
##  7 Ipsos                                                          6
##  8 Marist College                                                 1
##  9 Monmouth University                                            1
## 10 Morning Consult                                                1
## 11 NBC News/Wall Street Journal                                   1
## 12 RKM Research and Communications, Inc.                          1
## 13 Selzer &amp;amp; Company                                               1
## 14 The Times-Picayune/Lucid                                       8
## 15 USC Dornsife/LA Times                                          8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s visualize the data for the pollsters that are regularly polling:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/04-assignment_files/figure-html/pollster-bias-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot reveals an unexpected result. First, consider that the standard error predicted by theory for each poll:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls %&amp;gt;% group_by(pollster) %&amp;gt;%
  filter(n() &amp;gt;= 6) %&amp;gt;%
  summarize(se = 2 * sqrt(p_hat * (1-p_hat) / median(samplesize)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## `summarise()` ungrouping output (override with `.groups` argument)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   pollster                     se
##   &amp;lt;fct&amp;gt;                     &amp;lt;dbl&amp;gt;
## 1 ABC News/Washington Post 0.0265
## 2 IBD/TIPP                 0.0333
## 3 Ipsos                    0.0225
## 4 The Times-Picayune/Lucid 0.0196
## 5 USC Dornsife/LA Times    0.0183&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;is between 0.018 and 0.033, which agrees with the within poll variation we see. However, there appears to be differences &lt;em&gt;across the polls&lt;/em&gt;. Note, for example, how the USC Dornsife/LA Times pollster is predicting a 4% win for Trump, while Ipsos is predicting a win larger than 5% for Clinton. The theory we learned says nothing about different pollsters producing polls with different expected values. All the polls should have the same expected value. FiveThirtyEight refers to these differences as “house effects”. We also call them &lt;em&gt;pollster bias&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In the following section, rather than use the urn model theory, we are instead going to develop a data-driven model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-driven-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data-driven models&lt;/h2&gt;
&lt;p&gt;For each pollster, let’s collect their last reported result before the election:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;one_poll_per_pollster &amp;lt;- polls %&amp;gt;% group_by(pollster) %&amp;gt;%
  filter(enddate == max(enddate)) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is a histogram of the data for these 15 pollsters:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;qplot(spread, data = one_poll_per_pollster, binwidth = 0.01)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/assignment/04-assignment_files/figure-html/pollster-bias-histogram-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the previous section, we saw that using the urn model theory to combine these results might not be appropriate due to the pollster effect. Instead, we will model this spread data directly.&lt;/p&gt;
&lt;p&gt;The new model can also be thought of as an urn model, although the connection is not as direct. Rather than 0s (Republicans) and 1s (Democrats), our urn now contains poll results from all possible pollsters. We &lt;em&gt;assume&lt;/em&gt; that the expected value of our urn is the actual spread &lt;span class=&#34;math inline&#34;&gt;\(d=2p-1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Because instead of 0s and 1s, our urn contains continuous numbers between -1 and 1, the standard deviation of the urn is no longer &lt;span class=&#34;math inline&#34;&gt;\(\sqrt{p(1-p)}\)&lt;/span&gt;. Rather than voter sampling variability, the standard error now includes the pollster-to-pollster variability. Our new urn also includes the sampling variability from the polling. Regardless, this standard deviation is now an unknown parameter. In statistics textbooks, the Greek symbol &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is used to represent this parameter.&lt;/p&gt;
&lt;p&gt;In summary, we have two unknown parameters: the expected value &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and the standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Our task is to estimate &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. Because we model the observed values &lt;span class=&#34;math inline&#34;&gt;\(X_1,\dots X_N\)&lt;/span&gt; as a random sample from the urn, the CLT might still work in this situation because it is an average of independent random variables. For a large enough sample size &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, the probability distribution of the sample average &lt;span class=&#34;math inline&#34;&gt;\(\bar{X}\)&lt;/span&gt; is approximately normal with expected value &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard error &lt;span class=&#34;math inline&#34;&gt;\(\sigma/\sqrt{N}\)&lt;/span&gt;. If we are willing to consider &lt;span class=&#34;math inline&#34;&gt;\(N=15\)&lt;/span&gt; large enough, we can use this to construct confidence intervals.&lt;/p&gt;
&lt;p&gt;A problem is that we don’t know &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. But theory tells us that we can estimate the urn model &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; with the &lt;em&gt;sample standard deviation&lt;/em&gt; defined as
&lt;span class=&#34;math inline&#34;&gt;\(s = \sqrt{ \sum_{i=1}^N (X_i - \bar{X})^2 / (N-1)}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Unlike for the population standard deviation definition, we now divide by &lt;span class=&#34;math inline&#34;&gt;\(N-1\)&lt;/span&gt;. This makes &lt;span class=&#34;math inline&#34;&gt;\(s\)&lt;/span&gt; a better estimate of &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. There is a mathematical explanation for this, which is explained in most statistics textbooks, but we don’t cover it here.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;sd&lt;/code&gt; function in R computes the sample standard deviation:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sd(one_poll_per_pollster$spread)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.02419369&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are now ready to form a new confidence interval based on our new data-driven model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- one_poll_per_pollster %&amp;gt;%
  summarize(avg = mean(spread),
            se = sd(spread) / sqrt(length(spread))) %&amp;gt;%
  mutate(start = avg - 1.96 * se,
         end = avg + 1.96 * se)
round(results * 100, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   avg  se start end
## 1 2.9 0.6   1.7 4.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our confidence interval is wider now since it incorporates the pollster variability. It does include the election night result of 2.1%. Also, note that it was small enough not to include 0, which means we were confident Clinton would win the popular vote.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;EXERCISES&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Note that using dollar signs &lt;code&gt;$ $&lt;/code&gt; to enclose some text is how you make the fancy math you see below. If you installed &lt;code&gt;tinytex&lt;/code&gt; or some other Latex distribution in order to render your PDFs, you should be equipped to insert mathematics directly into your .Rmd file.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;In this section, we talked about pollster bias. We used visualization to motivate the presence of such bias. Here we will give it a more rigorous treatment. We will consider two pollsters that conducted daily polls. We will look at national polls for the month before the election.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(polls_us_election_2016)
polls &amp;lt;- polls_us_election_2016 %&amp;gt;%
  filter(pollster %in% c(&amp;quot;Rasmussen Reports/Pulse Opinion Research&amp;quot;,
                         &amp;quot;The Times-Picayune/Lucid&amp;quot;) &amp;amp;
           enddate &amp;gt;= &amp;quot;2016-10-15&amp;quot; &amp;amp;
           state == &amp;quot;U.S.&amp;quot;) %&amp;gt;%
  mutate(spread = rawpoll_clinton/100 - rawpoll_trump/100)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We want to answer the question: is there a poll bias? First, make a plot showing the spreads for each poll.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;The data does seem to suggest there is a difference. However, these data are subject to variability. Perhaps the differences we observe are due to chance.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The urn model theory says nothing about pollster effect. Under the urn model, both pollsters have the same expected value: the election day difference, that we call &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;We will model the observed data &lt;span class=&#34;math inline&#34;&gt;\(Y_{i,j}\)&lt;/span&gt; in the following way:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
Y_{i,j} = d + b_i + \varepsilon_{i,j}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;with &lt;span class=&#34;math inline&#34;&gt;\(i=1,2\)&lt;/span&gt; indexing the two pollsters, &lt;span class=&#34;math inline&#34;&gt;\(b_i\)&lt;/span&gt; the bias for pollster &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_ij\)&lt;/span&gt; poll to poll chance variability. We assume the &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon\)&lt;/span&gt; are independent from each other, have expected value &lt;span class=&#34;math inline&#34;&gt;\(0\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma_i\)&lt;/span&gt; regardless of &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Which of the following best represents our question?&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Is &lt;span class=&#34;math inline&#34;&gt;\(\varepsilon_{i,j}\)&lt;/span&gt; = 0?&lt;/li&gt;
&lt;li&gt;How close are the &lt;span class=&#34;math inline&#34;&gt;\(Y_{i,j}\)&lt;/span&gt; to &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;?&lt;/li&gt;
&lt;li&gt;Is &lt;span class=&#34;math inline&#34;&gt;\(b_1 \neq b_2\)&lt;/span&gt;?&lt;/li&gt;
&lt;li&gt;Are &lt;span class=&#34;math inline&#34;&gt;\(b_1 = 0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(b_2 = 0\)&lt;/span&gt; ?&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Suppose we define &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_1\)&lt;/span&gt; as the average of poll results from the first poll, &lt;span class=&#34;math inline&#34;&gt;\(Y_{1,1},\dots,Y_{1,N_1}\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(N_1\)&lt;/span&gt; the number of polls conducted by the first pollster:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls %&amp;gt;%
  filter(pollster==&amp;quot;Rasmussen Reports/Pulse Opinion Research&amp;quot;) %&amp;gt;%
  summarize(N_1 = n())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is the expected value of &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_1\)&lt;/span&gt;?&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;What is the standard error of &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_1\)&lt;/span&gt;? (It may be helpful to compute the expected value and standard error of &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_2\)&lt;/span&gt; as well.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Suppose we define &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_2\)&lt;/span&gt; as the average of poll results from the first poll, &lt;span class=&#34;math inline&#34;&gt;\(Y_{2,1},\dots,Y_{2,N_2}\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(N_2\)&lt;/span&gt; the number of polls conducted by the first pollster. What is the expected value &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_2\)&lt;/span&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What does the CLT tell us about the distribution of &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_2 - \bar{Y}_1\)&lt;/span&gt;?&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;Nothing because this is not the average of a sample.&lt;/li&gt;
&lt;li&gt;Because the &lt;span class=&#34;math inline&#34;&gt;\(Y_{ij}\)&lt;/span&gt; are approximately normal, so are the averages.&lt;/li&gt;
&lt;li&gt;Note that &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\bar{Y}_1\)&lt;/span&gt; are sample averages, so if we assume &lt;span class=&#34;math inline&#34;&gt;\(N_2\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(N_1\)&lt;/span&gt; are large enough, each is approximately normal. The difference of normals is also normal.&lt;/li&gt;
&lt;li&gt;The data are not 0 or 1, so CLT does not apply.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;7&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Construct a random variable that has expected value &lt;span class=&#34;math inline&#34;&gt;\(b_2 - b_1\)&lt;/span&gt;, the pollster bias difference. If our model holds, then this random variable has an approximately normal distribution and we know its standard error. The standard error depends on &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_2\)&lt;/span&gt; (the variances of the &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; above), but we can plug the sample standard deviations. &lt;strong&gt;Compute those now&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The statistic formed by dividing our estimate of &lt;span class=&#34;math inline&#34;&gt;\(b_2-b_1\)&lt;/span&gt; by its estimated standard error:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\frac{\bar{Y}_2 - \bar{Y}_1}{\sqrt{s_2^2/N_2 + s_1^2/N_1}}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;is called the t-statistic. Now you should be able to answer the question: is &lt;span class=&#34;math inline&#34;&gt;\(b_2 - b_1\)&lt;/span&gt; different from 0?&lt;/p&gt;
&lt;p&gt;Notice that we have more than two pollsters. We can also test for pollster effect using all pollsters, not just two. The idea is to compare the variability across polls to variability within polls. We can actually construct statistics to test for effects and approximate their distribution. The area of statistics that does this is called Analysis of Variance or ANOVA. We do not cover it here, but ANOVA provides a very useful set of tools to answer questions such as: is there a pollster effect?&lt;/p&gt;
&lt;p&gt;For this exercise, create a new table:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;polls &amp;lt;- polls_us_election_2016 %&amp;gt;%
  filter(enddate &amp;gt;= &amp;quot;2016-10-15&amp;quot; &amp;amp;
           state == &amp;quot;U.S.&amp;quot;) %&amp;gt;%
  group_by(pollster) %&amp;gt;%
  filter(n() &amp;gt;= 5) %&amp;gt;%
  mutate(spread = rawpoll_clinton/100 - rawpoll_trump/100) %&amp;gt;%
  ungroup()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Compute the average and standard deviation for each pollster and examine the variability across the averages and how it compares to the variability within the pollsters, summarized by the standard deviation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=TbKkjm-gheY&#34; class=&#34;uri&#34;&gt;https://www.youtube.com/watch?v=TbKkjm-gheY&lt;/a&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html&#34; class=&#34;uri&#34;&gt;https://www.nytimes.com/interactive/2016/upshot/presidential-polls-forecast.html&lt;/a&gt;&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://fivethirtyeight.com/features/trump-is-just-a-normal-polling-error-behind-clinton/&#34; class=&#34;uri&#34;&gt;https://fivethirtyeight.com/features/trump-is-just-a-normal-polling-error-behind-clinton/&lt;/a&gt;&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;&lt;a href=&#34;https://projects.fivethirtyeight.com/2016-election-forecast/&#34; class=&#34;uri&#34;&gt;https://projects.fivethirtyeight.com/2016-election-forecast/&lt;/a&gt;&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Correlations and Simple Models</title>
      <link>/assignment/05-assignment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/assignment/05-assignment/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#backstory-and-set-up&#34;&gt;Backstory and Set Up&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#data-exploration-and-processing&#34;&gt;Data Exploration and Processing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;NOTE&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You must turn in a PDF document of your &lt;code&gt;R Markdown&lt;/code&gt; code. Submit this to D2L by 11:59 PM Eastern Time on Monday, October 12.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This week’s lab will (hopefully) not repeat the disaster that was last week’s lab.&lt;/p&gt;
&lt;div id=&#34;backstory-and-set-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Backstory and Set Up&lt;/h2&gt;
&lt;p&gt;You have been recently hired to Zillow’s Zestimate product team as a junior analyst. As a part of their regular hazing, they have given you access to a small subset of their historic sales data. Your job is to present some basic predictions for housing values in a small geographic area (Ames, IA) using this historical pricing.&lt;/p&gt;
&lt;p&gt;First, let’s load the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ameslist &amp;lt;- read.table(&amp;quot;https://msudataanalytics.github.io/SSC442/Labs/data/ames.csv&amp;quot;,
                 header = TRUE,
                 sep = &amp;quot;,&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we proceed, let’s note a few things about the (simple) code above. First, we have specified &lt;code&gt;header = TRUE&lt;/code&gt; because—you guessed it—the original dataset has headers. Although simple, this is an incredibly important step because it allows &lt;code&gt;R&lt;/code&gt; to do some smart &lt;code&gt;R&lt;/code&gt; things. Specifically, once the headers are in, the variables are formatted as &lt;code&gt;int&lt;/code&gt; and &lt;code&gt;factor&lt;/code&gt; where appropriate. It is absolutely vital that we format the data correctly; otherwise, many &lt;code&gt;R&lt;/code&gt; commands will whine at us.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Run the above, but instead specifying &lt;code&gt;header = FALSE&lt;/code&gt;. What data type are the various columns? Now try ommitting the line altogether. What is the default behavior of the &lt;code&gt;read.table&lt;/code&gt; function?&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;data-exploration-and-processing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Exploration and Processing&lt;/h3&gt;
&lt;p&gt;We are not going to tell you anything about this data. This is intended to replicate a real-world experience that you will all encounter in the (possibly near) future: someone hands you data and you’re expected to make sense of it. Fortunately for us, this data is (somewhat) self-contained. We’ll first check the variable names to try to divine some information. Recall, we have a handy little function for that:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;names(ameslist)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that, when doing data exploration, we will sometimes choose to not save our output. This is a judgement call; here we’ve chosen to merely inspect the variables rather than diving in.&lt;/p&gt;
&lt;p&gt;Inspection yields some obvious truths. For example:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Explanation&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Type&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;ID&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Unique identifier for each row&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;LotArea&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Size of lot (&lt;strong&gt;units unknown&lt;/strong&gt;)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;SalePrice&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;Sale price of house ($)&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;…but we face some not-so-obvious things as well. For example:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th&gt;Variable&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Explanation&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Type&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;LotShape&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;? Something about the lot&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;code&gt;factor&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td&gt;&lt;code&gt;MSSubClass&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;? No clue at all&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;code&gt;int&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td&gt;&lt;code&gt;Condition1&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;? Seems like street info&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;&lt;code&gt;factor&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;It will be difficult to learn anything about the data that is of type &lt;code&gt;int&lt;/code&gt; without outside documentation. However, we can learn something more about the &lt;code&gt;factor&lt;/code&gt;-type variables. In order to understand these a little better, we need to review some of the values that each take on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Go through the variables in the dataset and make a note about your interpretation for each. Many will be obvious, but some require additional thought.&lt;/p&gt;
&lt;p&gt;We now turn to another central issue—and one that explains our nomenclature choice thus far: the data object is of type &lt;code&gt;list&lt;/code&gt;. To verify this for yourself, check:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;typeof(ameslist)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This isn’t ideal—for some visualization packages, for instance, we need data frames and not lists. We’ll make a mental note of this as something to potentially clean up if we desire.&lt;/p&gt;
&lt;p&gt;Although there are some variables that would be difficult to clean, there are a few that we can address with relative ease. Consider, for instance, the variable &lt;code&gt;GarageType&lt;/code&gt;. This might not be that important, but, remember, the weather in Ames, IA is pretty crummy—a detached garage might be a dealbreaker for some would-be homebuyers. Let’s inspect the values:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;&amp;gt; unique(ameslist$GarageType)
[1] Attchd  Detchd  BuiltIn CarPort &amp;lt;NA&amp;gt; Basment 2Types&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With this, we could make an informed decision and create a new variable. Let’s create &lt;code&gt;OutdoorGarage&lt;/code&gt; to indicate, say, homes that have any type of garage that requires the homeowner to walk outdoors after parking their car. (For those who aren’t familiar with different garage types, a car port is not insulated and is therefore considered outdoors. A detached garage presumably requires that the person walks outside after parking. The three other types are inside the main structure, and &lt;code&gt;2Types&lt;/code&gt; we can assume includes at least one attached garage of some sort). This is going to require a bit more coding and we will have to think through each step carefully.&lt;/p&gt;
&lt;p&gt;First, let’s create a new object that has indicator variables (that is, a variable whose values are either zero or one) for each of the &lt;code&gt;GarageType&lt;/code&gt; values. As with everything in &lt;code&gt;R&lt;/code&gt;, there’s a handy function to do this for us:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;GarageTemp = model.matrix( ~ GarageType - 1, data=ameslist )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We now have two separate objects living in our computer’s memory: &lt;code&gt;ameslist&lt;/code&gt; and &lt;code&gt;GarageTemp&lt;/code&gt;—so named to indicate that it is a temporary object.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; We now need to stitch it back onto our original data; we’ll use a simple concatenation and write over our old list with the new one:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ameslist &amp;lt;- cbind(ameslist, GarageTemp)
&amp;gt; Error in data.frame(..., check.names = FALSE) :
  arguments imply differing number of rows: 1460, 1379&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Huh. What’s going on?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Figure out what’s going on above. Fix this code so that you have a working version.&lt;/p&gt;
&lt;p&gt;Now that we’ve got that working (ha!) we can generate a new variable for our outdoor garage. We’ll use a somewhat gross version below because it is &lt;em&gt;verbose&lt;/em&gt;; that said, this can be easily accomplished using logical indexing for those who like that approach.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ameslist$GarageOutside &amp;lt;- ifelse(ameslist$GarageTypeDetchd == 1 | ameslist$GarageTypeCarPort == 1, 1, 0)
unique(ameslist$GarageOutside)
[1]  0  1 NA&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This seems to have worked. The command above &lt;code&gt;ifelse()&lt;/code&gt; does what it says: &lt;code&gt;if&lt;/code&gt; some condition is met (here, either of two variables equals one) then it returns a one; &lt;code&gt;else&lt;/code&gt; it returns a zero. Such functions are very handy, though as mentioned above, there are other ways of doing this. Also note, that while fixed the issue with &lt;code&gt;NA&lt;/code&gt; above, we’ve got new issues: we definitely don’t want &lt;code&gt;NA&lt;/code&gt; outputted from this operation. Accordingly, we’re going to need to deal with it somehow.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Try it:&lt;/strong&gt; Utilizing a similar approach to what you did above, fix this so that the only outputs are zero and one.&lt;/p&gt;
&lt;p&gt;Generally speaking, this is a persistent issue, and you will spend an extraordinary amount of time dealing with missing data or data that does not encode a variable exactly as you want it. This is expecially true if you deal with real-world data: you will need to learn how to handle &lt;code&gt;NA&lt;/code&gt;s. There are a number of fixes (as always, Google is your friend) and anything that works is good. But you should spend some time thinking about this and learning at least one approach.&lt;/p&gt;
&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;&lt;strong&gt;EXERCISES&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Prune the data to all of the variables that are &lt;code&gt;type = int&lt;/code&gt; about which you have some reasonable intuition for what they mean. This &lt;strong&gt;must&lt;/strong&gt; include the variable &lt;code&gt;SalePrice&lt;/code&gt;. Save this new dataset as &lt;code&gt;Ames&lt;/code&gt;. Produce documentation for this object in the form of a .txt file. This must describe each of the preserved variables, the values it can take (e.g., can it be negative?) and your interpretation of the variable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Produce a &lt;em&gt;scatterplot matrix&lt;/em&gt; which includes 12 of the variables that are &lt;code&gt;type = int&lt;/code&gt; in the data set. Choose those that you believe are likely to be correlated with &lt;code&gt;SalePrice&lt;/code&gt;.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Compute a matrix of correlations between these variables using the function &lt;code&gt;cor()&lt;/code&gt;. Does this match your prior beliefs? Briefly discuss the correlation between the miscellaneous variables and &lt;code&gt;SalePrice&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Produce a scatterplot between &lt;code&gt;SalePrice&lt;/code&gt; and &lt;code&gt;GrLivArea&lt;/code&gt;. Run a linear model using &lt;code&gt;lm()&lt;/code&gt; to explore the relationship. Finally, use the &lt;code&gt;abline()&lt;/code&gt; function to plot the relationship that you’ve found in the simple linear regression.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What is the largest outlier that is above the regression line? Produce the other information about this house.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;(Bonus)&lt;/strong&gt; Create a visualization that shows the rise of air conditioning over time in homes in Ames.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Of course, you could find out the defaults of the function by simply using the handy &lt;code&gt;?&lt;/code&gt; command. Don’t forget about this tool!&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;It’s not exactly true that these objects are in memory. They are… sort of. But how &lt;code&gt;R&lt;/code&gt; handles memory is complicated and silly and blah blah who cares. It’s basically in memory.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;If you are not familiar with this type of visualization, consult the book (&lt;em&gt;Introduction to Statistical Learning&lt;/em&gt;), Chapters 2 and 3. Google it; it’s free.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Final project</title>
      <link>/assignment/final-project/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/assignment/final-project/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#requirements&#34;&gt;Requirements&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#teams&#34;&gt;Teams&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#suggested-outline&#34;&gt;Suggested outline&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#theory-and-background&#34;&gt;Theory and Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-and-analyses&#34;&gt;Data and Analyses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;requirements&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;p&gt;Data analytics is inherently a hands-on endeavor. Accordingly, the final project for this class is hands-on. As per the overview page, the final project has the following elements:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;For your final project in this class, you will analyze &lt;strong&gt;existing data&lt;/strong&gt; in some area of interest to you.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; Aggregating data from multiple sources is encouraged, but is not required.&lt;/li&gt;
&lt;/ol&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;You must visualize (at least) three &lt;strong&gt;interesting&lt;/strong&gt; features of that data. Visualizations should aid the reader in understanding something about the data that might not be readily aparent.[^4]&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You must come up with some analysis—using tools from the course—which relates your data to either a prediction or a policy conclusion. For example, if you collected data from Major League Baseball games, you could try to “predict” whether a left-hander was pitching based solely on the outcomes of the batsmen.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;You will submit &lt;strong&gt;three things&lt;/strong&gt; via D2L:&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;A PDF of your report (see the outline below for details of what this needs to contain). You should compile this with R Markdown. You might want to write the prose-heavy sections in a word processor like Word or Google Docs and copy/paste the text into your &lt;code&gt;R&lt;/code&gt; Markdown document, since RStudio doesn’t have a nice spell checker or grammar checker. This should have &lt;em&gt;no visible &lt;code&gt;R&lt;/code&gt; code, warnings, or messages in it&lt;/em&gt;. To do this, you must set &lt;code&gt;echo = FALSE&lt;/code&gt; at the beginning of your document before you knit.&lt;/li&gt;
&lt;li&gt;The same PDF as above, but with all the R code in it (set &lt;code&gt;echo = TRUE&lt;/code&gt; at the beginning of your document and reknit the file). Please label files in an obvious way.&lt;/li&gt;
&lt;li&gt;A CSV file of your data; or a link to the data online if your code pulls from the internet. This must be a separate file titled “data.csv” or “data.txt” as applicable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This project is due by &lt;strong&gt;7:00 PM on Monday, December 14, 2020.&lt;/strong&gt; &lt;span style=&#34;color: #81056F; font-weight: bold&#34;&gt; No late work will be accepted.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;You can either run the analysis in RStudio locally on your computer (highly recommended!), since you won’t have to worry about keeping all your work on RStudio’s servers), or use an RStudio.cloud project.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;There is no final exam. This project is your final exam.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The project will &lt;strong&gt;&lt;em&gt;not&lt;/em&gt;&lt;/strong&gt; be graded using a check system, and will be graded by me (the main instructor, not a TA). I will evaluate the following four elements of your project:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Technical skills: Was the project easy? Does it showcase mastery of data analysis?&lt;/li&gt;
&lt;li&gt;Visual design: Was the information smartly conveyed and usable? Was it beautiful?&lt;/li&gt;
&lt;li&gt;Analytic design: Was the analysis appropriate? Was it sensible, given the dataset?&lt;/li&gt;
&lt;li&gt;Story: Did we learn something?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you’ve engaged with the course content and completed the exercises and mini projects throughout the course, you should do just fine with the final project.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;teams&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Teams&lt;/h2&gt;
&lt;p&gt;Most importantly, &lt;strong&gt;you must work with classmates&lt;/strong&gt;. You will work in groups of four people on your project. (There may be some groups of three). Your team must come up with a name and a &lt;strong&gt;Github&lt;/strong&gt; site for your project and labs. Your team will earn the same scores on all projects. To combat additional freeloading, we will use a reporting system. Any team member can email me to report another team member’s lack of participation secretly. See below for details. Two strikes will result in a 25% grade deduction on the mini projects and final project; three strikes will result in a 50% deduction.&lt;/p&gt;
&lt;p&gt;Here’s how we will select teams:&lt;/p&gt;
&lt;p&gt;If you choose to work in teams of your choosing, your group will receive 0 bonus points.&lt;/p&gt;
&lt;p&gt;If you choose to work in a team with a partner, you will be randomly matched with another pair of students and your group will receive 20 bonus points.&lt;/p&gt;
&lt;p&gt;If you choose to work in a &lt;em&gt;randomly assigned&lt;/em&gt; team, your group will receive 40 bonus points.&lt;/p&gt;
&lt;p&gt;You must make this selection by the end of the second full week of class.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;My team sucks; how can I switch teams?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Life is full of small disappointments. While we would love to spend 12 weeks carefully optimizing groups, that would require a collosal amount of effort that would ultimately not yield anything fruitful. You’re stuck.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;My team sucks; how can I punish them for their lack of effort?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;On this front, we will be more supportive. While you have to put up with your team regardless of their quality, you can indicate that your team members are not carrying their fair share by issuing a &lt;strong&gt;strike&lt;/strong&gt;. This processs works as follows:
1. A team member systematically fails to exert effort on collaborative projects (for example, by not showing up for meetings or not communicating, or by simply leeching off others without contributing.)
2. Your frustration reaches a boiling point. You decide this has to stop. You decide to issue a &lt;strong&gt;strike&lt;/strong&gt;
3. You send an email with the following information:
- &lt;code&gt;Subject line:&lt;/code&gt; [SSC442] Strike against [Last name of Recipient]
- &lt;code&gt;Body:&lt;/code&gt; You do &lt;strong&gt;not&lt;/strong&gt; need to provide detailed reasoning. However, you must discuss the actions (plural) you took to remedy the situation before sending the strike email.&lt;/p&gt;
&lt;p&gt;A strike is a serious matter, and will reduce that team member’s grade on joint work by 10%. If any team-member gets strikes from all other members of his or her team, their grade will be reduced by 50%.&lt;/p&gt;
&lt;p&gt;Strikes are &lt;em&gt;anonymous&lt;/em&gt; so that you do not need to fear social retaliation. However, they are not anonymous to allow you to issue them without thoughtful consideration. Perhaps the other person has a serious issue that is preventing them from completing work (e.g., a relative passing away). Please be thoughtful in using this remedy and consider it a last resort.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do I really need to create a team GitHub repository? I don’t like GitHub / programming/ work.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yes, you need to become familiar with GitHub and you and your team will work in a central repository for mini-projects and your final project.&lt;/p&gt;
&lt;p&gt;This is for two reasons. First, computer scientists spent a huge amount of time coming up with the solutions that are implemented in GitHub (and other flavors of &lt;code&gt;git&lt;/code&gt;). Their efforts are largely dedicated toward solving a very concrete goal: how can two people edit the same thing at the same time without creating a ton of new issues. While you could use a paid variant of GitHub (e.g., you could all collaborate over the Microsoft Office suite as implemented by the 360 software that MSU provides), you’d ultimately have the following issues:
1. The software doesn’t support some file types.
2. The software doesn’t autosave versions.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; If someone accidentally deletes something, you’re in trouble.
3. You have to learn an entirely new system every time you change classes / universities / jobs, because said institute doesn’t buy the product you love.&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I’m on a smaller-than-normal team. Does this mean that I have to do more work?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Your instructors are able to count and are aware the teams are imbalanced. Evaluations of final projects will take this into account. While your final product should reflect the best ability of your team, we do not anticipate that the uneven teams will lead to substantively different outputs.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;suggested-outline&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Suggested outline&lt;/h2&gt;
&lt;p&gt;You must write and present your analysis as if presenting to a &lt;strong&gt;C-suite executive&lt;/strong&gt;. If you are not familiar with this terminology, the C-suite includes, e.g., the CEO, CFO, and COO of a given company. Generally speaking, such executives are not particularly analytically oriented, and therefore your explanations need to be clear, consise (their time is valuable) and contain actionable (or valuable) information.&lt;a href=&#34;#fn4&#34; class=&#34;footnote-ref&#34; id=&#34;fnref4&#34;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;
- Concretely, this requires a written memo, which describes the data, analyses, and results. This must be clear and easy to understand for a non-expert in your field. Figures and tables do not apply to the page limit.&lt;/p&gt;
&lt;p&gt;Below is a very loose guide to the sort of content that we expect for the final project. Word limits are suggestions only. Note your final report will be approximately&lt;/p&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Introduction&lt;/h3&gt;
&lt;p&gt;Describe the motivation for this analysis. Briefly describe the dataset, and explain why the analysis you’re undertaking matters for society. (Or matters for some decision-making. You should not feel constrained to asking only “big questions.” The best projects will be narrow-scope but well-defined.) (&lt;strong&gt;≈300 words&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;theory-and-background&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Theory and Background&lt;/h3&gt;
&lt;p&gt;Provide in-depth background about the data of interest and about your analytics question. (&lt;strong&gt;≈300 words&lt;/strong&gt;)&lt;/p&gt;
&lt;div id=&#34;theory&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;“Theory”&lt;/h4&gt;
&lt;p&gt;Provide some theoretical guidance to the functional relationship you hope to explore. If you’re interested on how, say, height affects scoring in the NBA, write down a proposed function that might map height to scoring. Describe how you might look for this unknown relationship in the data.(&lt;strong&gt;≈300 words&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;hypotheses&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Hypotheses&lt;/h4&gt;
&lt;p&gt;Make predictions. Declare what you think will happen. (Note, this will carry over from mini-project 2 and you cannot edit the previously submitted version.) (&lt;strong&gt;≈250 words&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-and-analyses&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data and Analyses&lt;/h3&gt;
&lt;div id=&#34;data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Data&lt;/h4&gt;
&lt;p&gt;Given your motivations, limits on feasibility, and hypotheses, describe the data you use. (&lt;strong&gt;≈100 words&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analyses&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Analyses&lt;/h4&gt;
&lt;p&gt;Generate the analyses relevant to your hypotheses and interests. Here you must include three figures and must describe what they contain in simple, easy to digest language. Why did you visualize these elements? Your analyses also must include brief discussion.&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;As many words as you need to fully describe your analysis and results&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;What caveats should we consider? Do you believe this is a truly causal relationship? Why does any of this matter to the decision-maker? (&lt;strong&gt;≈75 words&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Note that &lt;strong&gt;existing&lt;/strong&gt; is taken to mean that you are not permitted to collect data by interacting with other people. That is not to say that you cannot gather data that previously has not been gathered into a single place—this sort of exercise is encouraged. But you cannot stand with a clipboard outside a store and count visitors (for instance).&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Some products, of course, solve this problem a little bit. For example, Dropbox allows users to share files with ease (of any file type) and saves a (coarse) version history. However, Dropbox does not allow multiple users to work on the same file, and has no way of merging edits together.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;This logic is also why we utilize only free software in this course. It sucks to get really good at, say, &lt;code&gt;SAS&lt;/code&gt; (as I did many years ago) only to realize that the software costs about $10000 and many firms are unwilling to spent that. We will try our best to avoid giving you dead-end skills.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn4&#34;&gt;&lt;p&gt;This exercise provides you with an opportunity to identify your marketable skills and to practice them. I encourage those who will be looking for jobs soon to take this exercise seriously.&lt;a href=&#34;#fnref4&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Project 1</title>
      <link>/assignment/project1/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/assignment/project1/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#part-1-rats-rats-rats.&#34;&gt;Part 1: Rats, rats, rats.&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#instructions&#34;&gt;Instructions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#starter-code&#34;&gt;Starter code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#part-2-data-hunting&#34;&gt;Part 2: Data Hunting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#evaluations&#34;&gt;Evaluations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div class=&#34;fyi&#34;&gt;
&lt;p&gt;Each member of the group should submit a copy of the project to D2L (for ease of evaluation and to ensure communication across the group). Please write your group number and the group members’ names across the top.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;part-1-rats-rats-rats.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 1: Rats, rats, rats.&lt;/h2&gt;
&lt;p&gt;New York City is full of urban wildlife, and rats are one of the city’s most infamous animal mascots. Rats in NYC are plentiful, but they also deliver food, so they’re useful too.&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/PeJUqcbool4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;NYC keeps incredibly detailed data regarding animal sightings, including rats, and &lt;a href=&#34;https://www.kaggle.com/new-york-city/nyc-rat-sightings/data&#34;&gt;it makes this data publicly available&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For this first project, you will use &lt;strong&gt;R and ggplot2&lt;/strong&gt; to tell an interesting story hidden in the data. You must create a story by looking carefully at the data.&lt;/p&gt;
&lt;div id=&#34;instructions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Instructions&lt;/h3&gt;
&lt;p&gt;Here’s what you need to do:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Download&lt;/strong&gt; New York City’s database of rat sightings since 2010:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;/data/Rat_sightings.csv&#34;&gt;&lt;i class=&#34;fas fa-file-csv&#34;&gt;&lt;/i&gt; &lt;code&gt;Rat_sightings.csv&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Summarize&lt;/strong&gt; the data somehow. The raw data has more than 100,000 rows, which means you’ll need to aggregate the data (&lt;code&gt;filter()&lt;/code&gt;, &lt;code&gt;group_by()&lt;/code&gt;, and &lt;code&gt;summarize()&lt;/code&gt; will be your friends). Consider looking at the number of sightings per borough, per year, per dwelling type, etc., or a combination of these, like the change in the number sightings across the 5 boroughs between 2010 and 2016.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Create&lt;/strong&gt; an appropriate visualization based on the data you summarized.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Write&lt;/strong&gt; a memo explaining your process. We are specifically looking for a discussion of the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;What story are you telling with your new graphic?&lt;/li&gt;
&lt;li&gt;How have you applied reasonable standards in visual storytelling?&lt;/li&gt;
&lt;li&gt;What policy implication is there (if any)?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Upload&lt;/strong&gt; the following outputs to D2L:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A PDF file of your memo with your final code and graphic embedded in it.&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; This means you’ll need to do all your coding in an &lt;code&gt;R&lt;/code&gt; Markdown file and embed your code in chunks. Note that Part 2 of this project should be included in this PDF (see below).&lt;/li&gt;
&lt;li&gt;A standalone PDF version of your graphic. Use &lt;code&gt;ggsave(plot_name, filename = &#34;output/blah.pdf&#34;, width = XX, height = XX)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;starter-code&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Starter code&lt;/h3&gt;
&lt;p&gt;I’ve provided some starter code below. A couple comments about it:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;By default, &lt;code&gt;read_csv()&lt;/code&gt; treats cells that are empty or “NA” as missing values. This rat dataset uses “N/A” to mark missing values, so we need to add that as a possible marker of missingness (hence &lt;code&gt;na = c(&#34;&#34;, &#34;NA&#34;, &#34;N/A&#34;)&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;To make life easier, I’ve renamed some of the key variables you might work with. You can rename others if you want.&lt;/li&gt;
&lt;li&gt;I’ve also created a few date-related variables (&lt;code&gt;sighting_year&lt;/code&gt;, &lt;code&gt;sighting_month&lt;/code&gt;, &lt;code&gt;sighting_day&lt;/code&gt;, and &lt;code&gt;sighting_weekday&lt;/code&gt;). You don’t have to use them, but they’re there if you need them. The functions that create these, like &lt;code&gt;year()&lt;/code&gt; and &lt;code&gt;wday()&lt;/code&gt; are part of the &lt;strong&gt;lubridate&lt;/strong&gt; library.&lt;/li&gt;
&lt;li&gt;The date/time variables are formatted like &lt;code&gt;04/03/2017 12:00:00 AM&lt;/code&gt;, which R is not able to automatically parse as a date when reading the CSV file. You can use the &lt;code&gt;mdy_hms()&lt;/code&gt; function in the &lt;strong&gt;lubridate&lt;/strong&gt; library to parse dates that are structured as “month-day-year-hour-minute”. There are also a bunch of other iterations of this function, like &lt;code&gt;ymd()&lt;/code&gt;, &lt;code&gt;dmy()&lt;/code&gt;, etc., for other date formats.&lt;/li&gt;
&lt;li&gt;There’s one row with an unspecified borough, so I filter that out.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(lubridate)
rats_raw &amp;lt;- read_csv(&amp;quot;data/Rat_Sightings.csv&amp;quot;, na = c(&amp;quot;&amp;quot;, &amp;quot;NA&amp;quot;, &amp;quot;N/A&amp;quot;))
# If you get an error that says &amp;quot;All formats failed to parse. No formats
# found&amp;quot;, it&amp;#39;s because the mdy_hms function couldn&amp;#39;t parse the date. The date
# variable *should* be in this format: &amp;quot;04/03/2017 12:00:00 AM&amp;quot;, but in some
# rare instances, it might load without the seconds as &amp;quot;04/03/2017 12:00 AM&amp;quot;.
# If there are no seconds, use mdy_hm() instead of mdy_hms().
rats_clean &amp;lt;- rats_raw %&amp;gt;%
  rename(created_date = `Created Date`,
         location_type = `Location Type`,
         borough = Borough) %&amp;gt;%
  mutate(created_date = mdy_hms(created_date)) %&amp;gt;%
  mutate(sighting_year = year(created_date),
         sighting_month = month(created_date),
         sighting_day = day(created_date),
         sighting_weekday = wday(created_date, label = TRUE, abbr = FALSE)) %&amp;gt;%
  filter(borough != &amp;quot;Unspecified&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You’ll summarize the data with functions from &lt;strong&gt;dplyr&lt;/strong&gt;, including stuff like &lt;code&gt;count()&lt;/code&gt;, &lt;code&gt;arrange()&lt;/code&gt;, &lt;code&gt;filter()&lt;/code&gt;, &lt;code&gt;group_by()&lt;/code&gt;, &lt;code&gt;summarize()&lt;/code&gt;, and &lt;code&gt;mutate()&lt;/code&gt;. Here are some examples of ways to summarize the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# See the count of rat sightings by weekday
rats_clean %&amp;gt;%
  count(sighting_weekday)
# Assign a summarized data frame to an object to use it in a plot
rats_by_weekday &amp;lt;- rats_clean %&amp;gt;%
  count(sighting_weekday, sighting_year)
ggplot(rats_by_weekday, aes(x = fct_rev(sighting_weekday), y = n)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~ sighting_year)
# See the count of rat sightings by weekday and borough
rats_clean %&amp;gt;%
  count(sighting_weekday, borough, sighting_year)
# An alternative to count() is to specify the groups with group_by() and then
# be explicit about how you&amp;#39;re summarizing the groups, such as calculating the
# mean, standard deviation, or number of observations (we do that here with
# `n()`).
rats_clean %&amp;gt;%
  group_by(sighting_weekday, borough) %&amp;gt;%
  summarize(n = n())&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;part-2-data-hunting&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Part 2: Data Hunting&lt;/h2&gt;
&lt;p&gt;For the second part of the project, your task is simple. Your group must identify three different data sources&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; for potential use in your final project. You are not bound to this decision.&lt;/p&gt;
&lt;p&gt;For each, you must write a single paragraph about what about this data interests you. Add this to the memo from Part 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;evaluations&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Evaluations&lt;/h2&gt;
&lt;p&gt;I will evaluate these projects (not the TA). I will only give top marks to those groups showing initiative and cleverness. I will use the following weights for final scores:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Part 1&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Technical difficulty: Does the final project show mastery of the skills we’ve discussed thus far? (10 points)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Appropriateness of visuals: Do the visualizations tell a clear story? Have we learned something? (10 points)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Storytelling: Does your memo clearly convey what you’re doing and why? (9 points)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Part 2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each piece of data (and description) is worth 7 points. (21 points total)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;You can approach this in a couple different ways—you can write the memo and then include the full figure and code at the end, &lt;a href=&#34;https://rud.is/b/2017/09/18/mapping-fall-foliage-with-sf/&#34;&gt;similar to this blog post&lt;/a&gt;, or you can write the memo in an incremental way, describing the different steps of creating the figure, ultimately arriving at a clean final figure, &lt;a href=&#34;https://rudeboybert.github.io/fivethirtyeight/articles/bechdel.html&#34;&gt;like this blog post&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;The three different sources need not be different websites or from different organizations. For example, three different tables from the US Census would be sufficient&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
