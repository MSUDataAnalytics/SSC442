[{"authors":["Ben"],"categories":null,"content":"I am an Assistant Professor at Michigan State University in the Department of Economics and a faculty affiliate in the Social Science Data Analytics Program. Prior to coming to MSU, I was a Postdoctoral Research Fellow at Harvard University and a Visiting Scholar at Harvard Business School. My research focuses on the intersection of psychology and economics \u0026ndash; also known as behavioral economics \u0026ndash; and has appeared in the American Economic Review and Neuron. Prior to coming to Michigan State University, I worked with the U.S. Army to help soldiers become more psychologically resilient.\nI hold a Ph.D. in Social Science (Economics) from the California Institute of Technology (Caltech), and a B.S. in Economics from the University of Oregon.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1627916210,"objectID":"bf008f22d9b0754cde4f6972811c28b7","permalink":"https://ssc442.netlify.app/authors/ben/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/ben/","section":"authors","summary":"I am an Assistant Professor at Michigan State University in the Department of Economics and a faculty affiliate in the Social Science Data Analytics Program. Prior to coming to MSU, I was a Postdoctoral Research Fellow at Harvard University and a Visiting Scholar at Harvard Business School. My research focuses on the intersection of psychology and economics \u0026ndash; also known as behavioral economics \u0026ndash; and has appeared in the American Economic Review and Neuron.","tags":null,"title":"Ben Bushong","type":"authors"},{"authors":["Justin"],"categories":null,"content":"I am an Assistant Professor at Michigan State University who has not yet filled out this description.\nI hold a Ph.D. in Environmental Economics from Duke University, an M.E.M. in Environmental Policy and Economics from Duke University, and a B.S. in Environmental Policy Analysis and City Planning from the University of California at Davis.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1627916210,"objectID":"8422260f0f3251af15c00666a8df9838","permalink":"https://ssc442.netlify.app/authors/justin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/justin/","section":"authors","summary":"I am an Assistant Professor at Michigan State University who has not yet filled out this description.\nI hold a Ph.D. in Environmental Economics from Duke University, an M.E.M. in Environmental Policy and Economics from Duke University, and a B.S. in Environmental Policy Analysis and City Planning from the University of California at Davis.","tags":null,"title":"Justin Kirkpatrick","type":"authors"},{"authors":null,"categories":null,"content":"  In these (modestly) secret pages, I’ve included some resources for those who read the syllabus closely.\nIf you’re stuck with anything or want help with, say, using markdown, you’ll find some basic guidance here. Additionally, there are links throughout to outside resources.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629136382,"objectID":"8939c748f3090c6f91bdac5d32db55ec","permalink":"https://ssc442.netlify.app/resource/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/","section":"resource","summary":"In these (modestly) secret pages, I’ve included some resources for those who read the syllabus closely.\nIf you’re stuck with anything or want help with, say, using markdown, you’ll find some basic guidance here. Additionally, there are links throughout to outside resources.","tags":null,"title":"Helpful resources","type":"docs"},{"authors":null,"categories":null,"content":"  Each week has a set of required readings that you should complete before coming to the (online) Tuesday lecture. That is, you should complete the reading, attend Tuesday class, then do the associated “exercises” (contained within the reading) before Thursday. You will be working each week’s lab between Thursday afternoon and Monday at 11:59 PM (when the labs are due). Don’t forget your weekly writing in between, due Saturday at 11:59pm.\nThe course content is structured as follows. For each topic, we begin with a set of questions that might guide your reading and help frame your thoughts. These questions can serve as helpful starting places for your thinking; they are not representative of the totality of the content and are not intended to be limiting. You should not try to respond to all of these (or any of them if you don’t want to)—they’ll just help you know what to look for and think about as you read.\nAll lecture videos are posted to our SSC442 channel on Mediaspace .\n","date":1598918400,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1627928029,"objectID":"1413f960ec974b9863bc45d887efa8bd","permalink":"https://ssc442.netlify.app/content/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/content/","section":"content","summary":"Each week has a set of required readings that you should complete before coming to the (online) Tuesday lecture. That is, you should complete the reading, attend Tuesday class, then do the associated “exercises” (contained within the reading) before Thursday. You will be working each week’s lab between Thursday afternoon and Monday at 11:59 PM (when the labs are due). Don’t forget your weekly writing in between, due Saturday at 11:59pm.","tags":null,"title":"Readings, lectures, and videos","type":"docs"},{"authors":null,"categories":null,"content":"   Weekly Writings  Weekly Writing Template  Labs Projects Final project   This course is the capstone of the Data Analytics Minor in the College of Social Science. Accordingly, you should—fingers crossed—enjoy data analysis. You will get the most of out this class if you:\nEngage with the readings and lecture materials Regularly use R (aka engage daily or almost every day in some way)  Each type of assignment in this class helps with one of these strategies.\nDownload and save the following files (right-click to Save Link As…)\n  Weekly writing template\n  Lab assignment template\n  Weekly Writings To encourage you to actively engage with the course content, you will write a ≈150 word memorandum about the reading or lecture each week. That’s fairly short: there are ≈250 words on a typical double-spaced page. You must complete eleven of these in the course. I will drop your one lowest weekly writing score. Your actual prompt will be assigned in class, so you must login each day to ensure you get these assignments. To keep you on your toes, we will vary whether these are assigned on Tuesdays or Thursdays. Each week’s weekly writing will be due on D2L by 11:59pm on Saturday\nYou can do a lot of different things with this memo: discuss something you learned from the course content, write about the best or worst data visualization you saw recently, connect the course content to your own work, etc. These reflections let you explore and answer some of the key questions of this course, including:\n When is a link correlational vs causal? How can we still make useful statements about non-causal things? Why do we visualize data? What makes a great data analysis? What makes a bad analysis? How do you choose which kind of analysis method to use? What is the role of the data structure in choosing an analysis? Can we be flexible?  The course content for each day will also include a set of questions specific to that topic. You do not have to answer all (or any) of these questions. That would be impossible. They exist to guide your thinking and to make complex reading more digestible. The specific topic for each week will be assigned in class. (We can’t emphasize this enough.)\nThe TA will grade these mini-exercises using a very simple system:\n ✔+: (11.5 points (115%) in gradebook) Work shows phenomenal thought and engagement with the course content. We will not assign these often. ✔: (10 points (100%) in gradebook) Work is thoughtful, well-written, and shows engagement with the course content. This is the expected level of performance. ✔−: (5 points (50%) in gradebook) Work is hastily composed, too short, and/or only cursorily engages with the course content. This grade signals that you need to improve next time. I will hopefully not assign these often.  (There is an implicit 0 above for work that is not turned in by Saturday at 11:59pm). Notice that this is essentially a pass/fail or completion-based system. We’re not grading your writing ability; we’re not counting the exact number of words you’re writing; and we’re not looking for encyclopedic citations of every single reading to prove that you did indeed read everything. We are looking for thoughtful engagement. Read the material, engage with the work and you’ll get a ✓.\nWeekly Writing Template You will turn these reflections in via D2L. You will write them using R Markdown and this weekly writing template (right-click to Save Link As…) . You must knit your work to a PDF document (this will be what you turn in). D2L will have eleven weekly writing assignments available. Upload your first weekly writing assignment to number 1, your second (regardless of which week you are writing on) to number 2, etc.\n  Labs Each week of the course has fully annotated examples of code that teach and demonstrate how to do specific tasks in R. However, without practicing these principles and making graphics on your own, you won’t remember what you learn.\nPlease do not do labs ahead of time. I am updating the assignments as the semester proceeds, and you may do an entire assignment that is completely changed.\nFor example, to practice working with ggplot2 and making data-based graphics, you will complete a brief set of exercises over a few class sessions. These exercises will have 1–3 short tasks that are directly related to the topic for the week. You need to show that you made a good faith effort to work each question. There will also be a final question which requires significantly more thought and work. This will be where you get to show some creativity and stretch your abilities. Overall, labs will be graded the same check system:\n ✔+: (17.5 points (115%) in gradebook) Exercises are complete. Every task was attempted and answered, and most answers are correct. Knitted document is clean and easy to follow. Work on the final problem shows creativity or is otherwise exceptional. We will not assign these often. ✔: (15 points (100%) in gradebook) Exercises are complete and most answers are correct. This is the expected level of performance. ✔−: (7.5 points (50%) in gradebook) Exercises are less than 70% complete and/or most answers are incorrect. This indicates that you need to improve next time. We will hopefully not assign these often, but subpar work can expect a ✔−.  There is an implicit 0 for any assignment not turned in on time. If you have only partial work, then turn that in for partial credit. As noted in the syllabus, we are not grading your coding ability. We are not checking each line of code to make sure it produces some exact final figure, and we do not expect perfection. Also note that a ✓ does not require 100% success. You will sometimes get stuck with weird errors that you can’t solve, or the demands of pandemic living might occasionally become overwhelming. We are looking for good faith effort. Try hard, engage with the task, and you’ll get a ✓.\nYou may work together on the labs, but you must turn in your own answers. You will turn these labs in via D2L. You will write them using R Markdown and must knit your work to a PDF document.\n Projects To give you practice with the data and design principles you’ll learn in this class, you will complete two projects en route to the overarching final project of the course. Both these mini projects and the final project must be completed in groups.\nThe two (mini) projects are checkpoints to ensure you’re working on your project seriously. They will be graded using a check system:\n ✔+: (55 points (≈115%) in gradebook) Project is phenomenally well-designed and uses advanced R techniques. The project uncovers an important story that is not readily apparent from just looking at the raw data. I will not assign these often. ✔: (50 points (100%) in gradebook) Project is fine, follows most design principles, answers a question from the data, and uses R correctly. This is the expected level of performance. ✔−: (25 points (50%) in gradebook) Project is missing large components, is poorly designed, does not answer a relevant question, and/or uses R incorrectly. This indicates that you need to improve next time. I will hopefully not assign these often.  Because these mini projects give you practice for the final project, we will provide you with substantial feedback on your design and code.\n Final project At the end of the course, you will demonstrate your skills by completing a final project. Complete details for the final project (including past examples of excellent projects) are here. In brief, the final project has the following elements:\nYou must find existing data to analyze.1 Aggregating data from multiple sources is encouraged, but is not required.  You must visualize (at least) three interesting features of that data. Visualizations should aid the reader in understanding something about the data that might not be readily aparent.2  You must come up with some analysis—using tools from the course—which relates your data to either a prediction or a policy conclusion. For example, if you collected data from Major League Baseball games, you could try to “predict” whether a left-hander was pitching based solely on the outcomes of the batsmen.3  You must write your analysis as if presenting to a C-suite executive. If you are not familiar with this terminology, the C-suite includes, e.g., the CEO, CFO, and COO of a given company. Generally speaking, such executives are not particularly analytically oriented, and therefore your explanations need to be clear, consise (their time is valuable) and contain actionable (or valuable) information.  There is no final exam. This project is your final exam.\nThe project will not be graded using a check system, and will be graded by me (the main instructor, not a TA). I will evaluate the following four elements of your project:\nTechnical skills: Was the project easy? Does it showcase mastery of data analysis? Visual design: Was the information smartly conveyed and usable? Was it beautiful? Analytic design: Was the analysis appropriate? Was it sensible, given the dataset? Story: Did we learn something?  If you’ve engaged with the course content and completed the exercises and mini projects throughout the course, you should do just fine with the final project.\n  Note that existing is taken to mean that you are not permitted to collect data by interacting with other people. That is not to say that you cannot gather data that previously has not been gathered into a single place—this sort of exercise is encouraged.↩︎\n Pie charts of any kind will result in a 25% grade deduction.↩︎\n This is an extremely dumb idea for a number of reasons. Moreover, it’s worth mentioning that sports data, while rich, can be overwhelming due to its sheer magnitude and the variety of approaches that can be applied. Use with caution.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1627928029,"objectID":"3aa23ffb1eb3dedbe4d8a9c2165e2c58","permalink":"https://ssc442.netlify.app/assignment/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/assignment/","section":"assignment","summary":"Weekly Writings  Weekly Writing Template  Labs Projects Final project   This course is the capstone of the Data Analytics Minor in the College of Social Science. Accordingly, you should—fingers crossed—enjoy data analysis. You will get the most of out this class if you:\nEngage with the readings and lecture materials Regularly use R (aka engage daily or almost every day in some way)  Each type of assignment in this class helps with one of these strategies.","tags":null,"title":"Assignments and Evaluations","type":"docs"},{"authors":null,"categories":null,"content":"  This section contains the content covered in Thursday lectures and some annotated R code that you can use as a reference for creating your own work. The intention is that in the Content section, you will sequentially build up your understanding of R and data analytics; here, you can see how all the pieces work together.\nVisit this section after you have finished the readings in the Content section and any supplemental lecture videos.\nIn class, we will work with R in real time and post the day’s examples in a video linked at the end.1 Hopefully, you’ll find it useful to watch the practice of coding. You’ll also notice me make all sorts of errors. This is normal. If you’re finding yourself making lots of errors and generally struggling to get your code to run, start by working with the final code and reverse-engineer the solution you want.\nAll lecture videos are posted to our SSC442 channel on Mediaspace \u0026lt;fa-s .\n I might edit these videos for length and because I like to talk to myself when I’m programming. Also, too much swearing.↩︎\n   ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1629136382,"objectID":"00e8826988eea7dfc8b8047b4c0184ce","permalink":"https://ssc442.netlify.app/example/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/example/","section":"example","summary":"This section contains the content covered in Thursday lectures and some annotated R code that you can use as a reference for creating your own work. The intention is that in the Content section, you will sequentially build up your understanding of R and data analytics; here, you can see how all the pieces work together.\nVisit this section after you have finished the readings in the Content section and any supplemental lecture videos.","tags":null,"title":"Examples","type":"docs"},{"authors":null,"categories":null,"content":"   Programming basics  Conditional expressions Defining functions Namespaces For-loops Vectorization and functionals Exercises    You must turn in a PDF document of your R markdown code. Submit this to D2L by 11:59 PM on Sunday, September 5th.\nNOTE:\nAs you read through this assignment, practice with each of the examples (copy-paste them into an empty R script and run them). At the bottom of this page you will find the questions that comprise the assignment. These questions apply and expand on the topics and R functions in the assignment. Many assignments will have this same structure: some instruction preceeding specific exercises.\nRight-click to download the .Rmd template for labs . Please save the template into the labs folder in the SSC442 folder on your local hard drive. If you don’t have a nice file structure setup for the course, please make one now. It will save you from headaches in the future.\n Programming basics We teach R because it greatly facilitates data analysis. By coding in R, we can efficiently perform exploratory data analysis, build data analysis pipelines, and prepare data visualization to communicate results. However, R is not just a data analysis environment but a programming language. Advanced R programmers can develop complex packages and even improve R itself. But we do not cover advanced programming in this course. Nonetheless, in this section, we introduce three key programming concepts: conditional expressions, for-loops, and functions. These are not just key building blocks for advanced programming, but are sometimes useful during data analysis. We also note that there are several functions that are widely used to program in R but that we will not cover directly in this course. These include split, cut, do.call, and Reduce, as well as the data.table package. These are worth learning if you plan to become an expert R programmer.\nConditional expressions Conditional expressions are one of the basic features of programming. They are used for what is called flow control. The most common conditional expression is the if-else statement. In R, we can actually perform quite a bit of data analysis without conditionals. However, they do come up occasionally, and you will need them once you start writing your own functions and packages.\nHere is a very simple example showing the general structure of an if-else statement. The basic idea is to print the reciprocal of a unless a is 0:\na \u0026lt;- 0 if(a!=0){ print(1/a) } else{ print(\u0026quot;No reciprocal for 0.\u0026quot;) } ## [1] \u0026quot;No reciprocal for 0.\u0026quot; Let’s look at one more example using the US murders data frame:\nlibrary(dslabs) data(murders) murder_rate \u0026lt;- murders$total / murders$population*100000 Here is a very simple example that tells us which states, if any, have a murder rate lower than 0.5 per 100,000. The if statement protects us from the case in which no state satisfies the condition.\nind \u0026lt;- which.min(murder_rate) if(murder_rate[ind] \u0026lt; 0.5){ print(murders$state[ind]) } else{ print(\u0026quot;No state has murder rate that low\u0026quot;) } ## [1] \u0026quot;Vermont\u0026quot; If we try it again with a rate of 0.25, we get a different answer:\nif(murder_rate[ind] \u0026lt; 0.25){ print(murders$state[ind]) } else{ print(\u0026quot;No state has a murder rate that low.\u0026quot;) } ## [1] \u0026quot;No state has a murder rate that low.\u0026quot; A related function that is very useful is ifelse. This function takes three arguments: a logical and two possible answers. If the logical is TRUE, the value in the second argument is returned and if FALSE, the value in the third argument is returned. Here is an example:\na \u0026lt;- 0 ifelse(a \u0026gt; 0, 1/a, NA) ## [1] NA The function is particularly useful because it works on vectors. It examines each entry of the logical vector and returns elements from the vector provided in the second argument, if the entry is TRUE, or elements from the vector provided in the third argument, if the entry is FALSE.\na \u0026lt;- c(0, 1, 2, -4, 5) result \u0026lt;- ifelse(a \u0026gt; 0, 1/a, NA) This table helps us see what happened:    a  is_a_positive  answer1  answer2  result      0  FALSE  Inf  NA  NA    1  TRUE  1.00  NA  1.0    2  TRUE  0.50  NA  0.5    -4  FALSE  -0.25  NA  NA    5  TRUE  0.20  NA  0.2     Here is an example of how this function can be readily used to replace all the missing values in a vector with zeros:\ndata(na_example) no_nas \u0026lt;- ifelse(is.na(na_example), 0, na_example) sum(is.na(no_nas)) ## [1] 0 Two other useful functions are any and all. The any function takes a vector of logicals and returns TRUE if any of the entries is TRUE. The all function takes a vector of logicals and returns TRUE if all of the entries are TRUE. Here is an example:\nz \u0026lt;- c(TRUE, TRUE, FALSE) any(z) ## [1] TRUE all(z) ## [1] FALSE  Defining functions As you become more experienced, you will find yourself needing to perform the same operations over and over. A simple example is computing averages. We can compute the average of a vector x using the sum and length functions: sum(x)/length(x). Because we do this repeatedly, it is much more efficient to write a function that performs this operation. This particular operation is so common that someone already wrote the mean function and it is included in base R. However, you will encounter situations in which the function does not already exist, so R permits you to write your own. A simple version of a function that computes the average can be defined like this:\navg \u0026lt;- function(x){ s \u0026lt;- sum(x) n \u0026lt;- length(x) s/n } Now avg is a function that computes the mean:\nx \u0026lt;- 1:100 identical(mean(x), avg(x)) ## [1] TRUE Notice that variables defined inside a function are not saved in the workspace. So while we use s and n when we call avg, the values are created and changed only during the call. Here is an illustrative example:\ns \u0026lt;- 3 avg(1:10) ## [1] 5.5 s ## [1] 3 Note how s is still 3 after we call avg.\nIn general, functions are objects, so we assign them to variable names with \u0026lt;-. The function function tells R you are about to define a function. The general form of a function definition looks like this:\nmy_function \u0026lt;- function(VARIABLE_NAME){ perform operations on VARIABLE_NAME and calculate VALUE VALUE } The functions you define can have multiple arguments as well as default values. For example, we can define a function that computes either the arithmetic or geometric average depending on a user defined variable like this:\navg \u0026lt;- function(x, arithmetic = TRUE){ n \u0026lt;- length(x) ifelse(arithmetic, sum(x)/n, prod(x)^(1/n)) } We will learn more about how to create functions through experience as we face more complex tasks.\n Namespaces Once you start becoming more of an R expert user, you will likely need to load several add-on packages for some of your analysis. Once you start doing this, it is likely that two packages use the same name for two different functions. And often these functions do completely different things. In fact, you have already encountered this because both dplyr and the R-base stats package define a filter function. There are five other examples in dplyr. We know this because when we first load dplyr we see the following message:\nThe following objects are masked from ‘package:stats’: filter, lag The following objects are masked from ‘package:base’: intersect, setdiff, setequal, union So what does R do when we type filter? Does it use the dplyr function or the stats function? From our previous work we know it uses the dplyr one. But what if we want to use the stats version?\nThese functions live in different namespaces. R will follow a certain order when searching for a function in these namespaces. You can see the order by typing:\nsearch() The first entry in this list is the global environment which includes all the objects you define.\nSo what if we want to use the stats filter instead of the dplyr filter but dplyr appears first in the search list? You can force the use of a specific namespace by using double colons (::) like this:\nstats::filter If we want to be absolutely sure that we use the dplyr filter, we can use\ndplyr::filter Also note that if we want to use a function in a package without loading the entire package, we can use the double colon as well.\nFor more on this more advanced topic we recommend the R packages book1.\n For-loops If we had to write this section in a single sentence, it would be: Don’t use for-loops. Looping is intuitive, but R is designed to provide more computationally efficient solutions. For-loops should be considered a quick-and-dirty way to get an answer. But, hey, you live your own life. Below we provide a brief overview to for-looping.\nThe formula for the sum of the series \\(1+2+\\dots+n\\) is \\(n(n+1)/2\\). What if we weren’t sure that was the right function? How could we check? Using what we learned about functions we can create one that computes the \\(S_n\\):\ncompute_s_n \u0026lt;- function(n){ x \u0026lt;- 1:n sum(x) } How can we compute \\(S_n\\) for various values of \\(n\\), say \\(n=1,\\dots,25\\)? Do we write 25 lines of code calling compute_s_n? No, that is what for-loops are for in programming. In this case, we are performing exactly the same task over and over, and the only thing that is changing is the value of \\(n\\). For-loops let us define the range that our variable takes (in our example \\(n=1,\\dots,10\\)), then change the value and evaluate expression as you loop.\nPerhaps the simplest example of a for-loop is this useless piece of code:\nfor(i in 1:5){ print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 Here is the for-loop we would write for our \\(S_n\\) example:\nm \u0026lt;- 25 s_n \u0026lt;- vector(length = m) # create an empty vector for(n in 1:m){ s_n[n] \u0026lt;- compute_s_n(n) } In each iteration \\(n=1\\), \\(n=2\\), etc…, we compute \\(S_n\\) and store it in the \\(n\\)th entry of s_n.\nNow we can create a plot to search for a pattern:\nn \u0026lt;- 1:m plot(n, s_n) If you noticed that it appears to be a quadratic, you are on the right track because the formula is \\(n(n+1)/2\\). --\n Vectorization and functionals Although for-loops are an important concept to understand, in R we rarely use them. As you learn more R, you will realize that vectorization is preferred over for-loops since it results in shorter and clearer code. (It’s also vastly more efficient computationally, which can matter as your data grows.) A vectorized function is a function that will apply the same operation on each of the vectors.\nx \u0026lt;- 1:10 sqrt(x) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278 y \u0026lt;- 1:10 x*y ## [1] 1 4 9 16 25 36 49 64 81 100 To make this calculation, there is no need for for-loops. However, not all functions work this way. For instance, the function we just wrote, compute_s_n, does not work element-wise since it is expecting a scalar. This piece of code does not run the function on each entry of n:\nn \u0026lt;- 1:25 compute_s_n(n) Functionals are functions that help us apply the same function to each entry in a vector, matrix, data frame, or list. Here we cover the functional that operates on numeric, logical, and character vectors: sapply.\nThe function sapply permits us to perform element-wise operations on any function. Here is how it works:\nx \u0026lt;- 1:10 sapply(x, sqrt) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278 Each element of x is passed on to the function sqrt and the result is returned. These results are concatenated. In this case, the result is a vector of the same length as the original x. This implies that the for-loop above can be written as follows:\nn \u0026lt;- 1:25 s_n \u0026lt;- sapply(n, compute_s_n) Other functionals are apply, lapply, tapply, mapply, vapply, and replicate. We mostly use sapply, apply, and replicate in this book, but we recommend familiarizing yourselves with the others as they can be very useful.\n Exercises This is your first weekly lab assignment. Each lab assignment will need to be done in Rmarkdown using the lab template, just right-click and Save As…Start a new folder on your drive for this course, and inside that a new folder for lab assignments, and inside that a new folder for Lab No. 1. Rmarkdown will place some intermediate files in that folder, so leaving .Rmd files on your desktop will make things messy, fast.\nOnce you’ve saved the file, open it up in Rstudio.\n Change the title to “Lab 1”\n Put your name on it\n Leave the date alone. That little `r Sys.time(...)` will ask R to return the date (with M-D-Y formatting), which Rmarkdown will put in as if you had typed in the actual date.\n When you type ## 1. Text of..., Markdown will recognize “1. Text of” as a header and will automatically make it big.\n So please copy the number and text of the question you are answering here.  Next will be the ```{r q1} text that will be in gray. R will recognize this as code and will treat it as such. Anything run in that block will have an output.\n If you want to see what the code will do, copy the code and paste it into the gray area. Then, click the green right arrow in the top-right corner of the gray code chunk. It should show you the results.\n Use the results (plus your understanding of the code) to answer the question\n  With each completed question, clidk the “Knit” button up above the script window. Rmarkdown will create a .pdf for you of your work (as long as it doesn’t hit any R errors). Knit often to make sure you haven’t hit an error!\n The \\newpage line is a Latex command (the program that makes the typesetting look nice). It will start a new pdf page.\n On the next page, copy question #2 to a new header using ##.\n Once done, render one last .pdf and turn it in on D2L!\n  EXERCISES\nIn your first code chunk, load the package library tidyverse, which you will need for Question 8. Always load all your package libraries at the top, in the first code chunk!\n What will this conditional expression return and why?\n  x \u0026lt;- c(1,2,-3,4) if(all(x\u0026gt;0)){ print(\u0026quot;All Postives\u0026quot;) } else{ print(\u0026quot;Not all positives\u0026quot;) } Which of the following expressions is always FALSE when at least one entry of a logical vector x is TRUE?  all(x) any(x) any(!x) all(!x)  The function nchar tells you how many characters long a character vector is. Write a line of code that assigns to the object new_names the state abbreviation when the state name is longer than 8 characters.\n Create a function sum_n that for any given value, say \\(n\\), computes the sum of the integers from 1 to n (inclusive). Use the function to determine the sum of integers from 1 to 5,000.\n Create a function altman_plot that takes two arguments, x and y, and plots the difference against the sum. Use it to make an altman plot of x \u0026lt;- c(5,7,9) and y \u0026lt;- c(10,11,12). When your function creates the plot, it will output automatically in your Rmarkdown knitted .pdf.\n After running the code below, what is the value of x and why?\n  x \u0026lt;- 3 my_func \u0026lt;- function(y){ x \u0026lt;- 5 y+5 } Write a function compute_s_n that for any given \\(n\\) computes the sum \\(S_n = 1^2 + 2^2 + 3^2 + \\dots n^2\\). Report the value of the sum when \\(n=10\\).\n Define an empty numerical vector s_n of size 25 using s_n \u0026lt;- vector(\"numeric\", 25) and store in the results of \\(S_1, S_2, \\dots S_{25}\\) using a for-loop.\n Repeat exercise 8, but this time use sapply.\n Repeat exercise 8, but this time use map_dbl.\n Plot \\(S_n\\) versus \\(n\\). Use points defined by \\(n=1,\\dots,25\\).\n Confirm that the formula for this sum is \\(S_n= n(n+1)(2n+1)/6\\).\n      http://r-pkgs.had.co.nz/namespace.html↩︎\n   ","date":1610668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629128785,"objectID":"5e86e029830987df59b0fed9d67636a4","permalink":"https://ssc442.netlify.app/assignment/00-assignment/","publishdate":"2021-01-15T00:00:00Z","relpermalink":"/assignment/00-assignment/","section":"assignment","summary":"Programming basics  Conditional expressions Defining functions Namespaces For-loops Vectorization and functionals Exercises    You must turn in a PDF document of your R markdown code. Submit this to D2L by 11:59 PM on Sunday, September 5th.\nNOTE:\nAs you read through this assignment, practice with each of the examples (copy-paste them into an empty R script and run them). At the bottom of this page you will find the questions that comprise the assignment.","tags":null,"title":"Programming Basics in R","type":"docs"},{"authors":null,"categories":null,"content":"   Install R Install RStudio Install tidyverse Install tinytex   As mentioned in the syllabus, you will do all of your work in this class with the open source programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—–R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.\nHopefully you’re well-versed in dealing with these things, but if you’re lost, here’s how you install the required software for the course.\nInstall R First you need to install R itself (the engine).\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\n Click on “Download R for XXX”, where XXX is either Mac or Windows:\n If you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is also 4.0.0) and download it.\n If you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n  Double click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\n If you use macOS, download and install XQuartz. You do not need to do this on Windows.\n   Install RStudio Next, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\n The website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n Double click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n  Double click on RStudio to run it (check your applications folder or start menu).\n Install tidyverse R packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including the ever-present ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel. Hopefully you’ve experienced installing packages before now; if not, consider this a crash course!\n Install tinytex When you knit to PDF, R uses a special scientific typesetting program named LaTeX.2\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB. To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nHere’s how to install tinytex so you can knit to pretty PDFs:\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console. Run tinytex::install_tinytex() in the console. Wait for a bit while R downloads and installs everything you need. The end! You should now be able to knit to PDF.    It’s a goofy name, but CRAN is where most R packages—and R itself—lives.↩︎\n Pronounced “lay-tek” for those who are correct; or “lah-tex” to those who love goofy nerdy pronunciation. Technically speaking, the x is the “ch” sound in “Bach”, but most people just say it as “k”. While either saying “lay” or “lah” is correct, “layteks” is frowned upon because it clearly shows you’re not cool.↩︎\n   ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629136382,"objectID":"efb59c0882a965443ffcbafa3cd27ca6","permalink":"https://ssc442.netlify.app/resource/install/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/resource/install/","section":"resource","summary":"Install R Install RStudio Install tidyverse Install tinytex   As mentioned in the syllabus, you will do all of your work in this class with the open source programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—–R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code.","tags":null,"title":"Installing R, RStudio, tidyverse, and tinytex","type":"docs"},{"authors":null,"categories":null,"content":"   Introduction to Examples  Getting started with R and RStudio The R console Scripts RStudio  The panes Key bindings Running commands while editing scripts  Installing R packages Rmarkdown Lecture Video    Introduction to Examples Examples in this class are designed to be presented in-class. Accordingly, the notes here are not comprehensive. Instead, they are intended to guide students through\nI’m also aware that my writing is dry and lifeless. If you’re reading this online without the advantage of seeing it in person, don’t worry—I’ll be “funnier” in class.1\nGetting started with R and RStudio R is not a programming language like C or Java. It was not created by software engineers for software development. Instead, it was developed by statisticians as an interactive environment for data analysis. You can read the full history in the paper A Brief History of S2. The interactivity is an indispensable feature in data science because, as you will soon learn, the ability to quickly explore data is a necessity for success in this field. However, like in other programming languages, you can save your work as scripts that can be easily executed at any moment. These scripts serve as a record of the analysis you performed, a key feature that facilitates reproducible work. If you are an expert programmer, you should not expect R to follow the conventions you are used—assuming this will leave you disappointed. If you are patient, you will come to appreciate the unequal power of R when it comes to data analysis and data visualization.\nOther attractive features of R are:\nR is free and open source3. It runs on all major platforms: Windows, Mac OS, UNIX/Linux. Scripts and data objects can be shared seamlessly across platforms. There is a large, growing, and active community of R users and, as a result, there are numerous resources for learning and asking questions4 5 6. It is easy for others to contribute add-ons which enables developers to share software implementations of new data science methodologies. The latest methods and tools are developed in R for a wide variety of disciplines and since social science is so broad, R is one of the few tools that spans the varied social sciences.   The R console Interactive data analysis usually occurs on the R console that executes commands as you type them. There are several ways to gain access to an R console. One way is to simply start R on your computer. The console looks something like this:\nAs a quick example, try using the console to calculate a 15% tip on a meal that cost $19.71:7\n0.15 * 19.71  ## [1] 2.9565 Note that in this course (at least, on most browsers), grey boxes are used to show R code typed into the R console. The symbol ## is used to denote what the R console outputs.\n Scripts One of the great advantages of R over point-and-click analysis software is that you can save your work as scripts. You can edit and save these scripts using a text editor. The material in this course was developed using the interactive integrated development environment (IDE) RStudio8. RStudio includes an editor with many R specific features, a console to execute your code, and other useful panes, including one to show figures.\nMost web-based R consoles also provide a pane to edit scripts, but not all permit you to save the scripts for later use. On the upper-right part of this webpage you’ll see a little button with the R logo. You can access a web-based console there.\n RStudio RStudio will be our launching pad for data science projects. It not only provides an editor for us to create and edit our scripts but also provides many other useful tools. In this section, we go over some of the basics.\nThe panes When you start RStudio for the first time, you will see three panes. The left pane shows the R console. On the right, the top pane includes tabs such as Environment and History, while the bottom pane shows five tabs: File, Plots, Packages, Help, and Viewer (these tabs may change in new versions). You can click on each tab to move across the different features.\nTo start a new script, you can click on File, then New File, then R Script.\nThis starts a new pane on the left and it is here where you can start writing your script.\n Key bindings Many tasks we perform with the mouse can be achieved with a combination of key strokes instead. These keyboard versions for performing tasks are referred to as key bindings. For example, we just showed how to use the mouse to start a new script, but you can also use a key binding: Ctrl+Shift+N on Windows and command+shift+N on the Mac.\nAlthough in this tutorial we often show how to use the mouse, we highly recommend that you memorize key bindings for the operations you use most. RStudio provides a useful cheat sheet with the most widely used commands. You might want to keep this handy so you can look up key-bindings when you find yourself performing repetitive point-and-clicking.\n Running commands while editing scripts There are many editors specifically made for coding. These are useful because color and indentation are automatically added to make code more readable. RStudio is one of these editors, and it was specifically developed for R. One of the main advantages provided by RStudio over other editors is that we can test our code easily as we edit our scripts. Below we show an example.\nLet’s start by opening a new script as we did before. A next step is to give the script a name. We can do this through the editor by saving the current new unnamed script. To do this, click on the save icon or use the key binding Ctrl+S on Windows and command+S on the Mac.\nWhen you ask for the document to be saved for the first time, RStudio will prompt you for a name. A good convention is to use a descriptive name, with lower case letters, no spaces, only hyphens to separate words, and then followed by the suffix .R. We will call this script my-first-script.R.\nNow we are ready to start editing our first script. The first lines of code in an R script are dedicated to loading the libraries we will use. Another useful RStudio feature is that once we type library() it starts auto-completing with libraries that we have installed. Note what happens when we type library(ti):\nAnother feature you may have noticed is that when you type library( the second parenthesis is automatically added. This will help you avoid one of the most common errors in coding: forgetting to close a parenthesis.\nNow we can continue to write code. As an example, we will make a graph showing murder totals versus population totals by state. Once you are done writing the code needed to make this plot, you can try it out by executing the code. To do this, click on the Run button on the upper right side of the editing pane. You can also use the key binding: Ctrl+Shift+Enter on Windows or command+shift+return on the Mac.\nOnce you run the code, you will see it appear in the R console and, in this case, the generated plot appears in the plots console. Note that the plot console has a useful interface that permits you to click back and forward across different plots, zoom in to the plot, or save the plots as files.\nTo run one line at a time instead of the entire script, you can use Control-Enter on Windows and command-return on the Mac.\nSETUP TIP\nChange the option Save workspace to .RData on exit to Never and uncheck the Restore .RData into workspace at start. By default, when you exit R saves all the objects you have created into a file called .RData. This is done so that when you restart the session in the same folder, it will load these objects. I find that this causes confusion especially when sharing code with colleagues or peers.\n   Installing R packages The functionality provided by a fresh install of R is only a small fraction of what is possible. In fact, we refer to what you get after your first install as base R. The extra functionality comes from add-ons available from developers. There are currently hundreds of these available from CRAN and many others shared via other repositories such as GitHub. However, because not everybody needs all available functionality, R instead makes different components available via packages. R makes it very easy to install packages from within R. For example, to install the dslabs package, which we use to share datasets and code related to this book, you would type:\ninstall.packages(\u0026quot;dslabs\u0026quot;) In RStudio, you can navigate to the Tools tab and select install packages. We can then load the package into our R sessions using the library function:\nlibrary(dslabs) ## ## Attaching package: \u0026#39;dslabs\u0026#39; ## The following object is masked from \u0026#39;package:gapminder\u0026#39;: ## ## gapminder As you go through this book, you will see that we load packages without installing them. This is because once you install a package, it remains installed and only needs to be loaded with library. The package remains loaded until we quit the R session. If you try to load a package and get an error, it probably means you need to install it first.\nWe can install more than one package at once by feeding a character vector to this function:\ninstall.packages(c(\u0026quot;tidyverse\u0026quot;, \u0026quot;dslabs\u0026quot;)) One advantage of using RStudio is that it auto-completes package names once you start typing, which is helpful when you do not remember the exact spelling of the package. Once you select your package, we recommend selecting all the defaults. Note that installing tidyverse actually installs several packages. This commonly occurs when a package has dependencies, or uses functions from other packages. When you load a package using library, you also load its dependencies.\nOnce packages are installed, you can load them into R and you do not need to install them again, unless you install a fresh version of R. Remember packages are installed in R not RStudio.\nIt is helpful to keep a list of all the packages you need for your work in a script because if you need to perform a fresh install of R, you can re-install all your packages by simply running a script.\nYou can see all the packages you have installed using the following function:\ninstalled.packages() As we move through this course, we will constantly be adding to our toolbox of packages. Accordingly, you will need to keep track to ensure you have the requisite package for any given lecture.\n Rmarkdown Markdown is a general-purpose syntax for laying out documents. Rmarkdown is a combination of R and markdown, as the name implies. When using markdown, one can define headers and tables using specific notation, and depending on the rendering engine, the headers and tables (and a whole lot more) are customized. In fact, this whole website is built in R using Rmarkdown (and a lot of add-ons like Hugo and blogdown). In other contexts, the rendering engine may recognize that your headers are likely to be entries in a table of contents, and does so for you. The table of contents at the top of this document is built from the markdown headers.\nThe power of Rmarkdown is that it lets us mix formatted text with R code. That is, you can have a section of the document that understands R code, and a separate section right after that discusses the results from the R code.\nTry it out using the Weekly Writing Template. If it opens in your web browser, just right-click the link and select Save As…. Make sure you save the file to its own folder on your hard drive. In converting your Rmarkdown .Rmd file to a .pdf, your system will make multiple interim files9. It also creates folders to store the output of any plots or graphics you create with your R code.\nIf we have time today, let’s open the template linked above and see what happens when we select “knit to pdf”.\n Lecture Video Video from lecture hosted on Mediaspace \n   Comments from previous classes indicate that I am not, in fact, funny.↩︎\n https://pdfs.semanticscholar.org/9b48/46f192aa37ca122cfabb1ed1b59866d8bfda.pdf↩︎\n https://opensource.org/history↩︎\n https://stats.stackexchange.com/questions/138/free-resources-for-learning-r↩︎\n https://www.r-project.org/help.html↩︎\n https://stackoverflow.com/documentation/r/topics↩︎\n But probably tip more than 15%. Times are tough, man.↩︎\n https://www.rstudio.com/↩︎\n Specifically, knitr will create an intermediate .md file which is then processed with Pandoc using Latex to create a pdf. Whew!↩︎\n   ","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630504385,"objectID":"bbf45ee74dc37731d7fd26186d3a77a6","permalink":"https://ssc442.netlify.app/example/00-example/","publishdate":"2021-01-09T00:00:00Z","relpermalink":"/example/00-example/","section":"example","summary":"Introduction to Examples  Getting started with R and RStudio The R console Scripts RStudio  The panes Key bindings Running commands while editing scripts  Installing R packages Rmarkdown Lecture Video    Introduction to Examples Examples in this class are designed to be presented in-class. Accordingly, the notes here are not comprehensive. Instead, they are intended to guide students through\nI’m also aware that my writing is dry and lifeless.","tags":null,"title":"Working with R and RStudio","type":"docs"},{"authors":null,"categories":null,"content":"   Accessibility Colors Fonts Graphic assets  Images Vectors Vectors, photos, videos, and other assets    Accessibility  Vischeck: Simulate how your images look for people with different forms of colorblindness (web-based) Color Oracle: Simulate how your images look for people with different forms of colorblindness (desktop-based, more types of colorblindness)   Colors  Adobe Color: Create, share, and explore rule-based and custom color palettes. ColourLovers: Like Facebook for color palettes. viridis: Percetually uniform color scales. Scientific Colour-Maps: Perceptually uniform color scales like viridis. Use them in R with scico. ColorBrewer: Sequential, diverging, and qualitative color palettes that take accessibility into account. Colorgorical: Create color palettes based on fancy mathematical rules for perceptual distance. Colorpicker for data: More fancy mathematical rules for color palettes (explanation). iWantHue: Yet another perceptual distance-based color palette builder. Photochrome: Word-based color pallettes. PolicyViz Design Color Tools: Large collection of useful color resources   Fonts  Google Fonts: Huge collection of free, well-made fonts. The Ultimate Collection of Google Font Pairings: A list of great, well-designed font pairings from all those fonts hosted by Google (for when you’re looking for good contrasting or complementary fonts).   Graphic assets Images  Use the Creative Commons filters on Google Images or Flickr Unsplash Pexels Pixabay StockSnap.io Burst freephotos.cc   Vectors  Noun Project: Thousands of free simple vector images aiconica: 1,000+ vector icons Vecteezy: Thousands of free vector images   Vectors, photos, videos, and other assets  Stockio    ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627916210,"objectID":"16fd04c4714e3d096bffcf19e6c524ca","permalink":"https://ssc442.netlify.app/resource/design/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/design/","section":"resource","summary":"Accessibility Colors Fonts Graphic assets  Images Vectors Vectors, photos, videos, and other assets    Accessibility  Vischeck: Simulate how your images look for people with different forms of colorblindness (web-based) Color Oracle: Simulate how your images look for people with different forms of colorblindness (desktop-based, more types of colorblindness)   Colors  Adobe Color: Create, share, and explore rule-based and custom color palettes. ColourLovers: Like Facebook for color palettes.","tags":null,"title":"Design","type":"docs"},{"authors":null,"categories":null,"content":"   Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references   Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting     Type… …or… …to get    Some text in a paragraph. More text in the next paragraph. Always use empty lines between paragraphs.  Some text in a paragraph.\nMore text in the next paragraph. Always use empty lines between paragraphs.\n  *Italic* _Italic_ Italic  **Bold** __Bold__ Bold  # Heading 1  Heading 1   ## Heading 2  Heading 2   ### Heading 3  Heading 3   (Go up to heading level 6 with ######)    [Link text](http://www.example.com)  Link text  ![Image caption](/path/to/image.png)    `Inline code` with backticks  Inline code with backticks  \u0026gt; Blockquote   Blockquote\n  - Things in - an unordered - list * Things in * an unordered * list  Things in an unordered list   1. Things in 2. an ordered 3. list 1) Things in 2) an ordered 3) list Things in an ordered list   Horizontal line --- Horizontal line *** Horizontal line\n     Math Markdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here.\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\n    Type… …to get    Based on the DAG, the regression model for estimating the effect of education on wages is $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, or $\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon$. Based on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\).    To put an equation on its own line in a display block, wrap it in double dollar signs, like this:\nType…\nThe quadratic equation was an important part of high school math: $$ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} $$ But now we just use computers to solve for $x$. …to get…\n The quadratic equation was an important part of high school math:\n\\[ x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a} \\]\nBut now we just use computers to solve for \\(x\\).\n Because dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs $5.75 and this other costs $40”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”.\n Tables There are 4 different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like pander (use pandoc.table()) or knitr (use kable()). The two most common are simple tables and pipe tables. You should look at the full documentation here.\nFor simple tables, type…\n Right Left Center Default ------- ------ ---------- ------- 12 12 12 12 123 123 123 123 1 1 1 1 Table: Caption goes here …to get…\n Caption goes here  Right Left Center Default    12 12 12 12  123 123 123 123  1 1 1 1    For pipe tables, type…\n| Right | Left | Default | Center | |------:|:-----|---------|:------:| | 12 | 12 | 12 | 12 | | 123 | 123 | 123 | 123 | | 1 | 1 | 1 | 1 | Table: Caption goes here …to get…\n Caption goes here  Right Left Default Center    12 12 12 12  123 123 123 123  1 1 1 1     Footnotes There are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags]. [^1]: This is a note. [^note-on-dags]: DAGs are neat. And here\u0026#39;s more of the document. …to get…\n Here is a footnote reference1 and here is another.2\nAnd here’s more of the document.\n  This is a note.↩︎   DAGs are neat.↩︎     You can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\nType…\nCausal inference is neat.^[But it can be hard too!] …to get…\n Causal inference is neat.1\n  But it can be hard too!↩︎      Front matter You can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; --- You can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n--- title: \u0026quot;My cool title: a subtitle\u0026quot; --- If you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n--- title: \u0026#39;An evaluation of \u0026quot;scare quotes\u0026quot;\u0026#39; ---  Citations One of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\nAdd a bibliography: entry to the YAML metadata:\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib --- Choose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n--- title: Title of your document date: \u0026quot;January 13, 2020\u0026quot; author: \u0026quot;Your name\u0026quot; bibliography: name_of_file.bib csl: \u0026quot;https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\u0026quot; --- Some of the most common CSLs are:\n Chicago author-date Chicago note-bibliography Chicago full note-bibliography (no shortened notes or ibids) APA 7th edition MLA 8th edition  Cite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\n    Type… …to get…    Causal inference is neat [@Rohrer:2018; @AngristPischke:2015]. Causal inference is neat (Rohrer 2018; Angrist and Pischke 2015).  Causal inference is neat [see @Rohrer:2018, p. 34; also @AngristPischke:2015, chapter 1]. Causal inference is neat (see Rohrer 2018, 34; also Angrist and Pischke 2015, chap. 1).  Angrist and Pischke say causal inference is neat [-@AngristPischke:2015; see also @Rohrer:2018]. Angrist and Pischke say causal inference is neat (2015; see also Rohrer 2018).  @AngristPischke:2015 [chapter 1] say causal inference is neat, and @Rohrer:2018 agrees. Angrist and Pischke (2015, chap. 1) say causal inference is neat, and Rohrer (2018) agrees.    After compiling, you should have a perfectly formatted bibliography added to the end of your document too:\n Angrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629.\n   Other references These websites have additional details and examples and practice tools:\n CommonMark’s Markdown tutorial: A quick interactive Markdown tutorial. Markdown tutorial: Another interactive tutorial to practice using Markdown. Markdown cheatsheet: Useful one-page reminder of Markdown syntax. The Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown.   ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629136382,"objectID":"dcf6a5ae191a1cca4f4c8ff8ac114538","permalink":"https://ssc442.netlify.app/resource/markdown/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/resource/markdown/","section":"resource","summary":"Basic Markdown formatting Math Tables Footnotes Front matter Citations Other references   Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)\nBasic Markdown formatting     Type… …or… …to get    Some text in a paragraph.","tags":null,"title":"Using Markdown","type":"docs"},{"authors":null,"categories":null,"content":"   Interesting and excellent real world examples How to select the appropriate chart type General resources Visualization in Excel Visualization in Tableau   Interesting and excellent real world examples  The Stories Behind a Line Australia as 100 people: You can make something like this with d3 and the potato project. Marrying Later, Staying Single Longer   How to select the appropriate chart type Many people have created many useful tools for selecting the correct chart type for a given dataset or question. Here are some of the best:\n The Data Visualisation Catalogue: Descriptions, explanations, examples, and tools for creating 60 different types of visualizations. The Data Viz Project: Descriptions and examples for 150 different types of visualizations. Also allows you to search by data shape and chart function (comparison, correlation, distribution, geographical, part to whole, trend over time, etc.). From Data to Viz: A decision tree for dozens of chart types with links to R and Python code. The Chartmaker Directory: Examples of how to create 51 different types of visualizations in 31 different software packages, including Excel, Tableau, and R. R Graph Catalog: R code for 124 ggplot graphs. Emery’s Essentials: Descriptions and examples of 26 different chart types.   General resources  Storytelling with Data: Blog and site full of resources by Cole Nussbaumer Knaflic. Ann K. Emery’s blog: Blog and tutorials by Ann Emery. Evergreen Data: Helful resources by Stephanie Evergreen. PolicyViz: Regular podcast and site full of helpful resources by Jon Schwabisch. Visualising Data: Fantastic collection of visualization resources, articles, and tutorials by Andy Kirk. Info We Trust: Detailed explorations of visualizations by RJ Andrews, including a beautiful visual history of the field. FlowingData: Blog by Nathan Yau. Information is Beautiful: Blog by David McCandless. Junk Charts: Blog by Kaiser Fung. WTF Visualizations: Visualizations that make you ask “wtf?” The Data Visualization Checklist: A helpful set of criteria for grading the effectiveness of a graphic. Data Literacy Starter Kit: Compilation of resources to become data literate by Laura Calloway. Seeing Data: A series of research projects about perceptions and visualizations.   Visualization in Excel  How to Build Data Visualizations in Excel: Detailed tutorials for creating 14 different visualizations in Excel. Ann Emery’s tutorials: Fantastic series of tutorials for creating charts in Excel.   Visualization in Tableau Because it is focused entirely on visualization (and because it’s a well-supported commercial product), Tableau has a phenomenal library of tutorials and training videos. There’s a helpful collections of videos here, as well.\n ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627916210,"objectID":"ca403ba352e0871f06b445d2470037b3","permalink":"https://ssc442.netlify.app/resource/visualization/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/visualization/","section":"resource","summary":"Interesting and excellent real world examples How to select the appropriate chart type General resources Visualization in Excel Visualization in Tableau   Interesting and excellent real world examples  The Stories Behind a Line Australia as 100 people: You can make something like this with d3 and the potato project. Marrying Later, Staying Single Longer   How to select the appropriate chart type Many people have created many useful tools for selecting the correct chart type for a given dataset or question.","tags":null,"title":"Visualization","type":"docs"},{"authors":null,"categories":null,"content":"   Key terms Add chunks Chunk names Chunk options Inline chunks Output formats   R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).\nThe documentation for R Markdown is extremely comprehensive, and their tutorials and cheatsheets are excellent—rely on those.\nHere are the most important things you’ll need to know about R Markdown in this class:\nKey terms  Document: A Markdown file where you type stuff\n Chunk: A piece of R code that is included in your document. It looks like this:\n```{r} # Code goes here ``` There must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not knit correctly.\n Knit: When you “knit” a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the knitted document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can knit by clicking on the “Knit” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows.\n   Add chunks There are three ways to insert chunks:\n Press ⌘⌥I on macOS or control + alt + I on Windows\n Click on the “Insert” button at the top of the editor window\n Manually type all the backticks and curly braces (don’t do this)\n   Chunk names You can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\nTo add a name, include it immediately after the {r in the first line of the chunk. Names cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.\n```{r name-of-this-chunk} # Code goes here ```  Chunk options There are a bunch of different options you can set for each chunk. You can see a complete list in the RMarkdown Reference Guide or at knitr’s website.\nOptions go inside the {r} section of the chunk:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE} # Code goes here ``` The most common chunk options are these:\n fig.width=5 and fig.height=3 (or whatever number you want): Set the dimensions for figures echo=FALSE: The code is not shown in the final document, but the results are message=FALSE: Any messages that R generates (like all the notes that appear after you load a package) are omitted warning=FALSE: Any warnings that R generates are omitted include=FALSE: The chunk still runs, but the code and results are not included in the final document  You can also set chunk options by clicking on the little gear icon in the top right corner of any chunk:\n Inline chunks You can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r find-avg-mpg, echo=FALSE} avg_mpg \u0026lt;- mean(mtcars$mpg) ``` The average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon. … would knit into this:\n The average fuel efficiency for cars from 1974 was 20.1 miles per gallon.\n  Output formats You can specify what kind of document you create when you knit in the YAML front matter.\ntitle: \u0026quot;My document\u0026quot; output: html_document: default pdf_document: default word_document: default You can also click on the down arrow on the “Knit” button to choose the output and generate the appropriate YAML. If you click on the gear icon next to the “Knit” button and choose “Output options”, you change settings for each specific output type, like default figure dimensions or whether or not a table of contents is included.\nThe first output type listed under output: will be what is generated when you click on the “Knit” button or press the keyboard shortcut (⌘⇧K on macOS; control + shift + K on Windows). If you choose a different output with the “Knit” button menu, that output will be moved to the top of the output section.\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical output section might look like:\n--- title: \u0026quot;My document\u0026quot; author: \u0026quot;My name\u0026quot; date: \u0026quot;January 13, 2020\u0026quot; output: html_document: toc: yes fig_caption: yes fig_height: 8 fig_width: 10 pdf_document: latex_engine: xelatex # More modern PDF typesetting engine toc: yes word_document: toc: yes fig_caption: yes fig_height: 4 fig_width: 5 ---  ","date":1578873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627916210,"objectID":"00c0b36df90b91640842af65d1311657","permalink":"https://ssc442.netlify.app/resource/rmarkdown/","publishdate":"2020-01-13T00:00:00Z","relpermalink":"/resource/rmarkdown/","section":"resource","summary":"Key terms Add chunks Chunk names Chunk options Inline chunks Output formats   R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown.","tags":null,"title":"Using R Markdown","type":"docs"},{"authors":null,"categories":null,"content":"   R style conventions Main style things to pay attention to for this class  Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments    R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times.\n Main style things to pay attention to for this class  Important note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty\u0026gt;10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n Spacing  See the “Spacing” section in the tidyverse style guide.\n Put spaces after commas (like in regular English):\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg , cty \u0026gt; 10) filter(mpg ,cty \u0026gt; 10) filter(mpg,cty \u0026gt; 10) Put spaces around operators like +, -, \u0026gt;, =, etc.:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter(mpg, cty\u0026gt;10) filter(mpg, cty\u0026gt; 10) filter(mpg, cty \u0026gt;10) Don’t put spaces around parentheses that are parts of functions:\n# Good filter(mpg, cty \u0026gt; 10) # Bad filter (mpg, cty \u0026gt; 10) filter ( mpg, cty \u0026gt; 10) filter( mpg, cty \u0026gt; 10 )  Long lines  See the “Long lines” section in the tidyverse style guide.\n It’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” \u0026gt; “Global Options” \u0026gt; “Code” \u0026gt; “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n# Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Good filter(mpg, cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) # Bad filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;)) # Good filter(mpg, cty \u0026gt; 10, class %in% c(\u0026quot;compact\u0026quot;, \u0026quot;pickup\u0026quot;, \u0026quot;midsize\u0026quot;, \u0026quot;subcompact\u0026quot;, \u0026quot;suv\u0026quot;, \u0026quot;2seater\u0026quot;, \u0026quot;minivan\u0026quot;))  Pipes (%\u0026gt;%) and ggplot layers (+) Put each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n# Good ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() # Super bad and won\u0026#39;t even work ggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw() Put each step in a dplyr pipeline on separate lines, with the %\u0026gt;% at the end of the line, indented with two spaces:\n# Good mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy)) # Super bad and won\u0026#39;t even work mpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% group_by(class) %\u0026gt;% summarize(avg_hwy = mean(hwy))  Comments  See the “Comments” section in the tidyverse style guide.\n Comments should start with a comment symbol and a single space: #\n# Good #Bad #Bad If the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group You can add extra spaces to get inline comments to align, if you want:\nmpg %\u0026gt;% filter(cty \u0026gt; 10) %\u0026gt;% # Only rows where cty is 10 + group_by(class) %\u0026gt;% # Divide into class groups summarize(avg_hwy = mean(hwy)) # Find the average hwy in each group If the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” \u0026gt; “Reflow comment”\n# Good # Happy families are all alike; every unhappy family is unhappy in its own way. # Everything was in confusion in the Oblonskys’ house. The wife had discovered # that the husband was carrying on an intrigue with a French girl, who had been # a governess in their family, and she had announced to her husband that she # could not go on living in the same house with him. This position of affairs # had now lasted three days, and not only the husband and wife themselves, but # all the members of their family and household, were painfully conscious of it. # Bad # Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it. Though, if you’re dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose.\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627916210,"objectID":"f4734e734c67442efdc8d228e91ad766","permalink":"https://ssc442.netlify.app/resource/style/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/style/","section":"resource","summary":"R style conventions Main style things to pay attention to for this class  Spacing Long lines Pipes (%\u0026gt;%) and ggplot layers (+) Comments    R style conventions R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\nmpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty\u0026gt;10, class==\u0026quot;compact\u0026quot;) filter(mpg,cty\u0026gt;10,class==\u0026quot;compact\u0026quot;) mpg %\u0026gt;% filter(cty \u0026gt; 10, class == \u0026quot;compact\u0026quot;) filter ( mpg,cty\u0026gt;10, class==\u0026quot;compact\u0026quot; ) But you’ll notice that only a few of those iterations (the first three) are easily readable.","tags":null,"title":"R style suggestions","type":"docs"},{"authors":null,"categories":null,"content":"  Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.\nUnzipping files on macOS is trivial, but unzipping files on Windows can mess you up if you don’t pay careful attention. Here’s a helpful guide to unzipping files on both macOS and Windows.\nUnzipping files on macOS Double click on the downloaded .zip file. macOS will automatically create a new folder with the same name as the .zip file, and all the file’s contents will be inside. Double click on the RStudio Project file (.Rproj) to get started.\n Unzipping files on Windows tl;dr: Right click on the .zip file, select “Extract All…”, and work with the resulting unzipped folder.\nUnlike macOS, Windows does not automatically unzip things for you. If you double click on the .zip file, Windows will show you what’s inside, but it will do so without actually extracting anything. This can be is incredibly confusing! Here’s what it looks like—the only clues that this folder is really a .zip file are that there’s a “Compressed Folder Tools” tab at the top, and there’s a “Ratio” column that shows how much each file is compressed.\nIt is very tempting to try to open files from this view. However, if you do, things will break and you won’t be able to correctly work with any of the files in the zipped folder. If you open the R Project file, for instance, RStudio will point to a bizarre working directory buried deep in some temporary folder:\nYou most likely won’t be able to open any data files or save anything, which will be frustrating.\nInstead, you need to right click on the .zip file and select “Extract All…”:\nThen choose where you want to unzip all the files and click on “Extract”\nYou should then finally have a real folder with all the contents of the zipped file. Open the R Project file and RStudio will point to the correct working directory and everything will work.\n ","date":1588723200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627916210,"objectID":"c14c352fd4c4ab8c12a3cd60b30b9d8c","permalink":"https://ssc442.netlify.app/resource/unzipping/","publishdate":"2020-05-06T00:00:00Z","relpermalink":"/resource/unzipping/","section":"resource","summary":"Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.","tags":null,"title":"Unzipping files","type":"docs"},{"authors":null,"categories":null,"content":"  There are a ton of places to find data related to public policy and administration (as well as data on pretty much any topic you want) online:\n Data is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\n Google Dataset Search: Google indexes thousands of public datasets; search for them here.\n Kaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public. See, for example, the European Soccer Database, the Salem Witchcraft Dataset or results from an Oreo flavors taste test.\n 360Giving: Dozens of British foundations follow a standard file format for sharing grant data and have made that data available online.\n US City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing.\n Political science and economics datasets: There’s a wealth of data available for political science- and economics-related topics:\n François Briatte’s extensive curated lists: Includes data from/about intergovernmental organizations (IGOs), nongovernmental organizations (NGOs), public opinion surveys, parliaments and legislatures, wars, human rights, elections, and municipalities. Thomas Leeper’s list of political science datasets: Good short list of useful datasets, divided by type of data (country-level data, survey data, social media data, event data, text data, etc.). Erik Gahner’s list of political science datasets: Huge list of useful datasets, divided by topic (governance, elections, policy, political elites, etc.)   ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627916210,"objectID":"2210aa8aeb5724b04bdf63d813d61030","permalink":"https://ssc442.netlify.app/resource/data/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/resource/data/","section":"resource","summary":"There are a ton of places to find data related to public policy and administration (as well as data on pretty much any topic you want) online:\n Data is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\n Google Dataset Search: Google indexes thousands of public datasets; search for them here.","tags":null,"title":"Data","type":"docs"},{"authors":null,"categories":null,"content":"   Contacting Me What is This Course and Can / Should You Take It? What This Course is Not Success in this Course Course materials  R and RStudio Online Help  Evaluations and Grades  Class Participation Academic honesty Grading  Resources Accommodations Mental Health and Wellbeing Mandated Reporting Acknowledgements Miscellanea  TA Office Hours Using Office Hours Letters of Recommendation / References    Instructor  Prof. Ben Bushong  25A Marshall-Adams Hall  bbushong@msu.edu  @benbushong   Course details  Tuesday and Thursday  September – December, 2021  12:40pm - 2:00pm  Slack   Contacting me Please consider whether your question is short and concrete; if so, feel free to email me. If your question is deep, vague, interesting, or otherwise complex, please come to office hours or we can discuss in class. See syllabus for details.\n  Contacting Me I have moved this up front in a (likely unsuccessful) attempt to minimize our collective headache.\nEmail is a blessing and a curse. Instant communication is wonderful, but often email is the wrong medium to have a productive conversation about course material. Moreover, I get a lot of emails. This means that I am frequently triaging emails into two piles: “my house is burning down” and “everything else”. Your email is unlikely to make the former pile. So, asking questions about course material is always best done in-class or in office hours. Students always roll their eyes when professors say things like that, but it’s true that if you have a question, it’s very likely someone else has the same question.\nThat said, it benefits us both if any emails you send are clear and effective. There’s an (unfunny) joke in academia that professors (i) read an email until they find a question; (ii) respond to that question and; (iii) ignore the rest of the email. I won’t do this, but I think it is helpful to assume that the person on the receiving end of an email will operate this way.\nSome general tips:\n Always include [SSC442] in your subject line (brackets included). Use a short but informative subject line. For example: [SSC442] Final Project Grading Use your University-supplied email for University business. This helps me know who you are. One topic, one email. If you have multiple things to discuss, and you anticipate followup replies, it is best to split them into two emails so that the threads do not get cluttered. Ask direct questions. If you’re asking multiple questions in one email, use a bulleted list. Don’t ask questions that are answered by reading the syllabus. This drives me nuts. I’ve also found that students are overly polite in emails. I suppose it may be intimidating to email a professor, and you should try to match the style that the professor prefers, but I view email for a course as a casual form of communication. Said another way: get to the point. Students often send an entire paragraph introducing themselves, but if you use your University email address, and add the course name in the subject, I will already know who you are. Here’s an example of an excellent email:   Subject: [SSC442] Lab, Question 2, Typo\nHi Prof. Bushong,\nThere seems to be a typo in the Lab on Question 2. The problem says to use a column of data that doesn’t seem to exist. Can you correct this or which should we use?\nThanks, Student McStudentFace\n Now on to your regularly scheduled syllabus.\n What is This Course and Can / Should You Take It? Innovations in statistical learning have created many engineering breakthroughs. From real time voice recognition to automatic categorization (and in some cases production) of news stories, machine learning is transforming the way we live our lives. These techniques are, at their heart, novel ways to work with data, and therefore they should have implications for social science. This course explores the intersection of statistical learning (or machine learning) and social science and aims to answer two primary questions about these new techniques:\nHow does statistical learning work and what kinds of statistical guarantees can be made about the performance of statistical-learning algorithms?\n How can statistical learning be used to answer questions that interest social science researchers, such as testing theories or improving social policy?\n  In order to address these questions, we will cover so-called “standard” techniques such as supervised and unsupervised learning, statistical learning theory and nonparametric and Bayesian approaches. If it were up to me, this course would be titled “Statistical Learning for Social Scientists”—I believe this provides a more appropriate guide to the content of this course. And while this class will cover these novel statistical methodologies in some detail, it is not a substitute for the appropriate class in Computer Science or Statistics. Nor is this a class that teaches specific skills for the job market. Rather, this class will teach you to think about data analytics broadly. We will spend a great deal of time learning how to interpret the output of statistical learning algorithms and approaches, and will also spend a great deal of time on better understanding the basic ideas in statistical learning. This, of course, comes at some cost in terms of time spent on learning computational and/or programming skills.\nEnrollment for credit in this course is simply not suitable for those unprepared in or uninterested in elementary statistical theory no matter the intensity of interest in machine learning or “Big Data”. Really.\nYou will be required to understand elementary mathematics in this course and should have at least some exposure to statistical theory. The class is front-loaded technically: early lectures are more mathematically oriented, while later lectures are more applied.\nThe topics covered in this course are listed later in this document. I will assign readings sparingly from Introduction to Statistical Learning, henceforth referred to as ISL. This text is available for free online and, for those who like physical books, can be purchased for about $25. Importantly, the lectures deviate a fair bit from the reading, and thus you will rely on your course notes more than you might in other classes.\nIf—after you have read this document and preferably after attending the first lecture—you have any questions about whether this course is appropriate for you, please come talk to me.\n What This Course is Not The focus of this course is conceptual. The goal is to create a working understanding of when and how tools from computer science and statistics can be profitably applied to problems in social science. Though students will be required to apply some of these techniques themselves, this course is not…\n…a replacement for EC420 or a course in causal inference.\nAs social scientists, we are most often concerned with causal inference in order to analyze and write policies. Statistical learning and the other methods we will discuss in this course are generally not well-suited to these problems, and while I’ll give a short overview of standard methods, this is only to build intuitions. Ultimately, this course has a different focus and you should still pursue standard methodological insights from your home departments.\n…a course on the computational aspects of the underlying methods.\nThere are many important innovations that have made machine learning techniques computationally feasible. We will not discuss these, as there are computer science courses better equipped to cover them. When appropriate, we will discuss whether something is computable, and we will even give rough approximations of the amount of time required (e.g. P vs NP). But we will not discuss how optimizers work or best practices in programming.\n…a primer on the nitty-gritty of how to use these tools or a way to pad your resume.\nThe mechanics of implementation, whether it be programming languages or learning to use APIs, will not be covered in any satisfying level of depth. Students will be expected to learn most of the programming skills on their own. Specifically, while there will be some material to remind you of basic R commands, this is not a good course for people who are simply looking to learn the mechanics of programming. This course is designed to get you to use both traditional analytics and, eventually, machine learning tools. We will do some review of basic programming, and you will have the opportunity to explore topics that interest you through a final project, but ultimately this is a course that largely focuses on the theoretical and practical aspects of statistical learning as applied to social science and not a class on programming.\nPerhaps most importantly, this course is an attempt to push undergraduate education toward the frontiers in social science. Accordingly, please allow some messiness. Some topics may be underdeveloped for a given person’s passions, but given the wide variety of technical skills and overall interests, this is a near certainty. Both the challenge and opportunity of this area comes from the fact that there is no fully developed, wholly unifying framework. Our collective struggle—me from teaching, you from learning—will ultimately bear fruit.\n Success in this Course I promise, you are equipped to succeed in this course.\nLearning R can be difficult at first. Like learning a new language—Spanish, French, or Mandarin—it takes dedication and perseverance. Hadley Wickham (the chief data scientist at RStudio and the author of some amazing R packages you’ll be using like) ggplot2—made this wise observation:\n It’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n Even experienced programmers (like me) find themselves bashing their heads against seemingly intractable errors.1 If you’re finding yourself bashing your head against a wall and not making progress, try the following. First, take a break. Sometimes you just need space to see an error. Next, talk to classmates. Finally, if you genuinely cannot see the solution, e-mail the TA. But, honestly, it’s probably just a typo.\n\n Course materials The course website can be found at https://ssc442.netlify.app (but you know that. You’re on it right now.)\nAll of the readings and software in this class are free. There are free online version of all the texts including Introduction to Statistical Learning and R / RStudio are free. (Don’t pay for RStudio.) We will reference outside readings and there exist paper versions of some “books” but you won’t need to buy anything2\nR and RStudio You will do all of your analysis with the open source (and free!) programming language R. You will use RStudio as the main program to access R. I find it helpful to think of R as an engine and RStudio as a car dashboard—R handles all the calculations produces the actual statistics and graphical output, while RStudio provides a nice interface for running R code.\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can use the free RStudio.cloud service, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R. We recommend this for those who may be switching between computers and are trying to get some work done. That said, while RStudio.cloud is convenient, it can be slow and it is not designed to be able to handle larger datasets or more complicated analysis and graphics. You also can’t use your own custom fonts with RStudio.cloud.3 And, generally speaking, you should have (from the prerequisite course) sufficient experience to make your R work. If not, over the course of the semester, you’ll probably want to get around to installing R, RStudio, and other R packages on your computer and wean yourself off of RStudio.cloud. If you plan on making a career out of data science, you should consider this a necessary step.\nYou can find instructions for installing R, RStudio, and all the tidyverse packages here. And you may find some other goodies.\n Online Help Data science and statistical programming can be difficult. Computers are stupid: they do only what you ask, not what you intend. This means that little errors in your code can cause hours of headache, even if you’ve been doing this stuff for years!\nFortunately there are tons of online resources to help you with this. Two of the most important are StackOverflow (a Q\u0026amp;A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nIf you use Twitter, you can try posting R-related questions and content with #rstats. The community there is exceptionally generous and helpful.\nSearching for help with R on Google can sometimes be tricky because the program name is, um, a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”). Likewise, whenever using a specific package, try searching for that package name instead of the letter “r” (e.g. “ggplot scatterplot”). Good, concise searches are generally more effective.\nHelp with Using R: There are some excellent additional tutorials on R available through Rstudio Clould Primers.\n  Evaluations and Grades Your grade in this course will be based on attendance/participation, labs, weekly writings, and a final project.\nThe general breakdown will be approximately 55% for labs, participation, and weekly writings, and 45% for projects (see below for specific details). The primary focus of the course is a final project; this requires two “mini-projects” to ensure you’re making satisfactory progress. Assignment of numeric grades will follow the standard, where ties (e.g., 91.5%) are rounded to favor the student. Evaluations (read: grades) are designed not to deter anyone from taking this course who might otherwise be interested, but will be taken seriously.\nWeekly writings are intended to be an easy way to get some points. Labs will be short homework assignments that require you to do something practical using a basic statistical language. Support will be provided for the R language only. You must have access to computing resources and the ability to program basic statistical analyses. As mentioned above, this course will not teach you how to program or how to write code in a specific language. If you are unprepared to do implement basic statistical coding, please take (or retake) PLS202. I highly encourage seeking coding advice from those who instruct computer science courses – it’s their job and they are better at it than I am. I’ll try to provide a good service, but I’m really not an expert in computer science.\nMore in-depth descriptions for all the assignments are on the assignments page. As the course progresses, the assignments themselves will be posted within that page.\nTo Recap:\n   Assignment Points Percent    Class Participation 20 4%  Weekly Writings (11 x 10), drop lowest 100 20%  Labs (11 x 15), drop lowest 150 30%  Mini project 1 50 10%  Mini project 2 50 10%  Final project 130 26%  Total 500 —        Grade Range Grade Range    4.0 92-100% 2.0 72-76%  3.5 87-91% 1.5 67-72%  3.0 82-87% 1.0 62-67%  2.5 77-81% 0.0 bad-66%     Class Participation Participation can take many forms. The bare minimum can best be described as “showing your presence and having some engagement.” To encourage some form of participation, I will often pose questions to the class. I am not above bribery - your response to these extra credit questions will earn extra credit points, up to 5, for participation. Thus, you can easily pad your score by (1) meeting the minimum participation requirements such that I know you are present, and (2) earning extra credit by responding to in-class extra credit prompts. I will clearly state which questions are extra credit. When it comes to participation, wrong answers get the same credit as right answers. We are here to learn. If you knew everything already, you wouldn’t be in the class.\n Academic honesty Violation of MSU’s Spartan Code of Honor will result in a grade of 0.0 in the course. Moreover, I am required by MSU policy to report suspected cases of academic dishonesty for possible disciplinary action.4\n Grading All grades are considered final. Any request for a re-grade beyond simple point-tallying mistakes will require that the entire assignment be re-graded. Any points previously awarded may be changed in either direction in the re-grade.\n  Resources Mental health concerns or stressful events may lead to diminished academic performance or reduce a student’s ability to participate in daily activities. Services are available to assist you with addressing these and other concerns you may be experiencing. You can learn more about the broad range of confidential mental health services available on campus via the Counseling \u0026amp; Psychiatric Services (CAPS) website at www.caps.msu.edu.\n Accommodations This class is designed to be fairly accomodating without a student asking. However, if you need a special accommodation for a disability, religious observance, or have any other concerns about your ability to perform well in this course, please contact me immediately so that we can discuss the issue and make appropriate arrangements.\nMichigan State University is committed to providing equal opportunity for participation in all programs, services and activities. Requests for accommodations by persons with disabilities may be made by contacting the Resource Center for Persons with Disabilities at 517-884-RCPD or on the web at here. Once your eligibility for an accommodation has been determined, you will be issued a verified individual services accommodation (“VISA”) form. Please present this form to me at the start of the term and/or two weeks prior to the accommodation date (test, project, etc). Requests received after this date will be honored whenever possible.\n Mental Health and Wellbeing Things for you might be especially hard right now.\nI’m fully committed to making sure that you learn everything you were hoping to learn from this class. I will make whatever accommodations I can to help you finish your exercises, do well on your projects, and learn and understand the class material. Under ordinary conditions, I am flexible and lenient with grading and course expectations when students face difficult challenges. Given the challenges of the past two years, that flexibility and leniency is intensified.\nIf you feel like you’re behind or not understanding everything, do not suffer in silence. Please contact me. I’m available at e-mail.\n Mandated Reporting Essays, journals, and other materials submitted for this class are generally considered confidential pursuant to the University’s student record policies. However, students should be aware that University employees, including instructors, may not be able to maintain confidentiality when it conflicts with their responsibility to report certain issues to protect the health and safety of MSU community members and others. As the instructor, I must report the following information to other University offices (including the Department of Police and Public Safety) if you share it with me: • Suspected child abuse/neglect, even if this maltreatment happened when you were a child; • Allegations of sexual assault, relationship violence, stalking, or sexual harassment; and • Credible threats of harm to oneself or to others. These reports may trigger contact from a campus official who will want to talk with you about the incident that you have shared. In almost all cases, it will be your decision whether you wish to speak with that individual. If you would like to talk about these events in a more confidential setting, you are encouraged to make an appointment with the MSU Counseling and Psychiatric Services.\n Acknowledgements This syllabus and course structure was developed in tandem with Prof. Justin Kirkpatrick. All credit goes to Prof. Kirkpatrick; all errors are my own.\n Miscellanea D2L will be used sparingly for submission of weekly writings and assignments and distribution of grades.\nTA Office Hours Our TA, Xueshi Wang, has generously offered to host (digital) office hours on Wednesdays between 10:10 and 11:10. Zoom link below. She can be contacted via email using wangxu36 @ msu.edu\n Using Office Hours Please use my office hours. It would be remarkable if you didn’t need some assistance with the material, and I am here to help. One of the benefits of open office hours is to accommodate many students at once; if fellow students are “in my office”, please join in and feel very free to show up in groups. Office hours will move around a little bit throughout the semester to attempt to meet the needs of all students.\nIn addition to drop-in office hours, I always have sign-up office hours for advising and other purposes. As a general rule, please first seek course-related help from the drop-in office hours. However, if my scheduled office hours are always infeasible for you, let me know, and then I may encourage you to make appointments with me. I ask that you schedule your studying so that you are prepared to ask questions during office hours – office hours are not a lecture and if you’re not prepared with questions we will end up awkwardly staring at each other for an hour until you leave.\nSome gentle requests regarding office hours and on contacting me. First, my office hours end sharply at the end, so don’t arrive 10 minutes before the scheduled end and expect a full session. Please arrive early if you have lengthy questions, or if you don’t want to risk not having time due to others’ questions. You are free to ask me some stuff by e-mail, (e.g. a typo or something on a handout), but please know e-mail sucks for answering many types of questions. “How do I do this lab?” or “What’s up with R?” are short questions with long answers. Come to office hours.\n Letters of Recommendation / References If you are applying for further study or another pursuit that requires letters of recommendation and you’d like me to recommend you, I will be glad to write a letter on your behalf if your final grade is a 4.0. Grades below a 4.0 may be handled on a case-by-case basis. In addition, you should have held at least three substantial conversations with me about the course material or other academic subjects over the course of the semester.\n   By the end of the course, you will realize that 1) I make many many many errors; 2) that I frequently cannot remember a command or the correct syntax; and 3) that none of this matters too much in the big picture because I know the broad approaches I’m trying to take and I know how to Google stuff. Learn from my idiocy.↩︎\n If you’ve got money to burn, you can buy me a burrito.↩︎\n This bothers me way more than it should.↩︎\n So just don’t cheat or plagiarize. This is an easy problem to avoid.↩︎\n   ","date":1630454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630424348,"objectID":"e4d5a4a79239f08c6ad0d7cbf1be756c","permalink":"https://ssc442.netlify.app/syllabus/","publishdate":"2021-09-01T00:00:00Z","relpermalink":"/syllabus/","section":"","summary":"Contacting Me What is This Course and Can / Should You Take It? What This Course is Not Success in this Course Course materials  R and RStudio Online Help  Evaluations and Grades  Class Participation Academic honesty Grading  Resources Accommodations Mental Health and Wellbeing Mandated Reporting Acknowledgements Miscellanea  TA Office Hours Using Office Hours Letters of Recommendation / References    Instructor  Prof.","tags":null,"title":"Syllabus","type":"page"},{"authors":null,"categories":null,"content":"   Requirements Teams Suggested outline  Introduction Theory and Background Data and Analyses Conclusion    Requirements Data analytics is inherently a hands-on endeavor. Thus, the final project for this class is hands-on. As per the overview page, the final project has the following elements:\nFor your final project in this class, you will analyze existing data in some area of interest to you.1 Aggregating data from multiple sources is encouraged, but is not required.  You must visualize (at least) three interesting features of that data. Visualizations should aid the reader in understanding something about the data that might not be readily aparent.[^4]\n You must come up with some analysis—using tools from the course—which relates your data to either a prediction or a policy conclusion. For example, if you collected data from Major League Baseball games, you could try to “predict” whether a left-hander was pitching based solely on the outcomes of the batsmen.\n You will submit three things via D2L:\n   A PDF of your report (see the outline below for details of what this needs to contain) rendered from your R Markdown. You might want to write the prose-heavy sections in a word processor like Word or Google Docs and copy/paste the text into your R Markdown document, since RStudio doesn’t have a nice spell checker or grammar checker. This should have no visible R code, warnings, or messages in it. To do this, you must set echo = FALSE in the code chunk options knitr::opts_chunk$set(echo = FALSE, ...) at the beginning of your document template before you knit.\n The same PDF as above, but with all the R code in it (set echo = TRUE at the beginning of your document and reknit the file). Please label files in an obvious way.\n A CSV file of your data; or a link to the data online if your code pulls from the internet. This must be a separate file titled “data.csv” or “data.txt” as applicable.\n  This project is due by 11:59 PM on Tuesday, April 27th, 2021. No late work will be accepted. For real. MSU has grading deadlines and I’ve given you every second that can be spared.\nThere is no final exam. This project is your final exam.\nThe project will not be graded using a check system, and will be graded by me (the main instructor, not a TA). I will evaluate the following four elements of your project:\nTechnical skills: Was the project easy? Does it showcase mastery of data analysis? (20%)\n Visual design: Was the information smartly conveyed and usable? Was it beautiful? (25%)\n Analytic design: Was the analysis appropriate? Was it sensible, given the dataset? (20%)\n Story: Did we learn something? (25%)\n Following instructions: Did you surpress R code as asked? Did you submit a separate datafile and label it correctly? (10%)\n  If you’ve engaged with the course content and completed the exercises and mini projects throughout the course, you should do just fine with the final project.\n Teams  My team sucks; how can I punish them for their lack of effort?\n On this front, we will be more supportive. While you have to put up with your team regardless of their quality, you can indicate that your team members are not carrying their fair share by issuing a strike. This processs works as follows: 1. A team member systematically fails to exert effort on collaborative projects (for example, by not showing up for meetings or not communicating, or by simply leeching off others without contributing.) 2. Your frustration reaches a boiling point. You decide this has to stop. You decide to issue a strike 3. You send an email with the following information: - Subject line: [SSC442] Strike against [Last name of Recipient] - Body: You do not need to provide detailed reasoning. However, you must discuss the actions (plural) you took to remedy the situation before sending the strike email.\nA strike is a serious matter, and will reduce that team member’s grade on joint work by 10%. If any team-member gets strikes from all other members of his or her team, their grade will be reduced by 50%.\nStrikes are anonymous so that you do not need to fear social retaliation. However, they are not anonymous to allow you to issue them without thoughtful consideration. Perhaps the other person has a serious issue that is preventing them from completing work (e.g., a relative passing away). Please be thoughtful in using this remedy and consider it a last resort.\nDo I really need to create a team GitHub repository? I don't like GitHub / programming/ work. --  I’m on a smaller-than-normal team. Does this mean that I have to do more work?\n Your instructors are able to count and are aware the teams are imbalanced. Evaluations of final projects will take this into account. While your final product should reflect the best ability of your team, we do not anticipate that the uneven teams will lead to substantively different outputs.\n Suggested outline You must write and present your analysis as if presenting to a C-suite executive. If you are not familiar with this terminology, the C-suite includes, e.g., the CEO, CFO, and COO of a given company. Generally speaking, such executives are not particularly analytically oriented, and therefore your explanations need to be clear, consise (their time is valuable) and contain actionable (or valuable) information.2 - Concretely, this requires a written memo, which describes the data, analyses, and results. This must be clear and easy to understand for a non-expert in your field. Figures and tables do not apply to the page limit.\nBelow is a very loose guide to the sort of content that we expect for the final project. Word limits are suggestions only. Note your final report will be approximately\nIntroduction Describe the motivation for this analysis. Briefly describe the dataset, and explain why the analysis you’re undertaking matters for society. (Or matters for some decision-making. You should not feel constrained to asking only “big questions.” The best projects will be narrow-scope but well-defined.) (≈300 words)\n Theory and Background Provide in-depth background about the data of interest and about your analytics question. (≈300 words)\n“Theory” Provide some theoretical guidance to the functional relationship you hope to explore. If you’re interested on how, say, height affects scoring in the NBA, write down a proposed function that might map height to scoring. Describe how you might look for this unknown relationship in the data.(≈300 words)\n Hypotheses Make predictions. Declare what you think will happen. (Note, this may carry over from second project.) (≈250 words)\n  Data and Analyses Data Given your motivations, limits on feasibility, and hypotheses, describe the data you use. (≈100 words)\n Analyses Generate the analyses relevant to your hypotheses and interests. Here you must include three figures and must describe what they contain in simple, easy to digest language. Why did you visualize these elements? Your analyses also must include brief discussion.\n(As many words as you need to fully describe your analysis and results)\n  Conclusion What caveats should we consider? Do you believe this is a truly causal relationship? Why does any of this matter to the decision-maker? (≈75 words)\n   Note that existing is taken to mean that you are not permitted to collect data by interacting with other people. That is not to say that you cannot gather data that previously has not been gathered into a single place—this sort of exercise is encouraged. But you cannot stand with a clipboard outside a store and count visitors (for instance).↩︎\n This exercise provides you with an opportunity to identify your marketable skills and to practice them. I encourage those who will be looking for jobs soon to take this exercise seriously.↩︎\n   ","date":1617494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629128785,"objectID":"8d16837a0c729f9c31150a71deaf1f1e","permalink":"https://ssc442.netlify.app/assignment/final-project/","publishdate":"2021-04-04T00:00:00Z","relpermalink":"/assignment/final-project/","section":"assignment","summary":"Requirements Teams Suggested outline  Introduction Theory and Background Data and Analyses Conclusion    Requirements Data analytics is inherently a hands-on endeavor. Thus, the final project for this class is hands-on. As per the overview page, the final project has the following elements:\nFor your final project in this class, you will analyze existing data in some area of interest to you.1 Aggregating data from multiple sources is encouraged, but is not required.","tags":null,"title":"Final project","type":"docs"},{"authors":null,"categories":null,"content":"    Readings A Brief Introduction to SSC442  About Me About You This Course More About This Course And finally… Guiding Questions  What is “Data Analytics”?  Starting point for this course  Statistical Learning The Pros and Cons of Correlation A Case Study in Prediction More Recent Examples of Prediction An Aside: Nomenclature Learning from Data   R basics  Case study: US homicides by firearm The (very) basics  Objects The workspace Functions Other prebuilt objects Variable names Saving your workspace Motivating scripts Commenting your code  Data types  Data frames Examining an object The accessor: $ Vectors: numerics, characters, and logical Factors Lists Matrices  Vectors  Creating vectors Names Sequences Subsetting  Coercion  Not availables (NA)  Sorting  sort order max and which.max rank Beware of recycling  Vector arithmetics  Rescaling a vector Two vectors  Indexing  Subsetting with logicals Logical operators which match %in%  Rmarkdown Lecture Video    Readings As noted in the syllabus, your readings will be assigned each week in this area. For this initial week, please read the course content. Read closely the following:\n The syllabus, content, examples, and labs pages for this class. This page. Yes, the whole thing.  Things to stress from syllabus:\n E-mail isn’t the ideal solution for technical problems No appointments necessary for regularly scheduled office hours; or by appointment. TA office hours are great as well. Our TA has experience in this course. Can only reschedule exams (with good reason) if you tell me before the exam that you have a conflict.  Notify me immediately if you need accommodations because of RCPD or religious convictions; If you approach me at the last minute, I may not be able to help.   Despite my apparent hard-assness, I’m here to help. I am not in the business of giving bad grades for no reason, and I genuinely want you to learn a lot and enjoy the course.\n A Brief Introduction to SSC442  I keep saying that the sexy job in the next 10 years will be statisticians. And I’m not kidding.\n Hal Varian, Chief Economist, Google  About Me Me: My primary area of expertise is behavioral economics (also known as psychology and economics). While my research occasionally touches the topics in the course, I mostly utilize things in the course as tools. In this way, we are likely the same.\nThis class is totally, unapologetically a work in progress. The material is a mish-mash of stuff from courses offered at Caltech, Stanford, Harvard, and Duke…so, yeah, it will be challenging. Hopefully, you’ll find it fun!\n About You New phone who dis? Please email me bbushong@msu.edu your\n name (with pronunciation guide)\n major\n desired graduation year and semester\n interest in this course on a 10-point scale (1: not at all interested; 10: helllllll yeah)\n   You must spend 5 minutes emailing me a little bit about your interests before the next class.\n This Course The syllabus is posted on the course website. I’ll walk through highlights now, but read it later – it’s long. - But eventually, please read it. It is “required.”\nSyllabus highlights:\n Grade is composed of weekly writings, labs, and projects.  Weekly writings: 22% Participation: 4% Labs: 29% Projects: 45%  This structure is designed to give ~55% “for free”. Success on the projects will require real work. Labs consist of a practical implementation of something we’ve covered in the course (e.g., code your own Recommender System).  Grading Grading: come to class.\nIf you complete all assignments and attend all class dates, I suspect you will do very well. Given the way the syllabus is structured, I conjecture that the following is a loose guide to grades:\n4.0 Turned in all assignments with good effort, worked hard on the projects and was proud of final product.\n3.5 Turned in all assignments with good effort, worked a bit on the projects and was indifferent to final product.\n3.0 Turned in all assignments with some effort, worked a bit on the projects and was shy about final product.\n\u0026lt; 3.0 Very little effort, or did not turn in all assignments, worked very little on the projects and was embarassed by final product.\n…of course, failing to turn in assignments can lead to a grade dramatically lower than just a 3.0.\n  More About This Course There are sort of three texts for this course and sort of zero.\nThe “main text” is free and available online. The secondary text is substantially more difficult, but also free online. The third text costs about $25. Assigned readings can be found on the course website under “Content”.\nPlease please please please please: Ask questions during class. - Most ideas will be new. - Sometimes (often?) the material itself will be confusing or interesting—or both! - Teaching is incredibly challenging right now. - Note: If I find that attendance is terrible, I may have to start incorporating attendance into participation.\nReturn of the Please: If there is some topic that you really want to learn about, ask. If you are uncomfortable asking in front of the whole group, please see me during office hours.\nBecause this is a new course:\n Some of the lectures will be way too long or too short. Some (most?) of the lectures won’t make sense. Some of the time I’ll forget what I intended to say and awkwardly stare at you for a few moments (sorry).  Comment throughout the course, not just at the end.\nThe material will improve with time and feedback.\nI encourage measured feedback and thoughtful responses to questions. If I call on you and you don’t know immediately, don’t freak out. If you don’t know, it’s totally okay to say you don’t know.\nSUPER BIG IMPORTANT EXPLANATION OF THE COURSE We teach using “math”. Don’t be afraid. The math won’t hurt you. I fundamentally believe that true knowledge of how we learn from data depends on a basic understanding of the underlying mathematics.\n-The good news is that you’ll face no black boxes. In this class you’ll actually learn how things work. (Probably. Hopefully?) -More good news: the level of required math is reasonably low. High-school algebra or equivalent should be fine. -The bad news is that (at times) the course is notation-heavy. This class will require an active mind.\n  And finally… I cannot address field-specific questions in areas outside economics to any satisfying degree. I’m good at knowing what I don’t know and have a very small ego, which means that I’m much less likely to blow smoke up your ass than other professors. So I won’t pretend I know everything. Of course, this implies that I can’t help with certain types of questions.\nThis course should be applicable broadly, but many of the examples will lean on my personal expertise (sorry).\n Guiding Questions For future lectures, the guiding questions will be more pointed and at a higher level to help steer your thinking. Here, we want to ensure you remember some basics and accordingly the questions are straightforward.\n Do you remember anything about R? What are the different data types in R? How do you index specific elements of a vector? Why might you want to do that?    What is “Data Analytics”? How do you define “data analytics”? (Not a rhetorical question!)\n This course will avoid this nomenclature. It is confusing and imprecise. But you signed up (suckers) and I owe an explanation of what this course will cover.  Some “data analytics” topics we will cover:\n Linear regression (il classico). Models of classification or discrete choice. Analysis of ``wide’’ data. Decision trees and other non-linear models.  Starting point for this course Better utilizing existing data can improve our predictive power whilst providing interpretable outputs for considering new policies.\nWARNING: Causation is tough and we will spend the entire course warning you to avoid making causal claims!\nStatistical Learning A Brief History\nSuppose you are a researcher and you want to teach a computer to recognize images of a tree.\nNote: this is an ``easy” problem. If you show pictures to a 3-year-old, that child will probably be able to tell you if there is a tree in the picture.\nComputer scientists spent about 20 years on this problem because they thought about the problem like nerds and tried to write down a series of rules.\nRules are difficult to form, and simply writing rules misses the key insight: the data can tell you something.\nSocial Science Approaches to Statistical Learning A Brief History\nSuppose you are a researcher and you want to know whether prisons reduce crime.\nfrom ``A Call for a Moratorium on Prison Building’’ (1976)\n Between 1955 and 1975, fifteen states increased the collective capacity of their adult prison systems by 56% (from, on average, 63,100 to 98,649). Fifteen other states increased capacity by less than 4% (from 49,575 to 51,440). In “heavy-construction” states the crime rate increased by 167%; in “low-construction” states the crime rate increased by 145%.     Prison Capacity Crime Rate    High construction \\(\\uparrow\\)~56% \\(\\uparrow\\)~167%  Low construction \\(\\uparrow\\)~4% \\(\\uparrow\\)~145%      The Pros and Cons of Correlation Pros: - Nature gives you correlations for free. - In principle, everyone can agree on the facts.\nCons: - Correlations are not very helpful. - They show what has happened, but not why. - For many things, we care about why.\nWhy a Correlation Exists Between X and Y \\(X \\rightarrow Y\\) X causes Y (causality)\n \\(X \\leftarrow Y\\) Y causes X (reverse causality)\n \\(Z \\rightarrow X\\); \\(Z \\rightarrow Y\\) Z causes X and Y (common cause)\n \\(X \\rightarrow Y\\); \\(Y \\rightarrow X\\) X causes Y and Y causes X (simultaneous equations)\n   Uniting Social Science and Computer Science We will start in this course by examining situations where we do not care about why something has happened, but instead we care about our ability to predict its occurrence from existing data.\n(But of course keep in back of mind that if you are making policy, you must care about why something happened).\nWe will also borrow a few other ideas from CS: - Anything is data + Satellite data + Unstructured text or audio + Facial expressions or vocal intonations - Subtle improvements on existing techniques - An eye towards practical implementability over ``cleanliness”\n  A Case Study in Prediction Example: a firm wishes to predict user behavior based on previous purchases or interactions.\nSmall margins \\(\\rightarrow\\) huge payoffs. \\(10\\% \\rightarrow\\) $1 million.\nNot obvious to me why this was worth so much for Netflix (that’s an interesting research question). However, it’s quite obvious why this is true in financial markets.\n More Recent Examples of Prediction  Identify the risk factors for prostate cancer. Classify a tissue sample into one of several cancer classes, based on a gene expression profile. Classify a recorded phoneme based on a log-periodogram. Predict whether someone will have a heart attack on the basis of demographic, diet and clinical measurements. Customize an email spam detection system. Identify a hand-drawn object. Determine which oscillations of stellar luminosity are likely due to exoplanets. Establish the relationship between salary and demographic variables in population survey data.   An Aside: Nomenclature Machine learning arose as a subfield of Artificial Intelligence.\nStatistical learning arose as a subfield of Statistics.\nThere is much overlap; however, a few points of distinction:\n Machine learning has a greater emphasis on large scale applications and prediction accuracy.\n Statistical learning emphasizes models and their interpretability, and precision and uncertainty.\n But the distinction has become more and more blurred, and there is a great deal of “cross-fertilization”.   Obviously true: machine learning has the upper hand in marketing.\n Learning from Data The following are the basic requirements for statistical learning:\nA pattern exists. This pattern is not easily expressed in a closed mathematical form. You have data.  ALERT\nThe course content below should be considered a prerequisite for success. For those concerned about basics of R, you absolutely must read this content and attempt the coding exercises. If you struggle to follow the content, please contact the professor or TA.\n    R basics In this class, we will be using R software environment for all our analyses. You will learn R and data analysis techniques simultaneously. To follow along you will therefore need access to R. We also recommend the use of an integrated development environment (IDE), such as RStudio, to save your work. Note that it is common for a course or workshop to offer access to an R environment and an IDE through your web browser, as done by RStudio cloud1. If you have access to such a resource, you don’t need to install R and RStudio. However, if you intend on becoming a practicing data analyst, we highly recommend installing these tools on your computer2. This is not hard.\nBoth R and RStudio are free and available online.\nCase study: US homicides by firearm Imagine you live in Europe (if only!) and are offered a job in a US company with many locations in every state. It is a great job, but headlines such as US Gun Homicide Rate Higher Than Other Developed Countries3 have you worried. Fox News runs a scary looking graphic, and charts like the one below only add to that concern:\nOr even worse, this version from everytown.org: But then you remember that (1) this is a hypothetical exercise; (2) you’ll take literally any job at this point; and (3) Geographic diversity matters – the United States is a large and diverse country with 50 very different states (plus the District of Columbia and some lovely territories).4\n## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please ## use `guide = \u0026quot;none\u0026quot;` instead. California, for example, has a larger population than Canada, and 20 US states have populations larger than that of Norway. In some respects, the variability across states in the US is akin to the variability across countries in Europe. Furthermore, although not included in the charts above, the murder rates in Lithuania, Ukraine, and Russia are higher than 4 per 100,000. So perhaps the news reports that worried you are too superficial.\nThis is a relatively simple and straightforward problem in social science: you have options of where to live, and want to determine the safety of the various states. Your “research” is clearly policy-relevant: you will eventually have to live somewhere. We will begin to tackle the problem by examining data related to gun homicides in the US during 2010 using R.\nBefore we get started with our example, we need to cover logistics as well as some of the very basic building blocks that are required to gain more advanced R skills. Ideally, this is a refresher. However, we are aware that your preparation in previously courses varies greatly from student to student. Moreover, we want you to be aware that the usefulness of some of these early building blocks may not be immediately obvious. Later in the class you will appreciate having these skills. Mastery will be rewarded both in this class and (of course) in life.\n The (very) basics Before we get started with the motivating dataset, we need to cover the very basics of R.\nObjects Suppose a relatively math unsavvy student asks us for help solving several quadratic equations of the form \\(ax^2+bx+c = 0\\). You—a savvy student—recall that the quadratic formula gives us the solutions:\n\\[ \\frac{-b - \\sqrt{b^2 - 4ac}}{2a}\\,\\, \\mbox{ and } \\frac{-b + \\sqrt{b^2 - 4ac}}{2a} \\]\nwhich of course depend on the values of \\(a\\), \\(b\\), and \\(c\\). That is, the quadratic equation represents a function with three arguments.\nOne advantage of programming languages is that we can define variables and write expressions with these variables, similar to how we do so in math, but obtain a numeric solution. We will write out general code for the quadratic equation below, but if we are asked to solve \\(x^2 + x -1 = 0\\), then we define:\na \u0026lt;- 1 b \u0026lt;- 1 c \u0026lt;- -1 which stores the values for later use. We use \u0026lt;- to assign values to the variables.\nWe can also assign values using = instead of \u0026lt;-, but we recommend against using = to avoid confusion.5\nTRY IT\nCopy and paste the code above into your console to define the three variables. Note that R does not print anything when we make this assignment. This means the objects were defined successfully. Had you made a mistake, you would have received an error message. Throughout these written notes, you’ll have the most success if you continue to copy code into your own console.\n To see the value stored in a variable, we simply ask R to evaluate a and it shows the stored value:\na ## [1] 1 A more explicit way to ask R to show us the value stored in a is using print like this:\nprint(a) ## [1] 1 We use the term object to describe stuff that is stored in R. Variables are examples, but objects can also be more complicated entities such as functions, which are described later.\n The workspace As we define objects in the console, we are actually changing the workspace. You can see all the variables saved in your workspace by typing:\nls() ## [1] \u0026quot;a\u0026quot; \u0026quot;b\u0026quot; \u0026quot;c\u0026quot; \u0026quot;dat\u0026quot; \u0026quot;filter\u0026quot; \u0026quot;murders\u0026quot; \u0026quot;select\u0026quot; (Note that one of my variables listed above comes from generating the graphs above). In RStudio, the Environment tab shows the values:\nWe should see a, b, and c. If you try to recover the value of a variable that is not in your workspace, you receive an error. For example, if you type x you will receive the following message: Error: object 'x' not found.\nNow since these values are saved in variables, to obtain a solution to our equation, we use the quadratic formula:\n(-b + sqrt(b^2 - 4*a*c) ) / ( 2*a ) ## [1] 0.618034 (-b - sqrt(b^2 - 4*a*c) ) / ( 2*a ) ## [1] -1.618034  Functions Once you define variables, the data analysis process can usually be described as a series of functions applied to the data. R includes several zillion predefined functions and most of the analysis pipelines we construct make extensive use of the built-in functions. But R’s power comes from its scalability. We have access to (nearly) infinite functions via install.packages and library. As we go through the course, we will carefully note new functions we bring to each problem. For now, though, we will stick to the basics.\nNote that you’ve used a function already: you used the function sqrt to solve the quadratic equation above. These functions do not appear in the workspace because you did not define them, but they are available for immediate use.\nIn general, we need to use parentheses to evaluate a function. If you type ls, the function is not evaluated and instead R shows you the code that defines the function. If you type ls() the function is evaluated and, as seen above, we see objects in the workspace.\nUnlike ls, most functions require one or more arguments. Below is an example of how we assign an object to the argument of the function log. Remember that we earlier defined a to be 1:\nlog(8) ## [1] 2.079442 log(a) ## [1] 0 You can find out what the function expects and what it does by reviewing the very useful manuals included in R. You can get help by using the help function like this:\nhelp(\u0026quot;log\u0026quot;) For most functions, we can also use this shorthand:\n?log The help page will show you what arguments the function is expecting. For example, log needs x and base to run. However, some arguments are required and others are optional. You can determine which arguments are optional by noting in the help document that a default value is assigned with =. Defining these is optional.6 For example, the base of the function log defaults to base = exp(1)—that is, log evaluates the natural log by default.\nIf you want a quick look at the arguments without opening the help system, you can type:\nargs(log) ## function (x, base = exp(1)) ## NULL You can change the default values by simply assigning another object:\nlog(8, base = 2) ## [1] 3 Note that we have not been specifying the argument x as such:\nlog(x = 8, base = 2) ## [1] 3 The above code works, but we can save ourselves some typing: if no argument name is used, R assumes you are entering arguments in the order shown in the help file or by args. So by not using the names, it assumes the arguments are x followed by base:\nlog(8,2) ## [1] 3 If using the arguments’ names, then we can include them in whatever order we want:\nlog(base = 2, x = 8) ## [1] 3 To specify arguments, we must use =, and cannot use \u0026lt;-.\nThere are some exceptions to the rule that functions need the parentheses to be evaluated. Among these, the most commonly used are the arithmetic and relational operators. For example:\n2 ^ 3 ## [1] 8 You can see the arithmetic operators by typing:\nhelp(\u0026quot;+\u0026quot;) or\n?\u0026quot;+\u0026quot; and the relational operators by typing:\nhelp(\u0026quot;\u0026gt;\u0026quot;) or\n?\u0026quot;\u0026gt;\u0026quot;  Other prebuilt objects There are several datasets that are included for users to practice and test out functions. You can see all the available datasets by typing:\ndata() This shows you the object name for these datasets. These datasets are objects that can be used by simply typing the name. For example, if you type:\nco2 R will show you Mauna Loa atmospheric \\(CO^2\\) concentration data.\nOther prebuilt objects are mathematical quantities, such as the constant \\(\\pi\\) and \\(\\infty\\):\npi ## [1] 3.141593 Inf+1 ## [1] Inf  Variable names We have used the letters a, b, and c as variable names, but variable names can be almost anything. Some basic rules in R are that variable names have to start with a letter, can’t contain spaces, and should not be variables that are predefined in R. For example, don’t name one of your variables install.packages by typing something like install.packages \u0026lt;- 2. Usually, R is smart enough to prevent you from doing such nonsense, but it’s important to develop good habits.\nA nice convention to follow is to use meaningful words that describe what is stored, use only lower case, and use underscores as a substitute for spaces. For the quadratic equations, we could use something like this:\nsolution_1 \u0026lt;- (-b + sqrt(b^2 - 4*a*c)) / (2*a) solution_2 \u0026lt;- (-b - sqrt(b^2 - 4*a*c)) / (2*a) For more advice, we highly recommend studying (Hadley Wickham’s style guide)[http://adv-r.had.co.nz/Style.html].\n Saving your workspace Values remain in the workspace until you end your session or erase them with the function rm. But workspaces also can be saved for later use. In fact, when you quit R, the program asks you if you want to save your workspace. If you do save it, the next time you start R, the program will restore the workspace.\nWe actually recommend against saving the workspace this way because, as you start working on different projects, it will become harder to keep track of what is saved. Instead, we recommend you assign the workspace a specific name. You can do this by using the function save or save.image. To load, use the function load. When saving a workspace, we recommend the suffix rda or RData. In RStudio, you can also do this by navigating to the Session tab and choosing Save Workspace as. You can later load it using the Load Workspace options in the same tab. You can read the help pages on save, save.image, and load to learn more.\n Motivating scripts To solve another equation such as \\(3x^2 + 2x -1\\), we can copy and paste the code above and then redefine the variables and recompute the solution:\na \u0026lt;- 3 b \u0026lt;- 2 c \u0026lt;- -1 (-b + sqrt(b^2 - 4*a*c)) / (2*a) (-b - sqrt(b^2 - 4*a*c)) / (2*a) By creating and saving a script with the code above, we would not need to retype everything each time and, instead, simply change the variable names. Try writing the script above into an editor and notice how easy it is to change the variables and receive an answer.\n Commenting your code If a line of R code starts with the symbol #, it is not evaluated. We can use this to write reminders of why we wrote particular code. For example, in the script above we could add:\n## Code to compute solution to quadratic equation of the form ax^2 + bx + c ## define the variables a \u0026lt;- 3 b \u0026lt;- 2 c \u0026lt;- -1 ## now compute the solution (-b + sqrt(b^2 - 4*a*c)) / (2*a) (-b - sqrt(b^2 - 4*a*c)) / (2*a) TRY IT\nWhat is the sum of the first 100 positive integers? The formula for the sum of integers \\(1\\) through \\(n\\) is \\(n(n+1)/2\\). Define \\(n=100\\) and then use R to compute the sum of \\(1\\) through \\(100\\) using the formula. What is the sum?\n Now use the same formula to compute the sum of the integers from 1 through 1,000.\n Look at the result of typing the following code into R:\n  n \u0026lt;- 1000 x \u0026lt;- seq(1, n) sum(x) Based on the result, what do you think the functions seq and sum do? You can use help.\nsum creates a list of numbers and seq adds them up. seq creates a list of numbers and sum adds them up. seq creates a random list and sum computes the sum of 1 through 1,000. sum always returns the same number.  In math and programming, we say that we evaluate a function when we replace the argument with a given number. So if we type sqrt(4), we evaluate the sqrt function. In R, you can evaluate a function inside another function. The evaluations happen from the inside out. Use one line of code to compute the log, in base 10, of the square root of 100.\n Which of the following will always return the numeric value stored in x? You can try out examples and use the help system if you want.\n  log(10^x) log10(x^10) log(exp(x)) exp(log(x, base = 2))     Data types Variables in R can be of different types. For example, we need to distinguish numbers from character strings and tables from simple lists of numbers. The function class helps us determine what type of object we have:\na \u0026lt;- 2 class(a) ## [1] \u0026quot;numeric\u0026quot; To work efficiently in R, it is important to learn the different types of variables and what we can do with these.\nData frames Up to now, the variables we have defined are just one number. This is not very useful for storing data. The most common way of storing a dataset in R is in a data frame. Conceptually, we can think of a data frame as a table with rows representing observations and the different variables reported for each observation defining the columns. Data frames are particularly useful for datasets because we can combine different data types into one object.\nA large proportion of data analysis challenges start with data stored in a data frame. For example, we stored the data for our motivating example in a data frame. You can access this dataset by loading the dslabs library and loading the murders dataset using the data function:\nlibrary(dslabs) data(murders) To see that this is in fact a data frame, we type:\nclass(murders) ## [1] \u0026quot;data.frame\u0026quot;  Examining an object The function str is useful for finding out more about the structure of an object:\nstr(murders) ## \u0026#39;data.frame\u0026#39;: 51 obs. of 5 variables: ## $ state : chr \u0026quot;Alabama\u0026quot; \u0026quot;Alaska\u0026quot; \u0026quot;Arizona\u0026quot; \u0026quot;Arkansas\u0026quot; ... ## $ abb : chr \u0026quot;AL\u0026quot; \u0026quot;AK\u0026quot; \u0026quot;AZ\u0026quot; \u0026quot;AR\u0026quot; ... ## $ region : Factor w/ 4 levels \u0026quot;Northeast\u0026quot;,\u0026quot;South\u0026quot;,..: 2 4 4 2 4 4 1 2 2 2 ... ## $ population: num 4779736 710231 6392017 2915918 37253956 ... ## $ total : num 135 19 232 93 1257 ... This tells us much more about the object. We see that the table has 51 rows (50 states plus DC) and five variables. We can show the first six lines using the function head:\nhead(murders) ## state abb region population total ## 1 Alabama AL South 4779736 135 ## 2 Alaska AK West 710231 19 ## 3 Arizona AZ West 6392017 232 ## 4 Arkansas AR South 2915918 93 ## 5 California CA West 37253956 1257 ## 6 Colorado CO West 5029196 65 In this dataset, each state is considered an observation and five variables are reported for each state.\nBefore we go any further in answering our original question about different states, let’s learn more about the components of this object.\n The accessor: $ For our analysis, we will need to access the different variables represented by columns included in this data frame. To do this, we use the accessor operator $ in the following way:\nmurders$population ## [1] 4779736 710231 6392017 2915918 37253956 5029196 3574097 897934 ## [9] 601723 19687653 9920000 1360301 1567582 12830632 6483802 3046355 ## [17] 2853118 4339367 4533372 1328361 5773552 6547629 9883640 5303925 ## [25] 2967297 5988927 989415 1826341 2700551 1316470 8791894 2059179 ## [33] 19378102 9535483 672591 11536504 3751351 3831074 12702379 1052567 ## [41] 4625364 814180 6346105 25145561 2763885 625741 8001024 6724540 ## [49] 1852994 5686986 563626 But how did we know to use population? Previously, by applying the function str to the object murders, we revealed the names for each of the five variables stored in this table. We can quickly access the variable names using:\nnames(murders) ## [1] \u0026quot;state\u0026quot; \u0026quot;abb\u0026quot; \u0026quot;region\u0026quot; \u0026quot;population\u0026quot; \u0026quot;total\u0026quot; It is important to know that the order of the entries in murders$population preserves the order of the rows in our data table. This will later permit us to manipulate one variable based on the results of another. For example, we will be able to order the state names by the number of murders.\nTip: R comes with a very nice auto-complete functionality that saves us the trouble of typing out all the names. Try typing murders$p then hitting the tab key on your keyboard. This functionality and many other useful auto-complete features are available when working in RStudio.\n Vectors: numerics, characters, and logical The object murders$population is not one number but several. We call these types of objects vectors. A single number is technically a vector of length 1, but in general we use the term vectors to refer to objects with several entries. The function length tells you how many entries are in the vector:\npop \u0026lt;- murders$population length(pop) ## [1] 51 This particular vector is numeric since population sizes are numbers:\nclass(pop) ## [1] \u0026quot;numeric\u0026quot; In a numeric vector, every entry must be a number.\nTo store character strings, vectors can also be of class character. For example, the state names are characters:\nclass(murders$state) ## [1] \u0026quot;character\u0026quot; As with numeric vectors, all entries in a character vector need to be a character.\nAnother important type of vectors are logical vectors. These must be either TRUE or FALSE.\nz \u0026lt;- 3 == 2 z ## [1] FALSE class(z) ## [1] \u0026quot;logical\u0026quot; Here the == is a relational operator asking if 3 is equal to 2. In R, if you just use one =, you actually assign a variable, but if you use two == you test for equality. Yet another reason to avoid assigning via =… it can get confusing and typos can really mess things up.\nYou can see the other relational operators by typing:\n?Comparison In future sections, you will see how useful relational operators can be.\nWe discuss more important features of vectors after the next set of exercises.\nAdvanced: Mathematically, the values in pop are integers and there is an integer class in R. However, by default, numbers are assigned class numeric even when they are round integers. For example, class(1) returns numeric. You can turn them into class integer with the as.integer() function or by adding an L like this: 1L. Note the class by typing: class(1L)\n Factors In the murders dataset, we might expect the region to also be a character vector. However, it is not:\nclass(murders$region) ## [1] \u0026quot;factor\u0026quot; It is a factor. Factors are useful for storing categorical data. We can see that there are only 4 regions by using the levels function:\nlevels(murders$region) ## [1] \u0026quot;Northeast\u0026quot; \u0026quot;South\u0026quot; \u0026quot;North Central\u0026quot; \u0026quot;West\u0026quot; In the background, R stores these levels as integers and keeps a map to keep track of the labels. This is more memory efficient than storing all the characters. It is also useful for computational reasons we’ll explore later.\nNote that the levels have an order that is different from the order of appearance in the factor object. The default in R is for the levels to follow alphabetical order. However, often we want the levels to follow a different order. You can specify an order through the levels argument when creating the factor with the factor function. For example, in the murders dataset regions are ordered from east to west. The function reorder lets us change the order of the levels of a factor variable based on a summary computed on a numeric vector. We will demonstrate this with a simple example, and will see more advanced ones in the Data Visualization part of the book.\nSuppose we want the levels of the region by the total number of murders rather than alphabetical order. If there are values associated with each level, we can use the reorder and specify a data summary to determine the order. The following code takes the sum of the total murders in each region, and reorders the factor following these sums.\nregion \u0026lt;- murders$region value \u0026lt;- murders$total region \u0026lt;- reorder(region, value, FUN = sum) levels(region) ## [1] \u0026quot;Northeast\u0026quot; \u0026quot;North Central\u0026quot; \u0026quot;West\u0026quot; \u0026quot;South\u0026quot; The new order is in agreement with the fact that the Northeast has the least murders and the South has the most.\nWarning: Factors can be a source of confusion since sometimes they behave like characters and sometimes they do not. As a result, confusing factors and characters are a common source of bugs.\n Lists Data frames are a special case of lists. We will cover lists in more detail later, but know that they are useful because you can store any combination of different types. Below is an example of a list we created for you:\nrecord ## $name ## [1] \u0026quot;John Doe\u0026quot; ## ## $student_id ## [1] 1234 ## ## $grades ## [1] 95 82 91 97 93 ## ## $final_grade ## [1] \u0026quot;A\u0026quot; class(record) ## [1] \u0026quot;list\u0026quot; As with data frames, you can extract the components of a list with the accessor $. In fact, data frames are a type of list.\nrecord$student_id ## [1] 1234 We can also use double square brackets ([[) like this:\nrecord[[\u0026quot;student_id\u0026quot;]] ## [1] 1234 You should get used to the fact that in R there are often several ways to do the same thing. such as accessing entries.7\nYou might also encounter lists without variable names.\nrecord2 ## [[1]] ## [1] \u0026quot;John Doe\u0026quot; ## ## [[2]] ## [1] 1234 If a list does not have names, you cannot extract the elements with $, but you can still use the brackets method and instead of providing the variable name, you provide the list index, like this:\nrecord2[[1]] ## [1] \u0026quot;John Doe\u0026quot; We won’t be using lists until later, but you might encounter one in your own exploration of R. For this reason, we show you some basics here.\n Matrices Matrices are another type of object that are common in R. Matrices are similar to data frames in that they are two-dimensional: they have rows and columns. However, like numeric, character and logical vectors, entries in matrices have to be all the same type. For this reason data frames are much more useful for storing data, since we can have characters, factors, and numbers in them.\nYet matrices have a major advantage over data frames: we can perform matrix algebra operations, a powerful type of mathematical technique. We do not describe these operations in this class, but much of what happens in the background when you perform a data analysis involves matrices. We describe them briefly here since some of the functions we will learn return matrices.\nWe can define a matrix using the matrix function. We need to specify the number of rows and columns.\nmat \u0026lt;- matrix(1:12, 4, 3) mat ## [,1] [,2] [,3] ## [1,] 1 5 9 ## [2,] 2 6 10 ## [3,] 3 7 11 ## [4,] 4 8 12 You can access specific entries in a matrix using square brackets ([). If you want the second row, third column, you use:\nmat[2, 3] ## [1] 10 If you want the entire second row, you leave the column spot empty:\nmat[2, ] ## [1] 2 6 10 Notice that this returns a vector, not a matrix.\nSimilarly, if you want the entire third column, you leave the row spot empty:\nmat[, 3] ## [1] 9 10 11 12 This is also a vector, not a matrix.\nYou can access more than one column or more than one row if you like. This will give you a new matrix.\nmat[, 2:3] ## [,1] [,2] ## [1,] 5 9 ## [2,] 6 10 ## [3,] 7 11 ## [4,] 8 12 You can subset both rows and columns:\nmat[1:2, 2:3] ## [,1] [,2] ## [1,] 5 9 ## [2,] 6 10 We can convert matrices into data frames using the function as.data.frame:\nas.data.frame(mat) ## V1 V2 V3 ## 1 1 5 9 ## 2 2 6 10 ## 3 3 7 11 ## 4 4 8 12 You can also use single square brackets ([) to access rows and columns of a data frame:\ndata(\u0026quot;murders\u0026quot;) murders[25, 1] ## [1] \u0026quot;Mississippi\u0026quot; murders[2:3, ] ## state abb region population total ## 2 Alaska AK West 710231 19 ## 3 Arizona AZ West 6392017 232 TRY IT\nLoad the US murders dataset.  library(dslabs) data(murders) Use the function str to examine the structure of the murders object. Which of the following best describes the variables represented in this data frame?\nThe 51 states. The murder rates for all 50 states and DC. The state name, the abbreviation of the state name, the state’s region, and the state’s population and total number of murders for 2010. str shows no relevant information.  What are the column names used by the data frame for these five variables?\n Use the accessor $ to extract the state abbreviations and assign them to the object a. What is the class of this object?\n Now use the square brackets to extract the state abbreviations and assign them to the object b. Use the identical function to determine if a and b are the same.\n We saw that the region column stores a factor. You can corroborate this by typing:\n  class(murders$region) With one line of code, use the function levels and length to determine the number of regions defined by this dataset.\nThe function table takes a vector and returns the frequency of each element. You can quickly see how many states are in each region by applying this function. Use this function in one line of code to create a table of states per region.     Vectors In R, the most basic objects available to store data are vectors. As we have seen, complex datasets can usually be broken down into components that are vectors. For example, in a data frame, each column is a vector. Here we learn more about this important class.\nCreating vectors We can create vectors using the function c, which stands for concatenate. We use c to concatenate entries in the following way:\ncodes \u0026lt;- c(380, 124, 818) codes ## [1] 380 124 818 We can also create character vectors. We use the quotes to denote that the entries are characters rather than variable names.\ncountry \u0026lt;- c(\u0026quot;italy\u0026quot;, \u0026quot;canada\u0026quot;, \u0026quot;egypt\u0026quot;) In R you can also use single quotes:\ncountry \u0026lt;- c(\u0026#39;italy\u0026#39;, \u0026#39;canada\u0026#39;, \u0026#39;egypt\u0026#39;) But be careful not to confuse the single quote ’ with the back quote, which shares a keyboard key with ~.\nBy now you should know that if you type:\ncountry \u0026lt;- c(italy, canada, egypt) you receive an error because the variables italy, canada, and egypt are not defined. If we do not use the quotes, R looks for variables with those names and returns an error.\n Names Sometimes it is useful to name the entries of a vector. For example, when defining a vector of country codes, we can use the names to connect the two:\ncodes \u0026lt;- c(italy = 380, canada = 124, egypt = 818) codes ## italy canada egypt ## 380 124 818 The object codes continues to be a numeric vector:\nclass(codes) ## [1] \u0026quot;numeric\u0026quot; but with names:\nnames(codes) ## [1] \u0026quot;italy\u0026quot; \u0026quot;canada\u0026quot; \u0026quot;egypt\u0026quot; If the use of strings without quotes looks confusing, know that you can use the quotes as well:\ncodes \u0026lt;- c(\u0026quot;italy\u0026quot; = 380, \u0026quot;canada\u0026quot; = 124, \u0026quot;egypt\u0026quot; = 818) codes ## italy canada egypt ## 380 124 818 There is no difference between this function call and the previous one. This is one of the many ways in which R is quirky compared to other languages.\nWe can also assign names using the names functions:\ncodes \u0026lt;- c(380, 124, 818) country \u0026lt;- c(\u0026quot;italy\u0026quot;,\u0026quot;canada\u0026quot;,\u0026quot;egypt\u0026quot;) names(codes) \u0026lt;- country codes ## italy canada egypt ## 380 124 818  Sequences Another useful function for creating vectors generates sequences:\nseq(1, 10) ## [1] 1 2 3 4 5 6 7 8 9 10 The first argument defines the start, and the second defines the end which is included. The default is to go up in increments of 1, but a third argument lets us tell it how much to jump by:\nseq(1, 10, 2) ## [1] 1 3 5 7 9 If we want consecutive integers, we can use the following shorthand:\n1:10 ## [1] 1 2 3 4 5 6 7 8 9 10 When we use these functions, R produces integers, not numerics, because they are typically used to index something:\nclass(1:10) ## [1] \u0026quot;integer\u0026quot; However, if we create a sequence including non-integers, the class changes:\nclass(seq(1, 10, 0.5)) ## [1] \u0026quot;numeric\u0026quot;  Subsetting We use square brackets to access specific elements of a vector. For the vector codes we defined above, we can access the second element using:\ncodes[2] ## canada ## 124 You can get more than one entry by using a multi-entry vector as an index:\ncodes[c(1,3)] ## italy egypt ## 380 818 The sequences defined above are particularly useful if we want to access, say, the first two elements:\ncodes[1:2] ## italy canada ## 380 124 If the elements have names, we can also access the entries using these names. Below are two examples.\ncodes[\u0026quot;canada\u0026quot;] ## canada ## 124 codes[c(\u0026quot;egypt\u0026quot;,\u0026quot;italy\u0026quot;)] ## egypt italy ## 818 380   Coercion In general, coercion is an attempt by R to be flexible with data types. When an entry does not match the expected, some of the prebuilt R functions try to guess what was meant before throwing an error. This can also lead to confusion. Failing to understand coercion can drive programmers crazy when attempting to code in R since it behaves quite differently from most other languages in this regard. Let’s learn about it with some examples.\nWe said that vectors must be all of the same type. So if we try to combine, say, numbers and characters, you might expect an error:\nx \u0026lt;- c(1, \u0026quot;canada\u0026quot;, 3) But we don’t get one, not even a warning! What happened? Look at x and its class:\nx ## [1] \u0026quot;1\u0026quot; \u0026quot;canada\u0026quot; \u0026quot;3\u0026quot; class(x) ## [1] \u0026quot;character\u0026quot; R coerced the data into characters. It guessed that because you put a character string in the vector, you meant the 1 and 3 to actually be character strings \"1\" and “3”. The fact that not even a warning is issued is an example of how coercion can cause many unnoticed errors in R.\nR also offers functions to change from one type to another. For example, you can turn numbers into characters with:\nx \u0026lt;- 1:5 y \u0026lt;- as.character(x) y ## [1] \u0026quot;1\u0026quot; \u0026quot;2\u0026quot; \u0026quot;3\u0026quot; \u0026quot;4\u0026quot; \u0026quot;5\u0026quot; You can turn it back with as.numeric:\nas.numeric(y) ## [1] 1 2 3 4 5 This function is actually quite useful since datasets that include numbers as character strings are common.\nNot availables (NA) This “topic” seems to be wholly unappreciated and it has been our experience that students often panic when encountering an NA. This often happens when a function tries to coerce one type to another and encounters an impossible case. In such circumstances, R usually gives us a warning and turns the entry into a special value called an NA (for “not available”). For example:\nx \u0026lt;- c(\u0026quot;1\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;3\u0026quot;) as.numeric(x) ## Warning: NAs introduced by coercion ## [1] 1 NA 3 R does not have any guesses for what number you want when you type b, so it does not try.\nWhile coercion is a common case leading to NAs, you’ll see them in nearly every real-world dataset. Most often, you will encounter the NAs as a stand-in for missing data. Again, this a common problem in real-world datasets and you need to be aware that it will come up.\n  Sorting Now that we have mastered some basic R knowledge (ha!), let’s try to gain some insights into the safety of different states in the context of gun murders.\nsort Say we want to rank the states from least to most gun murders. The function sort sorts a vector in increasing order. We can therefore see the largest number of gun murders by typing:\nlibrary(dslabs) data(murders) sort(murders$total) ## [1] 2 4 5 5 7 8 11 12 12 16 19 21 22 27 32 ## [16] 36 38 53 63 65 67 84 93 93 97 97 99 111 116 118 ## [31] 120 135 142 207 219 232 246 250 286 293 310 321 351 364 376 ## [46] 413 457 517 669 805 1257 However, this does not give us information about which states have which murder totals. For example, we don’t know which state had 1257.\n order The function order is closer to what we want. It takes a vector as input and returns the vector of indexes that sorts the input vector. This may sound confusing so let’s look at a simple example. We can create a vector and sort it:\nx \u0026lt;- c(31, 4, 15, 92, 65) sort(x) ## [1] 4 15 31 65 92 Rather than sort the input vector, the function order returns the index that sorts input vector:\nindex \u0026lt;- order(x) x[index] ## [1] 4 15 31 65 92 This is the same output as that returned by sort(x). If we look at this index, we see why it works:\nx ## [1] 31 4 15 92 65 order(x) ## [1] 2 3 1 5 4 The second entry of x is the smallest, so order(x) starts with 2. The next smallest is the third entry, so the second entry is 3 and so on.\nHow does this help us order the states by murders? First, remember that the entries of vectors you access with $ follow the same order as the rows in the table. For example, these two vectors containing state names and abbreviations, respectively, are matched by their order:\nmurders$state[1:6] ## [1] \u0026quot;Alabama\u0026quot; \u0026quot;Alaska\u0026quot; \u0026quot;Arizona\u0026quot; \u0026quot;Arkansas\u0026quot; \u0026quot;California\u0026quot; ## [6] \u0026quot;Colorado\u0026quot; murders$abb[1:6] ## [1] \u0026quot;AL\u0026quot; \u0026quot;AK\u0026quot; \u0026quot;AZ\u0026quot; \u0026quot;AR\u0026quot; \u0026quot;CA\u0026quot; \u0026quot;CO\u0026quot; This means we can order the state names by their total murders. We first obtain the index that orders the vectors according to murder totals and then index the state names vector:\nind \u0026lt;- order(murders$total) murders$abb[ind] ## [1] \u0026quot;VT\u0026quot; \u0026quot;ND\u0026quot; \u0026quot;NH\u0026quot; \u0026quot;WY\u0026quot; \u0026quot;HI\u0026quot; \u0026quot;SD\u0026quot; \u0026quot;ME\u0026quot; \u0026quot;ID\u0026quot; \u0026quot;MT\u0026quot; \u0026quot;RI\u0026quot; \u0026quot;AK\u0026quot; \u0026quot;IA\u0026quot; \u0026quot;UT\u0026quot; \u0026quot;WV\u0026quot; \u0026quot;NE\u0026quot; ## [16] \u0026quot;OR\u0026quot; \u0026quot;DE\u0026quot; \u0026quot;MN\u0026quot; \u0026quot;KS\u0026quot; \u0026quot;CO\u0026quot; \u0026quot;NM\u0026quot; \u0026quot;NV\u0026quot; \u0026quot;AR\u0026quot; \u0026quot;WA\u0026quot; \u0026quot;CT\u0026quot; \u0026quot;WI\u0026quot; \u0026quot;DC\u0026quot; \u0026quot;OK\u0026quot; \u0026quot;KY\u0026quot; \u0026quot;MA\u0026quot; ## [31] \u0026quot;MS\u0026quot; \u0026quot;AL\u0026quot; \u0026quot;IN\u0026quot; \u0026quot;SC\u0026quot; \u0026quot;TN\u0026quot; \u0026quot;AZ\u0026quot; \u0026quot;NJ\u0026quot; \u0026quot;VA\u0026quot; \u0026quot;NC\u0026quot; \u0026quot;MD\u0026quot; \u0026quot;OH\u0026quot; \u0026quot;MO\u0026quot; \u0026quot;LA\u0026quot; \u0026quot;IL\u0026quot; \u0026quot;GA\u0026quot; ## [46] \u0026quot;MI\u0026quot; \u0026quot;PA\u0026quot; \u0026quot;NY\u0026quot; \u0026quot;FL\u0026quot; \u0026quot;TX\u0026quot; \u0026quot;CA\u0026quot; According to the above, California had the most murders.\n max and which.max If we are only interested in the entry with the largest value, we can use max for the value:\nmax(murders$total) ## [1] 1257 and which.max for the index of the largest value:\ni_max \u0026lt;- which.max(murders$total) murders$state[i_max] ## [1] \u0026quot;California\u0026quot; For the minimum, we can use min and which.min in the same way.\nDoes this mean California is the most dangerous state? In an upcoming section, we argue that we should be considering rates instead of totals. Before doing that, we introduce one last order-related function: rank.\n rank Although not as frequently used as order and sort, the function rank is also related to order and can be useful. For any given vector it returns a vector with the rank of the first entry, second entry, etc., of the input vector. Here is a simple example:\nx \u0026lt;- c(31, 4, 15, 92, 65) rank(x) ## [1] 3 1 2 5 4 To summarize, let’s look at the results of the three functions we have introduced:\n  original  sort  order  rank      31  4  2  3    4  15  3  1    15  31  1  2    92  65  5  5    65  92  4  4      Beware of recycling Another common source of unnoticed errors in R is the use of recycling. We saw that vectors are added elementwise. So if the vectors don’t match in length, it is natural to assume that we should get an error. But we don’t. Notice what happens:\nx \u0026lt;- c(1,2,3) y \u0026lt;- c(10, 20, 30, 40, 50, 60, 70) x+y ## Warning in x + y: longer object length is not a multiple of shorter object ## length ## [1] 11 22 33 41 52 63 71 We do get a warning, but no error. For the output, R has recycled the numbers in x. Notice the last digit of numbers in the output.\nTRY IT\nFor these exercises we will use the US murders dataset. Make sure you load it prior to starting.\nlibrary(dslabs) data(\u0026quot;murders\u0026quot;) Use the $ operator to access the population size data and store it as the object pop. Then use the sort function to redefine pop so that it is sorted. Finally, use the [ operator to report the smallest population size.\n Now instead of the smallest population size, find the index of the entry with the smallest population size. Hint: use order instead of sort.\n We can actually perform the same operation as in the previous exercise using the function which.min. Write one line of code that does this.\n Now we know how small the smallest state is and we know which row represents it. Which state is it? Define a variable states to be the state names from the murders data frame. Report the name of the state with the smallest population.\n You can create a data frame using the data.frame function. Here is a quick example:\n  temp \u0026lt;- c(35, 88, 42, 84, 81, 30) city \u0026lt;- c(\u0026quot;Beijing\u0026quot;, \u0026quot;Lagos\u0026quot;, \u0026quot;Paris\u0026quot;, \u0026quot;Rio de Janeiro\u0026quot;, \u0026quot;San Juan\u0026quot;, \u0026quot;Toronto\u0026quot;) city_temps \u0026lt;- data.frame(name = city, temperature = temp) Use the rank function to determine the population rank of each state from smallest population size to biggest. Save these ranks in an object called ranks, then create a data frame with the state name and its rank. Call the data frame my_df.\nRepeat the previous exercise, but this time order my_df so that the states are ordered from least populous to most populous. Hint: create an object ind that stores the indexes needed to order the population values. Then use the bracket operator [ to re-order each column in the data frame.\n The na_example vector represents a series of counts. You can quickly examine the object using:\n  data(\u0026quot;na_example\u0026quot;) str(na_example) ## int [1:1000] 2 1 3 2 1 3 1 4 3 2 ... However, when we compute the average with the function mean, we obtain an NA:\nmean(na_example) ## [1] NA The is.na function returns a logical vector that tells us which entries are NA. Assign this logical vector to an object called ind and determine how many NAs does na_example have.\nNow compute the average again, but only for the entries that are not NA. Hint: remember the ! operator.     Vector arithmetics California had the most murders, but does this mean it is the most dangerous state? What if it just has many more people than any other state? We can quickly confirm that California indeed has the largest population:\nlibrary(dslabs) data(\u0026quot;murders\u0026quot;) murders$state[which.max(murders$population)] ## [1] \u0026quot;California\u0026quot; with over 37 million inhabitants. It is therefore unfair to compare the totals if we are interested in learning how safe the state is. What we really should be computing is the murders per capita. The reports we describe in the motivating section used murders per 100,000 as the unit. To compute this quantity, the powerful vector arithmetic capabilities of R come in handy.\nRescaling a vector In R, arithmetic operations on vectors occur element-wise. For a quick example, suppose we have height in inches:\ninches \u0026lt;- c(69, 62, 66, 70, 70, 73, 67, 73, 67, 70) and want to convert to centimeters. Notice what happens when we multiply inches by 2.54:\ninches * 2.54 ## [1] 175.26 157.48 167.64 177.80 177.80 185.42 170.18 185.42 170.18 177.80 In the line above, we multiplied each element by 2.54. Similarly, if for each entry we want to compute how many inches taller or shorter than 69 inches, the average height for males, we can subtract it from every entry like this:\ninches - 69 ## [1] 0 -7 -3 1 1 4 -2 4 -2 1  Two vectors If we have two vectors of the same length, and we sum them in R, they will be added entry by entry as follows:\n\\[ \\begin{pmatrix} a\\\\ b\\\\ c\\\\ d \\end{pmatrix} + \\begin{pmatrix} e\\\\ f\\\\ g\\\\ h \\end{pmatrix} = \\begin{pmatrix} a +e\\\\ b + f\\\\ c + g\\\\ d + h \\end{pmatrix} \\]\nThe same holds for other mathematical operations, such as -, * and /.\nThis implies that to compute the murder rates we can simply type:\nmurder_rate \u0026lt;- murders$total / murders$population * 100000 Once we do this, we notice that California is no longer near the top of the list. In fact, we can use what we have learned to order the states by murder rate:\nmurders$abb[order(murder_rate)] ## [1] \u0026quot;VT\u0026quot; \u0026quot;NH\u0026quot; \u0026quot;HI\u0026quot; \u0026quot;ND\u0026quot; \u0026quot;IA\u0026quot; \u0026quot;ID\u0026quot; \u0026quot;UT\u0026quot; \u0026quot;ME\u0026quot; \u0026quot;WY\u0026quot; \u0026quot;OR\u0026quot; \u0026quot;SD\u0026quot; \u0026quot;MN\u0026quot; \u0026quot;MT\u0026quot; \u0026quot;CO\u0026quot; \u0026quot;WA\u0026quot; ## [16] \u0026quot;WV\u0026quot; \u0026quot;RI\u0026quot; \u0026quot;WI\u0026quot; \u0026quot;NE\u0026quot; \u0026quot;MA\u0026quot; \u0026quot;IN\u0026quot; \u0026quot;KS\u0026quot; \u0026quot;NY\u0026quot; \u0026quot;KY\u0026quot; \u0026quot;AK\u0026quot; \u0026quot;OH\u0026quot; \u0026quot;CT\u0026quot; \u0026quot;NJ\u0026quot; \u0026quot;AL\u0026quot; \u0026quot;IL\u0026quot; ## [31] \u0026quot;OK\u0026quot; \u0026quot;NC\u0026quot; \u0026quot;NV\u0026quot; \u0026quot;VA\u0026quot; \u0026quot;AR\u0026quot; \u0026quot;TX\u0026quot; \u0026quot;NM\u0026quot; \u0026quot;CA\u0026quot; \u0026quot;FL\u0026quot; \u0026quot;TN\u0026quot; \u0026quot;PA\u0026quot; \u0026quot;AZ\u0026quot; \u0026quot;GA\u0026quot; \u0026quot;MS\u0026quot; \u0026quot;MI\u0026quot; ## [46] \u0026quot;DE\u0026quot; \u0026quot;SC\u0026quot; \u0026quot;MD\u0026quot; \u0026quot;MO\u0026quot; \u0026quot;LA\u0026quot; \u0026quot;DC\u0026quot; TRY IT\nPreviously we created this data frame:  temp \u0026lt;- c(35, 88, 42, 84, 81, 30) city \u0026lt;- c(\u0026quot;Beijing\u0026quot;, \u0026quot;Lagos\u0026quot;, \u0026quot;Paris\u0026quot;, \u0026quot;Rio de Janeiro\u0026quot;, \u0026quot;San Juan\u0026quot;, \u0026quot;Toronto\u0026quot;) city_temps \u0026lt;- data.frame(name = city, temperature = temp) Remake the data frame using the code above, but add a line that converts the temperature from Fahrenheit to Celsius. The conversion is \\(C = \\frac{5}{9} \\times (F - 32)\\).\nWrite code to compute the following sum \\(1+1/2^2 + 1/3^2 + \\dots 1/100^2\\)? Hint: thanks to Euler, we know it should be close to \\(\\pi^2/6\\).\n Compute the per 100,000 murder rate for each state and store it in the object murder_rate. Then compute the average murder rate for the US using the function mean. What is the average?\n     Indexing Indexing is a boring name for an important tool. R provides a powerful and convenient way of referencing specific elements of vectors. We can, for example, subset a vector based on properties of another vector. In this section, we continue working with our US murders example, which we can load like this:\nlibrary(dslabs) data(\u0026quot;murders\u0026quot;) Subsetting with logicals We have now calculated the murder rate using:\nmurder_rate \u0026lt;- murders$total / murders$population * 100000 Imagine you are moving from Italy where, according to an ABC news report, the murder rate is only 0.71 per 100,000. You would prefer to move to a state with a similar murder rate. Another powerful feature of R is that we can use logicals to index vectors. If we compare a vector to a single number, it actually performs the test for each entry. The following is an example related to the question above:\nind \u0026lt;- murder_rate \u0026lt; 0.71 If we instead want to know if a value is less or equal, we can use:\nind \u0026lt;- murder_rate \u0026lt;= 0.71 Note that we get back a logical vector with TRUE for each entry smaller than or equal to 0.71. To see which states these are, we can leverage the fact that vectors can be indexed with logicals.\nmurders$state[ind] ## [1] \u0026quot;Hawaii\u0026quot; \u0026quot;Iowa\u0026quot; \u0026quot;New Hampshire\u0026quot; \u0026quot;North Dakota\u0026quot; ## [5] \u0026quot;Vermont\u0026quot; In order to count how many are TRUE, the function sum returns the sum of the entries of a vector and logical vectors get coerced to numeric with TRUE coded as 1 and FALSE as 0. Thus we can count the states using:\nsum(ind) ## [1] 5  Logical operators Suppose we like the mountains and we want to move to a safe state in the western region of the country. We want the murder rate to be at most 1. In this case, we want two different things to be true. Here we can use the logical operator and, which in R is represented with \u0026amp;. This operation results in TRUE only when both logicals are TRUE. To see this, consider this example:\nTRUE \u0026amp; TRUE ## [1] TRUE TRUE \u0026amp; FALSE ## [1] FALSE FALSE \u0026amp; FALSE ## [1] FALSE For our example, we can form two logicals:\nwest \u0026lt;- murders$region == \u0026quot;West\u0026quot; safe \u0026lt;- murder_rate \u0026lt;= 1 and we can use the \u0026amp; to get a vector of logicals that tells us which states satisfy both conditions:\nind \u0026lt;- safe \u0026amp; west murders$state[ind] ## [1] \u0026quot;Hawaii\u0026quot; \u0026quot;Idaho\u0026quot; \u0026quot;Oregon\u0026quot; \u0026quot;Utah\u0026quot; \u0026quot;Wyoming\u0026quot;  which Suppose we want to look up California’s murder rate. For this type of operation, it is convenient to convert vectors of logicals into indexes instead of keeping long vectors of logicals. The function which tells us which entries of a logical vector are TRUE. So we can type:\nind \u0026lt;- which(murders$state == \u0026quot;California\u0026quot;) murder_rate[ind] ## [1] 3.374138  match If instead of just one state we want to find out the murder rates for several states, say New York, Florida, and Texas, we can use the function match. This function tells us which indexes of a second vector match each of the entries of a first vector:\nind \u0026lt;- match(c(\u0026quot;New York\u0026quot;, \u0026quot;Florida\u0026quot;, \u0026quot;Texas\u0026quot;), murders$state) ind ## [1] 33 10 44 Now we can look at the murder rates:\nmurder_rate[ind] ## [1] 2.667960 3.398069 3.201360  %in% If rather than an index we want a logical that tells us whether or not each element of a first vector is in a second, we can use the function %in%. Let’s imagine you are not sure if Boston, Dakota, and Washington are states. You can find out like this:\nc(\u0026quot;Boston\u0026quot;, \u0026quot;Dakota\u0026quot;, \u0026quot;Washington\u0026quot;) %in% murders$state ## [1] FALSE FALSE TRUE Note that we will be using %in% often throughout the book.\nAdvanced: There is a connection between match and %in% through which. To see this, notice that the following two lines produce the same index (although in different order):\nmatch(c(\u0026quot;New York\u0026quot;, \u0026quot;Florida\u0026quot;, \u0026quot;Texas\u0026quot;), murders$state) ## [1] 33 10 44 which(murders$state%in%c(\u0026quot;New York\u0026quot;, \u0026quot;Florida\u0026quot;, \u0026quot;Texas\u0026quot;)) ## [1] 10 33 44   Rmarkdown If you’re new to Rmarkdown, I have made a short video on how to use it . This video is for my EC420 course, but works for us as well.\nEXERCISES\nStart by loading the library and data.\nlibrary(dslabs) data(murders) Compute the per 100,000 murder rate for each state and store it in an object called murder_rate. Then use logical operators to create a logical vector named low that tells us which entries of murder_rate are lower than 1.\n Now use the results from the previous exercise and the function which to determine the indices of murder_rate associated with values lower than 1.\n Use the results from the previous exercise to report the names of the states with murder rates lower than 1.\n Now extend the code from exercises 2 and 3 to report the states in the Northeast with murder rates lower than 1. Hint: use the previously defined logical vector low and the logical operator \u0026amp;.\n In a previous exercise we computed the murder rate for each state and the average of these numbers. How many states are below the average?\n Use the match function to identify the states with abbreviations AK, MI, and IA. Hint: start by defining an index of the entries of murders$abb that match the three abbreviations, then use the [ operator to extract the states.\n Use the %in% operator to create a logical vector that answers the question: which of the following are actual abbreviations: MA, ME, MI, MO, MU?\n Extend the code you used in exercise 7 to report the one entry that is not an actual abbreviation. Hint: use the ! operator, which turns FALSE into TRUE and vice versa, then which to obtain an index.\n    Lecture Video Video from lecture hosted on Mediaspace \n   https://rstudio.cloud↩︎\n https://rafalab.github.io/dsbook/installing-r-rstudio.html↩︎\n http://abcnews.go.com/blogs/headlines/2012/12/us-gun-ownership-homicide-rate-higher-than-other-developed-countries/↩︎\n I’m especially partial to Puerto Rico.↩︎\n This is, without a doubt, my least favorite aspect of R. I’d even venture to call it stupid. The logic behind this pesky \u0026lt;- is a total mystery to me, but there is logic to avoiding =. But, you do you.↩︎\n This equals sign is the reasons we assign values with \u0026lt;-; then when arguments of a function are assigned values, we don’t end up with multiple equals signs. But… who cares.↩︎\n Whether you view this as a feature or a bug is a good indicator whether you’ll enjoy working with R.↩︎\n   ","date":1609286400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1630504385,"objectID":"9be773bd8dbb1773f9326846c039d666","permalink":"https://ssc442.netlify.app/content/00-content/","publishdate":"2020-12-30T00:00:00Z","relpermalink":"/content/00-content/","section":"content","summary":"Readings A Brief Introduction to SSC442  About Me About You This Course More About This Course And finally… Guiding Questions  What is “Data Analytics”?  Starting point for this course  Statistical Learning The Pros and Cons of Correlation A Case Study in Prediction More Recent Examples of Prediction An Aside: Nomenclature Learning from Data   R basics  Case study: US homicides by firearm The (very) basics  Objects The workspace Functions Other prebuilt objects Variable names Saving your workspace Motivating scripts Commenting your code  Data types  Data frames Examining an object The accessor: $ Vectors: numerics, characters, and logical Factors Lists Matrices  Vectors  Creating vectors Names Sequences Subsetting  Coercion  Not availables (NA)  Sorting  sort order max and which.","tags":null,"title":"Welcome Back to R","type":"docs"},{"authors":null,"categories":null,"content":"  Below is a roadmap for the semester. Note that this will inevitably change from the first day you access this course. However, whatever is listed below should be considered canon. Accordingly, you should visit this page frequently throughout the term.\nAs mentioned in the syllabus, the course is structured by topics. Each week introduces a new topic. Within each week, there are three elements of the course—these are described below.\nOverview The class is structured with three distinct bits. First, the Tuesday lecture will give an overview of the topic for the week. Next, the Thursday lecture will have a shorter, practical lecture and an activity which is designed to give you hands-on experience and a greater understanding of the broader material. Finally, you will complete weekly writings (short) and labs (also short; requiring coding in R). Out of class, you will complete readings and can watch supplemental videos on the week’s topic. You are not required to view supplemental recorded videos unless specifically noted.\n Content (): This page contains the readings and recorded lectures for the topic. These pages should be read completely. Lectures are not an exact replication of the written content; on the contrary, the lectures are intended to keep you focused on the high-level ideas, while the readings are broader and more comprehensive. Accordingly, lectures are shorter than the (often quite lengthy) written content.\n Examples (): This page the material that we will discuss in Thursday classes. In addition to teaching specific content, there are many more R code examples. These are intended as a useful reference to various functions that you will need when working on (nearly) weekly labs and your group project.\n Assignments (): This page contains the instructions for the weekly lab (1–3 brief tasks) and for the two mini projects + final project. Labs are due by 11:59 PM (Eastern) on the Sunday after they’re posted.\n   Office Hours (TA): To Be Determined. The teaching assistant for this course (TBD) will host office each week to help promote additional understanding. I highly encourage you to utilize this resource, especially if you struggle with basic R programming.\ntl;dr: You should follow this general process (in order) each week:\n Do everything on the content () page before Tuesday Come to the lecture on Tuesday. While “in class” on Thursday, work through the example () page Complete the lab () and the weekly writing (assigned in class) before the next Tuesday. As needed, attend the lab hours hosted by the TA.      Programming Foundations Content Example Assignment   Week 0 (30 August) (Re-) Introduction to R      Week 1 (6 September) Programming Basics, the tidyverse, and Visualization         Week 2 (13 September) Visualization II         Week 3 (20 September) Visualization III       Data Analysis Foundations Content Example Assignment   Week 4 (27 September) Probability and Statistics in R         3 October  Project 1 Due         Week 5 (4 October) Linear Regression I         Week 6 (11 October) Linear Regression II         Week 7 (18 October) Linear Regression III          Applications of Data Analysis Content Example Assignment   Week 8 (25 October) Bias vs Variance         Week 9 (1 November) Nonlinear Regression         7 November  Project 2 Due         Week 10 (8 November) Classification         Week 11 (15 November) Wrangling Data          Further Extensions Content Example Assignment   Week 12 (22 November) Geospatial Data in R         Week 12 (29 November) Text as Data         Week 14 (6 December) Advanced Topics and Analyses          Conclusions Content Example Assignment   14 December, 11:59 PM Eastern  Final Project Due          ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629127886,"objectID":"3e223d7ba58b0122b42458e4cf52e04c","permalink":"https://ssc442.netlify.app/schedule/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/schedule/","section":"","summary":"Below is a roadmap for the semester. Note that this will inevitably change from the first day you access this course. However, whatever is listed below should be considered canon. Accordingly, you should visit this page frequently throughout the term.\nAs mentioned in the syllabus, the course is structured by topics. Each week introduces a new topic. Within each week, there are three elements of the course—these are described below.","tags":null,"title":"Schedule","type":"page"}]